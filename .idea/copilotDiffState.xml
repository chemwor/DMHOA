<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/app.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app.py" />
              <option name="originalContent" value="import os&#10;import io&#10;import json&#10;import logging&#10;from typing import Dict, Any, Optional, Tuple, List&#10;import re&#10;from datetime import datetime&#10;import threading&#10;import time&#10;&#10;import requests&#10;from flask import Flask, request, jsonify&#10;from pypdf import PdfReader&#10;import stripe&#10;&#10;import smtplib&#10;from email.mime.text import MIMEText&#10;from email.mime.multipart import MIMEMultipart&#10;&#10;# Image processing and OCR imports&#10;from PIL import Image&#10;import pytesseract&#10;&#10;&#10;# Configure logging&#10;logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')&#10;logger = logging.getLogger(__name__)&#10;&#10;app = Flask(__name__)&#10;&#10;# Configuration&#10;SUPABASE_URL = os.environ.get('SUPABASE_URL')&#10;SUPABASE_SERVICE_ROLE_KEY = os.environ.get('SUPABASE_SERVICE_ROLE_KEY')&#10;DOC_EXTRACT_WEBHOOK_SECRET = os.environ.get('DOC_EXTRACT_WEBHOOK_SECRET')&#10;&#10;# Stripe Configuration&#10;STRIPE_SECRET_KEY = os.environ.get('STRIPE_SECRET_KEY')&#10;STRIPE_WEBHOOK_SECRET = os.environ.get('STRIPE_WEBHOOK_SECRET')&#10;STRIPE_PRICE_ID = os.environ.get('STRIPE_PRICE_ID')&#10;SITE_URL = os.environ.get('SITE_URL', 'https://disputemyhoa.com')&#10;&#10;# OpenAI Configuration&#10;OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')&#10;&#10;# Configure Stripe&#10;if STRIPE_SECRET_KEY:&#10;    stripe.api_key = STRIPE_SECRET_KEY&#10;&#10;# SMTP Configuration - Optional, only needed for email functionality&#10;SMTP_HOST = os.environ.get(&quot;SMTP_HOST&quot;)&#10;SMTP_PORT = int(os.environ.get(&quot;SMTP_PORT&quot;, &quot;587&quot;))&#10;# Clean SMTP credentials to handle non-ASCII characters like non-breaking spaces&#10;SMTP_USER = (os.environ.get(&quot;SMTP_USER&quot;) or &quot;&quot;).strip().replace('\xa0', ' ')&#10;SMTP_PASS = (os.environ.get(&quot;SMTP_PASS&quot;) or &quot;&quot;).strip().replace('\xa0', ' ')&#10;SMTP_FROM = os.environ.get(&quot;SMTP_FROM&quot;, &quot;support@disputemyhoa.com&quot;)&#10;&#10;SMTP_SENDER_WEBHOOK_SECRET = os.environ.get(&quot;SMTP_SENDER_WEBHOOK_SECRET&quot;)&#10;SMTP_SENDER_WEBHOOK_URL = os.environ.get(&quot;SMTP_SENDER_WEBHOOK_URL&quot;)&#10;&#10;# Request timeouts&#10;TIMEOUT = (5, 60)  # (connect, read)&#10;&#10;def supabase_headers() -&gt; Dict[str, str]:&#10;    &quot;&quot;&quot;Return headers for Supabase API requests.&quot;&quot;&quot;&#10;    return {&#10;        'apikey': SUPABASE_SERVICE_ROLE_KEY,&#10;        'Authorization': f'Bearer {SUPABASE_SERVICE_ROLE_KEY}',&#10;        'Content-Type': 'application/json'&#10;    }&#10;&#10;def fetch_document_status(document_id: str) -&gt; Optional[Dict[str, Any]]:&#10;    &quot;&quot;&quot;Fetch current document status from Supabase.&quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        params = {&#10;            'id': f'eq.{document_id}',&#10;            'select': 'id,token,status'&#10;        }&#10;        headers = supabase_headers()&#10;&#10;        response = requests.get(url, params=params, headers=headers, timeout=TIMEOUT)&#10;        response.raise_for_status()&#10;&#10;        data = response.json()&#10;        return data[0] if data else None&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Failed to fetch document status for {document_id}: {str(e)}&quot;)&#10;        return None&#10;&#10;def update_document(document_id: str, token: str, updates: Dict[str, Any]) -&gt; bool:&#10;    &quot;&quot;&quot;Update document in Supabase database.&quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        params = {&#10;            'id': f'eq.{document_id}',&#10;            'token': f'eq.{token}'&#10;        }&#10;        headers = supabase_headers()&#10;        headers['Prefer'] = 'return=representation'&#10;&#10;        response = requests.patch(url, params=params, headers=headers,&#10;                                json=updates, timeout=TIMEOUT)&#10;        response.raise_for_status()&#10;&#10;        logger.info(f&quot;Updated document {document_id} with: {updates}&quot;)&#10;        return True&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Failed to update document {document_id}: {str(e)}&quot;)&#10;        return False&#10;&#10;def download_storage_object(bucket: str, path: str) -&gt; Optional[bytes]:&#10;    &quot;&quot;&quot;Download file from Supabase Storage.&quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/storage/v1/object/{bucket}/{path}&quot;&#10;        headers = {&#10;            'apikey': SUPABASE_SERVICE_ROLE_KEY,&#10;            'Authorization': f'Bearer {SUPABASE_SERVICE_ROLE_KEY}'&#10;        }&#10;&#10;        response = requests.get(url, headers=headers, timeout=TIMEOUT)&#10;&#10;        if response.status_code == 404:&#10;            logger.error(f&quot;File not found: {bucket}/{path}&quot;)&#10;            return None&#10;&#10;        response.raise_for_status()&#10;&#10;        logger.info(f&quot;Downloaded {len(response.content)} bytes from {bucket}/{path}&quot;)&#10;        return response.content&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Failed to download {bucket}/{path}: {str(e)}&quot;)&#10;        return None&#10;&#10;def extract_pdf_text(pdf_bytes: bytes) -&gt; Tuple[str, int, int, Optional[str]]:&#10;    &quot;&quot;&quot;&#10;    Extract text from PDF bytes.&#10;    Returns: (extracted_text, page_count, char_count, error_message)&#10;    &quot;&quot;&quot;&#10;    try:&#10;        reader = PdfReader(io.BytesIO(pdf_bytes))&#10;        page_count = len(reader.pages)&#10;&#10;        text_parts = []&#10;        for page in reader.pages:&#10;            try:&#10;                page_text = page.extract_text() or &quot;&quot;&#10;                text_parts.append(page_text)&#10;            except Exception as e:&#10;                logger.warning(f&quot;Failed to extract text from page: {str(e)}&quot;)&#10;                text_parts.append(&quot;&quot;)&#10;&#10;        extracted_text = &quot;\n\n&quot;.join(text_parts)&#10;        char_count = len(extracted_text)&#10;&#10;        # Check if text is empty or only whitespace&#10;        if not extracted_text or extracted_text.strip() == &quot;&quot;:&#10;            return &quot;&quot;, page_count, 0, &quot;No text layer found - document may be scanned and require OCR&quot;&#10;&#10;        logger.info(f&quot;Extracted {char_count} characters from {page_count} pages&quot;)&#10;        return extracted_text, page_count, char_count, None&#10;&#10;    except Exception as e:&#10;        error_msg = f&quot;Failed to extract text from PDF: {str(e)}&quot;&#10;        logger.error(error_msg)&#10;        return &quot;&quot;, 0, 0, error_msg&#10;&#10;&#10;def extract_image_text(image_bytes: bytes, filename: str = &quot;&quot;) -&gt; Tuple[str, int, int, Optional[str]]:&#10;    &quot;&quot;&quot;&#10;    Extract text from image bytes using OCR.&#10;    Returns: (extracted_text, page_count=1, char_count, error_message)&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Open image from bytes&#10;        image = Image.open(io.BytesIO(image_bytes))&#10;&#10;        # Convert to RGB if necessary (some formats like RGBA or P need conversion)&#10;        if image.mode not in ('RGB', 'L'):&#10;            image = image.convert('RGB')&#10;&#10;        logger.info(f&quot;Processing image: {image.size[0]}x{image.size[1]} pixels, mode: {image.mode}&quot;)&#10;&#10;        # Set TESSDATA_PREFIX if not already set (for Heroku compatibility)&#10;        if 'TESSDATA_PREFIX' not in os.environ:&#10;            possible_paths = [&#10;                '/usr/share/tesseract-ocr/5/tessdata',&#10;                '/usr/share/tesseract-ocr/tessdata',&#10;                '/usr/share/tessdata',&#10;                '/app/.apt/usr/share/tesseract-ocr/5/tessdata',&#10;                '/app/.apt/usr/share/tesseract-ocr/tessdata'&#10;            ]&#10;            for path in possible_paths:&#10;                if os.path.exists(path):&#10;                    os.environ['TESSDATA_PREFIX'] = path&#10;                    logger.info(f&quot;Set TESSDATA_PREFIX to: {path}&quot;)&#10;                    break&#10;            else:&#10;                logger.warning(&quot;Could not find tessdata directory in any expected location&quot;)&#10;&#10;        # Try multiple OCR configurations for better compatibility&#10;        configs_to_try = [&#10;            r'--oem 1 --psm 1 -l eng',   # Automatic page segmentation with OSD&#10;            r'--oem 1 --psm 3 -l eng',   # Fully automatic page segmentation, but no OSD&#10;            r'--oem 1 --psm 4 -l eng',   # Assume a single column of text of variable sizes&#10;            r'--oem 1 --psm 6 -l eng',   # Assume a single uniform block of text&#10;            r'--oem 3 --psm 1 -l eng',   # LSTM with automatic page segmentation&#10;            r'--oem 3 --psm 3 -l eng',   # LSTM with fully automatic page segmentation&#10;            r'--oem 3 --psm 6 -l eng',   # LSTM standard config&#10;            r'--oem 3 --psm 11 -l eng',  # Sparse text - find as much text as possible&#10;            r'--oem 3 --psm 12 -l eng',  # Sparse text with OSD&#10;            r'--psm 6',                  # No language specified fallback&#10;        ]&#10;&#10;        extracted_text = &quot;&quot;&#10;        best_text = &quot;&quot;&#10;        best_char_count = 0&#10;        last_error = None&#10;&#10;        for config in configs_to_try:&#10;            try:&#10;                logger.info(f&quot;Trying OCR with config: {config}&quot;)&#10;                current_text = pytesseract.image_to_string(image, config=config)&#10;                current_text = current_text.strip()&#10;                char_count = len(current_text)&#10;&#10;                # Keep track of the best result (most text that looks reasonable)&#10;                if char_count &gt; best_char_count:&#10;                    # Basic heuristic: prefer results with more alphanumeric content&#10;                    alphanumeric_ratio = sum(c.isalnum() or c.isspace() for c in current_text) / max(len(current_text), 1)&#10;                    if alphanumeric_ratio &gt; 0.3:  # At least 30% should be readable characters&#10;                        best_text = current_text&#10;                        best_char_count = char_count&#10;                        logger.info(f&quot;New best result: {char_count} chars, {alphanumeric_ratio:.2f} alphanumeric ratio&quot;)&#10;&#10;                # If we got a decent amount of readable text, we can stop&#10;                if char_count &gt; 50 and best_text:&#10;                    extracted_text = best_text&#10;                    break&#10;&#10;            except Exception as e:&#10;                last_error = str(e)&#10;                logger.warning(f&quot;OCR config failed: {config}, error: {str(e)}&quot;)&#10;                continue&#10;&#10;        # Use the best result we found&#10;        if not extracted_text and best_text:&#10;            extracted_text = best_text&#10;&#10;        # Clean up the extracted text&#10;        extracted_text = extracted_text.strip()&#10;        char_count = len(extracted_text)&#10;&#10;        if char_count == 0:&#10;            error_msg = f&quot;No text found in image - image may be blank or contain no readable text. Last OCR error: {last_error}&quot;&#10;            return &quot;&quot;, 1, 0, error_msg&#10;&#10;        logger.info(f&quot;OCR extracted {char_count} characters from image {filename}&quot;)&#10;        return extracted_text, 1, char_count, None&#10;&#10;    except Exception as e:&#10;        error_msg = f&quot;Failed to extract text from image: {str(e)}&quot;&#10;        logger.error(error_msg)&#10;        return &quot;&quot;, 0, 0, error_msg&#10;&#10;&#10;def is_image_file(filename: str, mime_type: str = &quot;&quot;) -&gt; bool:&#10;    &quot;&quot;&quot;Check if file is a supported image format.&quot;&quot;&quot;&#10;    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.tif', '.webp'}&#10;    image_mime_types = {&#10;        'image/jpeg', 'image/jpg', 'image/png', 'image/gif',&#10;        'image/bmp', 'image/tiff', 'image/webp'&#10;    }&#10;&#10;    # Check by file extension&#10;    if filename:&#10;        ext = os.path.splitext(filename.lower())[1]&#10;        if ext in image_extensions:&#10;            return True&#10;&#10;    # Check by MIME type&#10;    if mime_type and mime_type.lower() in image_mime_types:&#10;        return True&#10;&#10;    return False&#10;&#10;&#10;def is_pdf_file(filename: str, mime_type: str = &quot;&quot;) -&gt; bool:&#10;    &quot;&quot;&quot;Check if file is a PDF.&quot;&quot;&quot;&#10;    if filename and filename.lower().endswith('.pdf'):&#10;        return True&#10;    if mime_type and mime_type.lower() == 'application/pdf':&#10;        return True&#10;    return False&#10;&#10;&#10;@app.route('/health', methods=['GET'])&#10;def health_check():&#10;    &quot;&quot;&quot;Health check endpoint.&quot;&quot;&quot;&#10;    return jsonify({'status': 'healthy'}), 200&#10;&#10;&#10;@app.route('/debug/env', methods=['GET'])&#10;def debug_env():&#10;    &quot;&quot;&quot;Return presence of critical env vars (gated by DOC_EXTRACT_WEBHOOK_SECRET).&#10;&#10;    This does NOT return any secret values, only boolean flags indicating whether each&#10;    required configuration item is set. Intended for quick diagnostics on deployed app.&#10;    &quot;&quot;&quot;&#10;    secret = request.headers.get('X-Webhook-Secret')&#10;    if not secret or secret != DOC_EXTRACT_WEBHOOK_SECRET:&#10;        logger.warning(&quot;Unauthorized request to /debug/env&quot;)&#10;        return jsonify({'error': 'Unauthorized'}), 401&#10;&#10;    keys = [&#10;        'SUPABASE_URL', 'SUPABASE_SERVICE_ROLE_KEY', 'DOC_EXTRACT_WEBHOOK_SECRET',&#10;        'SMTP_HOST', 'SMTP_PORT', 'SMTP_USER', 'SMTP_PASS', 'SMTP_FROM', 'SMTP_SENDER_WEBHOOK_SECRET'&#10;    ]&#10;    presence = {k: bool(os.environ.get(k)) for k in keys}&#10;    logger.info(f&quot;/debug/env requested; presence: { {k: presence[k] for k in presence} }&quot;)&#10;    return jsonify({'env_presence': presence}), 200&#10;&#10;@app.route('/webhooks/doc-extract', methods=['POST'])&#10;def doc_extract_webhook():&#10;    &quot;&quot;&quot;Main webhook endpoint for document extraction.&quot;&quot;&quot;&#10;    # Validate webhook secret&#10;    webhook_secret = request.headers.get('X-Webhook-Secret')&#10;    if not webhook_secret or webhook_secret != DOC_EXTRACT_WEBHOOK_SECRET:&#10;        logger.warning(&quot;Invalid or missing webhook secret&quot;)&#10;        return jsonify({'error': 'Unauthorized'}), 401&#10;&#10;    document_id = None&#10;    token = None&#10;&#10;    try:&#10;        # Parse JSON body&#10;        data = request.get_json()&#10;        if not data:&#10;            return jsonify({'error': 'Invalid JSON body'}), 400&#10;&#10;        # Validate required fields&#10;        required_fields = ['token', 'document_id', 'bucket', 'path']&#10;        missing_fields = [field for field in required_fields if not data.get(field)]&#10;        if missing_fields:&#10;            return jsonify({&#10;                'error': f'Missing required fields: {&quot;, &quot;.join(missing_fields)}'&#10;            }), 400&#10;&#10;        token = data['token']&#10;        document_id = data['document_id']&#10;        bucket = data['bucket']&#10;        path = data['path']&#10;        filename = data.get('filename', '') or ''  # Handle null values&#10;        mime_type = data.get('mime_type', '') or ''  # Handle null values&#10;&#10;        logger.info(f&quot;Processing document extraction - ID: {document_id}, Token: {token[:8]}...&quot;)&#10;        logger.info(f&quot;Raw payload data - filename: {repr(filename)}, mime_type: {repr(mime_type)}, path: {path}&quot;)&#10;&#10;        # Check if document is already processed&#10;        current_doc = fetch_document_status(document_id)&#10;        if current_doc and current_doc.get('status') == 'ready':&#10;            logger.info(f&quot;Document {document_id} already processed&quot;)&#10;            return jsonify({&#10;                'message': 'Document already processed',&#10;                'document_id': document_id,&#10;                'status': 'ready'&#10;            }), 200&#10;&#10;        # Mark document as processing&#10;        if not update_document(document_id, token, {'status': 'processing'}):&#10;            return jsonify({&#10;                'error': 'Failed to update document status to processing',&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        # Download file from Supabase Storage&#10;        file_bytes = download_storage_object(bucket, path)&#10;        if file_bytes is None:&#10;            error_msg = f&quot;Failed to download file from {bucket}/{path}&quot;&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': error_msg[:2000]&#10;            })&#10;            return jsonify({&#10;                'error': error_msg,&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        # Determine file type with multiple fallback strategies&#10;        logger.info(f&quot;Initial file detection - filename: '{filename}', mime_type: '{mime_type}'&quot;)&#10;&#10;        # Strategy 1: If filename is empty/null, extract from path&#10;        if not filename or filename.lower() == 'null':&#10;            filename = os.path.basename(path)&#10;            logger.info(f&quot;Extracted filename from path: '{filename}'&quot;)&#10;&#10;        # Strategy 2: If mime_type is empty/null, guess from filename&#10;        if not mime_type or mime_type.lower() == 'null':&#10;            if filename:&#10;                ext = os.path.splitext(filename.lower())[1]&#10;                mime_type_map = {&#10;                    '.pdf': 'application/pdf',&#10;                    '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg',&#10;                    '.png': 'image/png', '.gif': 'image/gif',&#10;                    '.bmp': 'image/bmp', '.tiff': 'image/tiff', '.tif': 'image/tiff',&#10;                    '.webp': 'image/webp'&#10;                }&#10;                mime_type = mime_type_map.get(ext, '')&#10;                logger.info(f&quot;Guessed MIME type from extension '{ext}': '{mime_type}'&quot;)&#10;&#10;        # Strategy 3: If still no filename, try extracting just the filename from the full path&#10;        if not filename:&#10;            # Handle paths like &quot;dmhoa-docs/case_xxx/original/image.jpg&quot;&#10;            path_parts = path.split('/')&#10;            if path_parts:&#10;                filename = path_parts[-1]  # Get the last part&#10;                logger.info(f&quot;Extracted filename from path parts: '{filename}'&quot;)&#10;&#10;        # Strategy 4: If we still have no clear type, try to detect from file content&#10;        detected_type = None&#10;        if not (is_pdf_file(filename, mime_type) or is_image_file(filename, mime_type)):&#10;            # Check file magic bytes as last resort&#10;            if file_bytes and len(file_bytes) &gt;= 4:&#10;                # PDF magic bytes&#10;                if file_bytes.startswith(b'%PDF'):&#10;                    detected_type = 'pdf'&#10;                    logger.info(&quot;Detected PDF from file magic bytes&quot;)&#10;                # JPEG magic bytes&#10;                elif file_bytes.startswith(b'\xff\xd8\xff'):&#10;                    detected_type = 'image'&#10;                    mime_type = 'image/jpeg'&#10;                    logger.info(&quot;Detected JPEG from file magic bytes&quot;)&#10;                # PNG magic bytes&#10;                elif file_bytes.startswith(b'\x89PNG'):&#10;                    detected_type = 'image'&#10;                    mime_type = 'image/png'&#10;                    logger.info(&quot;Detected PNG from file magic bytes&quot;)&#10;&#10;        logger.info(f&quot;Final file detection - filename: '{filename}', mime_type: '{mime_type}', detected_type: {detected_type}&quot;)&#10;&#10;        # Process based on detected file type&#10;        if is_pdf_file(filename, mime_type) or detected_type == 'pdf':&#10;            logger.info(f&quot;Processing as PDF: {filename}&quot;)&#10;            extracted_text, page_count, char_count, extraction_error = extract_pdf_text(file_bytes)&#10;        elif is_image_file(filename, mime_type) or detected_type == 'image':&#10;            logger.info(f&quot;Processing as image using OCR: {filename}&quot;)&#10;            extracted_text, page_count, char_count, extraction_error = extract_image_text(file_bytes, filename)&#10;        else:&#10;            error_msg = f&quot;Unsupported file type: filename='{filename}', mime_type='{mime_type}', path='{path}'. Supported formats: PDF, JPG, JPEG, PNG, GIF, BMP, TIFF, WEBP&quot;&#10;            logger.warning(error_msg)&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': error_msg[:2000]&#10;            })&#10;            return jsonify({&#10;                'error': error_msg,&#10;                'document_id': document_id&#10;            }, 400)&#10;&#10;        if extraction_error:&#10;            # Handle extraction failure&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': extraction_error[:2000],&#10;                'page_count': page_count&#10;            })&#10;            return jsonify({&#10;                'error': extraction_error,&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        if char_count == 0:&#10;            # Handle no text found case&#10;            error_msg = &quot;No text found in document - document may be blank or contain no readable text&quot;&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': error_msg,&#10;                'page_count': page_count,&#10;                'char_count': 0&#10;            })&#10;            return jsonify({&#10;                'error': error_msg,&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        # Update document with extracted text&#10;        success = update_document(document_id, token, {&#10;            'status': 'ready',&#10;            'extracted_text': extracted_text,&#10;            'page_count': page_count,&#10;            'char_count': char_count,&#10;            'error': None&#10;        })&#10;&#10;        if not success:&#10;            return jsonify({&#10;                'error': 'Failed to update document with extracted text',&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        file_type = &quot;PDF&quot; if is_pdf_file(filename, mime_type) else &quot;image&quot;&#10;        logger.info(f&quot;Successfully processed {file_type} document {document_id} - {page_count} pages, {char_count} characters&quot;)&#10;&#10;        return jsonify({&#10;            'message': f'{file_type} document processed successfully',&#10;            'document_id': document_id,&#10;            'status': 'ready',&#10;            'page_count': page_count,&#10;            'char_count': char_count,&#10;            'file_type': file_type.lower()&#10;        }), 200&#10;&#10;    except Exception as e:&#10;        error_msg = str(e)[:2000]  # Truncate error message&#10;        logger.error(f&quot;Unexpected error processing document: {error_msg}&quot;)&#10;&#10;        # Try to update document status to failed if we have the required data&#10;        if document_id and token:&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': error_msg&#10;            })&#10;            return jsonify({&#10;                'error': error_msg,&#10;                'document_id': document_id&#10;            }), 500&#10;        else:&#10;            return jsonify({'error': error_msg}), 500&#10;&#10;@app.route(&quot;/webhooks/send-receipt-email&quot;, methods=[&quot;POST&quot;])&#10;def send_receipt_email():&#10;    secret = request.headers.get(&quot;X-Webhook-Secret&quot;)&#10;    logger.info(&quot;Received send-receipt-email webhook&quot;)&#10;&#10;    if not secret or secret != SMTP_SENDER_WEBHOOK_SECRET:&#10;        logger.warning(&quot;Unauthorized send-receipt-email attempt: missing or invalid webhook secret&quot;)&#10;        return jsonify({&quot;error&quot;: &quot;Unauthorized&quot;}), 401&#10;&#10;    # Check which SMTP environment variables are missing so we can diagnose quickly&#10;    required = {&#10;        'SMTP_HOST': SMTP_HOST,&#10;        'SMTP_PORT': SMTP_PORT,&#10;        'SMTP_USER': SMTP_USER,&#10;        'SMTP_PASS': SMTP_PASS,&#10;        'SMTP_SENDER_WEBHOOK_SECRET': SMTP_SENDER_WEBHOOK_SECRET,&#10;    }&#10;    missing = [name for name, val in required.items() if not val]&#10;    if missing:&#10;        # Log the missing variable names (not their values) for diagnostics&#10;        logger.error(f&quot;SMTP not configured - missing environment variables: {missing}&quot;)&#10;        return jsonify({&quot;error&quot;: &quot;SMTP not configured&quot;, &quot;missing&quot;: missing}), 500&#10;&#10;    data = request.get_json() or {}&#10;    token = data.get(&quot;token&quot;)&#10;    to_email = data.get(&quot;email&quot;)&#10;    case_url = data.get(&quot;case_url&quot;)&#10;    amount_total = data.get(&quot;amount_total&quot;)&#10;    currency = (data.get(&quot;currency&quot;) or &quot;usd&quot;).upper()&#10;    customer_name = data.get(&quot;customer_name&quot;)&#10;    stripe_session_id = data.get(&quot;stripe_session_id&quot;)&#10;&#10;    logger.info(f&quot;send-receipt-email payload: token_present={bool(token)}, to_email={to_email}, case_url_present={bool(case_url)}, customer_name={customer_name}&quot;)&#10;&#10;    if not token or not to_email or not case_url:&#10;        logger.warning(&quot;send-receipt-email missing required fields&quot;)&#10;        return jsonify({&quot;error&quot;: &quot;Missing token/email/case_url&quot;}), 400&#10;&#10;    # Personalized greeting&#10;    greeting = f&quot;Hi {customer_name},&quot; if customer_name else &quot;Hi,&quot;&#10;&#10;    # Format payment amount&#10;    dollars = f&quot;${(amount_total or 0)/100:.2f}&quot; if isinstance(amount_total, int) else &quot;&quot;&#10;    payment_info = f&quot; for {dollars} {currency}&quot; if dollars else &quot;&quot;&#10;&#10;    # Enhanced email content&#10;    subject = &quot;Payment Confirmed - Your Dispute My HOA Case is Ready&quot;&#10;&#10;    text = f&quot;&quot;&quot;{greeting}&#10;&#10;Thank you for your payment{payment_info}! Your payment has been successfully processed and your Dispute My HOA case is now unlocked and ready for access.&#10;&#10; ACCESS YOUR CASE:&#10;{case_url}&#10;&#10; IMPORTANT: Please save this email for your records. You can use the link above to access your case anytime in the future.&#10;&#10; WHAT'S NEXT:&#10;• Review your case documents and analysis&#10;• Use the AI-powered insights to understand your dispute&#10;• Access legal templates and guidance specific to your situation&#10;• Get step-by-step instructions for resolving your HOA dispute&#10;&#10; NEED HELP?&#10;If you have any questions or need assistance accessing your case, simply reply to this email and we'll get back to you promptly.&#10;&#10;Your case token for reference: {token[:8]}...&#10;{f'Transaction ID: {stripe_session_id}' if stripe_session_id else ''}&#10;&#10;Best regards,&#10;The Dispute My HOA Team&#10;https://disputemyhoa.com&#10;&#10;---&#10;This email confirms your payment and provides access to your case. Keep this email safe for future reference.&quot;&quot;&quot;&#10;&#10;    msg = MIMEMultipart()&#10;    msg[&quot;From&quot;] = SMTP_FROM&#10;    msg[&quot;To&quot;] = to_email&#10;    msg[&quot;Subject&quot;] = subject&#10;    msg.attach(MIMEText(text, &quot;plain&quot;))&#10;&#10;    try:&#10;        logger.info(f&quot;Connecting to SMTP {SMTP_HOST}:{SMTP_PORT} to send to {to_email}&quot;)&#10;        logger.info(f&quot;SMTP_USER after cleaning: '{SMTP_USER}' (length: {len(SMTP_USER)})&quot;)&#10;        logger.info(f&quot;SMTP_PASS after cleaning: length={len(SMTP_PASS)}, starts_with='{SMTP_PASS[:4]}...'&quot;)&#10;&#10;        with smtplib.SMTP(SMTP_HOST, SMTP_PORT, timeout=20) as server:&#10;            server.ehlo()&#10;            server.starttls()&#10;            server.ehlo()&#10;            server.login(SMTP_USER, SMTP_PASS)&#10;            server.sendmail(SMTP_FROM, [to_email], msg.as_string())&#10;&#10;        logger.info(f&quot;Receipt email sent to {to_email} (token={token[:8]}...&quot; )&#10;        return jsonify({&quot;ok&quot;: True}), 200&#10;&#10;    except smtplib.SMTPAuthenticationError as e:&#10;        error_msg = f&quot;Gmail authentication failed. For Gmail, you need: 1) Enable 2-Step Verification, 2) Create App Password. Error: {str(e)}&quot;&#10;        logger.error(error_msg)&#10;        return jsonify({&quot;ok&quot;: False, &quot;error&quot;: error_msg}), 500&#10;    except Exception as e:&#10;        # Log full exception with traceback to help diagnose mail failures&#10;        logger.exception(&quot;Failed to send receipt email&quot;)&#10;        return jsonify({&quot;ok&quot;: False, &quot;error&quot;: str(e)}), 500&#10;&#10;&#10;def preview_env(name: str, value: str) -&gt; Dict[str, Any]:&#10;    &quot;&quot;&quot;Helper: safely preview env values without leaking secrets&quot;&quot;&quot;&#10;    if not value:&#10;        return {'name': name, 'present': False, 'preview': None, 'length': 0}&#10;&#10;    lower = name.lower()&#10;    is_secret = (&#10;        'secret' in lower or&#10;        'service_role' in lower or&#10;        'key' in lower&#10;    )&#10;&#10;    preview = f&quot;{value[:6]}…({len(value)})&quot; if is_secret else f&quot;{value[:24]}{'…' if len(value) &gt; 24 else ''}&quot;&#10;&#10;    return {'name': name, 'present': True, 'preview': preview, 'length': len(value)}&#10;&#10;def extract_structured_result(responses_json: Any) -&gt; Optional[Dict[str, Any]]:&#10;    &quot;&quot;&quot;Safer JSON extraction from OpenAI Responses API payload&quot;&quot;&quot;&#10;    output = responses_json.get('output') if responses_json else None&#10;&#10;    if isinstance(output, list) and len(output) &gt; 0:&#10;        for item in output:&#10;            content = item.get('content') if item else None&#10;&#10;            if isinstance(content, list):&#10;                # Look for output_json type first&#10;                cj = next((c for c in content&#10;                          if c and c.get('type') == 'output_json' and c.get('json')), None)&#10;                if not cj:&#10;                    # Fallback to any content with json&#10;                    cj = next((c for c in content&#10;                              if c and c.get('json') and isinstance(c['json'], dict)), None)&#10;&#10;                if cj and cj.get('json') and isinstance(cj['json'], dict):&#10;                    return cj['json']&#10;&#10;                # Look for text content to parse as JSON&#10;                ct = next((c for c in content&#10;                          if c and c.get('type') == 'output_text' and isinstance(c.get('text'), str)), None)&#10;                if not ct:&#10;                    ct = next((c for c in content&#10;                              if c and isinstance(c.get('text'), str)), None)&#10;&#10;                if ct and ct.get('text'):&#10;                    try:&#10;                        parsed = json.loads(ct['text'])&#10;                        if parsed and isinstance(parsed, dict):&#10;                            return parsed&#10;                    except Exception:&#10;                        pass  # ignore parse errors&#10;&#10;    return None&#10;&#10;&#10;def get_draft_titles(payload: Dict[str, Any]) -&gt; Dict[str, str]:&#10;    &quot;&quot;&quot;&#10;    Keeps DB keys stable (drafts.clarification/extension/compliance),&#10;    but changes what those &quot;slots&quot; mean based on the user's selection.&#10;    &quot;&quot;&quot;&#10;    outcome = str(payload.get('outcome', '')).lower()&#10;&#10;    titles = {&#10;        'clarification': 'Request Clarification / Rule Citation',&#10;        'extension': 'Request Extension / Pause Enforcement',&#10;        'compliance': 'Confirm Compliance Plan'&#10;    }&#10;&#10;    if outcome == 'clarification':&#10;        titles = {&#10;            'clarification': 'Request Clarification / Rule Citation',&#10;            'extension': 'Request Extension While Clarifying',&#10;            'compliance': 'Confirm Compliance Plan (If Needed)'&#10;        }&#10;    elif outcome == 'extension':&#10;        titles = {&#10;            'clarification': 'Request Clarification + Confirm Requirements',&#10;            'extension': 'Request Extension / New Deadline',&#10;            'compliance': 'Confirm Compliance Plan + Timeline'&#10;        }&#10;    elif outcome == 'alternative':&#10;        titles = {&#10;            'clarification': 'Request Approved Options / Standards',&#10;            'extension': 'Request Temporary Variance / Extra Time',&#10;            'compliance': 'Propose Alternative Remedy Plan'&#10;        }&#10;    elif outcome == 'comply':&#10;        titles = {&#10;            'clarification': 'Confirm Requirements Before Starting Work',&#10;            'extension': 'Request Extra Time to Complete Work',&#10;            'compliance': 'Confirm Compliance Completion'&#10;        }&#10;    elif outcome == 'dispute':&#10;        titles = {&#10;            'clarification': 'Formal Dispute / Appeal Letter',&#10;            'extension': 'Request Hearing Extension / Reschedule',&#10;            'compliance': 'Evidence Submission Cover Letter'&#10;        }&#10;    elif outcome == 'not-sure':&#10;        titles = {&#10;            'clarification': 'Request Clarification / Rule Citation',&#10;            'extension': 'Request Extension to Evaluate Options',&#10;            'compliance': 'Provisional Compliance Plan (If Required)'&#10;        }&#10;&#10;    return titles&#10;&#10;&#10;def safe_iso(s: Any) -&gt; Optional[str]:&#10;    &quot;&quot;&quot;Convert value to ISO string safely&quot;&quot;&quot;&#10;    v = str(s or '').strip()&#10;    if not v:&#10;        return None&#10;    try:&#10;        d = datetime.fromisoformat(v.replace('Z', '+00:00'))&#10;        return d.isoformat()&#10;    except Exception:&#10;        try:&#10;            d = datetime.strptime(v, '%Y-%m-%d %H:%M:%S')&#10;            return d.isoformat()&#10;        except Exception:&#10;            return None&#10;&#10;&#10;def newest_updated_at(docs: List[Dict[str, Any]]) -&gt; Optional[str]:&#10;    &quot;&quot;&quot;Find the newest updated_at timestamp from documents&quot;&quot;&quot;&#10;    newest = None&#10;    for d in docs:&#10;        iso = safe_iso(d.get('updated_at'))&#10;        if not iso:&#10;            continue&#10;        if not newest or datetime.fromisoformat(iso) &gt; datetime.fromisoformat(newest):&#10;            newest = iso&#10;    return newest&#10;&#10;&#10;@app.route('/api/create-checkout-session', methods=['POST', 'OPTIONS'])&#10;def create_checkout_session():&#10;    &quot;&quot;&quot;Create Stripe checkout session endpoint (converted from Supabase edge function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    logger.info('[create-checkout-session] request', extra={&#10;        'method': request.method,&#10;        'url': request.url,&#10;        'has_auth_header': bool(request.headers.get('authorization')),&#10;        'has_apikey_header': bool(request.headers.get('apikey')),&#10;        'origin': request.headers.get('origin')&#10;    })&#10;&#10;    try:&#10;        # Environment variables validation&#10;        env_report = [&#10;            preview_env('STRIPE_SECRET_KEY', STRIPE_SECRET_KEY or ''),&#10;            preview_env('STRIPE_PRICE_ID', STRIPE_PRICE_ID or ''),&#10;            preview_env('SITE_URL', SITE_URL),&#10;            preview_env('SUPABASE_URL', SUPABASE_URL or ''),&#10;            preview_env('SUPABASE_SERVICE_ROLE_KEY', SUPABASE_SERVICE_ROLE_KEY or ''),&#10;        ]&#10;        logger.info('[create-checkout-session] env report', extra={'env_report': env_report})&#10;&#10;        missing = [v['name'] for v in env_report if not v['present']]&#10;        if missing:&#10;            logger.error('[create-checkout-session] missing env vars', extra={'missing': missing})&#10;            response = jsonify({'error': 'Missing required environment variables', 'missing': missing})&#10;            return add_cors_headers(response), 500&#10;&#10;        logger.info('[create-checkout-session] initializing clients')&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = body.get('token')&#10;        email = body.get('email')&#10;        payload = body.get('payload')&#10;&#10;        logger.info('[create-checkout-session] parsed body', extra={&#10;            'has_token': bool(token),&#10;            'token_preview': f&quot;{token[:12]}…&quot; if isinstance(token, str) else None,&#10;            'has_email': bool(email),&#10;            'email_domain': email.split('@')[1] if isinstance(email, str) and '@' in email else None,&#10;            'has_payload': bool(payload)&#10;        })&#10;&#10;        if not token or not email:&#10;            response = jsonify({'error': 'Token and email are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Validate email format&#10;        email_regex = re.compile(r'^[^\s@]+@[^\s@]+\.[^\s@]+$')&#10;        if not email_regex.match(email):&#10;            response = jsonify({'error': 'Invalid email format'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # 1) Fetch case (it may not exist yet — that's OK)&#10;        logger.info('[create-checkout-session] fetching case', extra={'token_preview': f&quot;{token[:12]}…&quot;})&#10;&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,status,stripe_checkout_session_id'&#10;        }&#10;        headers = supabase_headers()&#10;&#10;        try:&#10;            response_data = requests.get(url, params=params, headers=headers, timeout=TIMEOUT)&#10;            response_data.raise_for_status()&#10;            cases = response_data.json()&#10;            existing_case = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('[create-checkout-session] database fetch error', extra={&#10;                'message': str(e)&#10;            })&#10;            response = jsonify({'error': 'Database error'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 2) Create case if missing&#10;        if not existing_case:&#10;            logger.warning('[create-checkout-session] case not found, creating new case',&#10;                         extra={'token_preview': f&quot;{token[:12]}…&quot;})&#10;&#10;            insert_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            insert_data = {&#10;                'token': token,&#10;                'email': email,&#10;                'status': 'pending_payment',&#10;                'unlocked': False,&#10;                'payload': payload,&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            insert_headers = supabase_headers()&#10;            insert_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_response = requests.post(insert_url, headers=insert_headers,&#10;                                              json=insert_data, timeout=TIMEOUT)&#10;                insert_response.raise_for_status()&#10;            except Exception as e:&#10;                logger.error('[create-checkout-session] failed to create case', extra={&#10;                    'message': str(e)&#10;                })&#10;                response = jsonify({'error': 'Failed to create case'})&#10;                return add_cors_headers(response), 500&#10;        else:&#10;            logger.info('[create-checkout-session] case found', extra={&#10;                'status': existing_case.get('status'),&#10;                'has_existing_session': bool(existing_case.get('stripe_checkout_session_id'))&#10;            })&#10;&#10;            # Update existing case&#10;            logger.info('[create-checkout-session] updating case status -&gt; pending_payment')&#10;            update_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            update_params = {'token': f'eq.{token}'}&#10;            update_data = {&#10;                'email': email,&#10;                'payload': payload,&#10;                'status': 'pending_payment',&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            update_headers = supabase_headers()&#10;&#10;            try:&#10;                update_response = requests.patch(update_url, params=update_params,&#10;                                               headers=update_headers, json=update_data, timeout=TIMEOUT)&#10;                update_response.raise_for_status()&#10;            except Exception as e:&#10;                logger.error('[create-checkout-session] database update error', extra={&#10;                    'message': str(e)&#10;                })&#10;                response = jsonify({'error': 'Failed to update case'})&#10;                return add_cors_headers(response), 500&#10;&#10;        # 3) Create Stripe Checkout Session&#10;        logger.info('[create-checkout-session] creating stripe checkout session', extra={&#10;            'price_id': STRIPE_PRICE_ID,&#10;            'site_url': SITE_URL,&#10;            'expires_in_minutes': 30&#10;        })&#10;&#10;        try:&#10;            session = stripe.checkout.Session.create(&#10;                mode='payment',&#10;                line_items=[{'price': STRIPE_PRICE_ID, 'quantity': 1}],&#10;                success_url=f&quot;{SITE_URL}/case.html?case={token}&amp;session_id={{CHECKOUT_SESSION_ID}}&quot;,&#10;                cancel_url=f&quot;{SITE_URL}/case-preview.html?case={token}&quot;,&#10;                client_reference_id=token,&#10;                customer_email=email,&#10;                metadata={'token': token, 'source': 'dispute-my-hoa'},&#10;                expires_at=int(datetime.utcnow().timestamp()) + (30 * 60)  # 30 minutes&#10;            )&#10;        except Exception as e:&#10;            logger.error('[create-checkout-session] stripe session creation failed', extra={&#10;                'message': str(e)&#10;            })&#10;            response = jsonify({'error': f'Stripe error: {str(e)}'})&#10;            return add_cors_headers(response), 500&#10;&#10;        logger.info('[create-checkout-session] stripe session created', extra={&#10;            'session_id': session.id,&#10;            'has_url': bool(session.url),&#10;            'amount_total': session.amount_total,&#10;            'currency': session.currency&#10;        })&#10;&#10;        # 4) Save session id on the case&#10;        save_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        save_params = {'token': f'eq.{token}'}&#10;        save_data = {&#10;            'stripe_checkout_session_id': session.id,&#10;            'updated_at': datetime.utcnow().isoformat()&#10;        }&#10;        save_headers = supabase_headers()&#10;&#10;        try:&#10;            save_response = requests.patch(save_url, params=save_params,&#10;                                         headers=save_headers, json=save_data, timeout=TIMEOUT)&#10;            save_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.warning('[create-checkout-session] failed saving stripe session id (non-fatal)', extra={&#10;                'message': str(e)&#10;            })&#10;&#10;        # 5) Log event (non-fatal)&#10;        event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;        event_data = {&#10;            'token': token,&#10;            'type': 'checkout_session_created',&#10;            'data': {&#10;                'session_id': session.id,&#10;                'email_domain': email.split('@')[1] if '@' in email else None,&#10;                'amount': session.amount_total,&#10;                'currency': session.currency&#10;            }&#10;        }&#10;        event_headers = supabase_headers()&#10;&#10;        try:&#10;            event_response = requests.post(event_url, headers=event_headers,&#10;                                         json=event_data, timeout=TIMEOUT)&#10;            event_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.warning('[create-checkout-session] failed to insert dmhoa_events (non-fatal)', extra={&#10;                'message': str(e)&#10;            })&#10;&#10;        response = jsonify({'url': session.url})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('[create-checkout-session] error', extra={&#10;            'message': str(e),&#10;            'name': type(e).__name__&#10;        })&#10;        response = jsonify({'error': str(e) or 'Internal server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/store-message', methods=['POST', 'OPTIONS'])&#10;def store_message():&#10;    &quot;&quot;&quot;Store chat message endpoint (converted from Supabase edge function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        origin = request.headers.get('Origin')&#10;        allowed_origins = [&#10;            'https://disputemyhoa.com',&#10;            'https://dmhoadev.netlify.app',&#10;            'http://localhost:5173',&#10;            'http://localhost:3000',&#10;            'http://127.0.0.1:5173'&#10;        ]&#10;        if origin in allowed_origins:&#10;            response.headers.add('Access-Control-Allow-Origin', origin)&#10;        else:&#10;            response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        origin = request.headers.get('Origin')&#10;        allowed_origins = [&#10;            'https://disputemyhoa.com',&#10;            'https://dmhoadev.netlify.app',&#10;            'http://localhost:5173',&#10;            'http://localhost:3000',&#10;            'http://127.0.0.1:5173'&#10;        ]&#10;        if origin in allowed_origins:&#10;            response.headers.add('Access-Control-Allow-Origin', origin)&#10;        else:&#10;            response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = (body.get('token') or '').strip()&#10;        role = (body.get('role') or '').strip()&#10;        content = (body.get('content') or '').strip()&#10;&#10;        if not token or not role or not content:&#10;            response = jsonify({'error': 'token, role, content are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        if role not in ['user', 'assistant', 'system']:&#10;            response = jsonify({'error': 'invalid role'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Check if case is unlocked&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'unlocked'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Failed to fetch case for unlock check', extra={'error': str(e)})&#10;            response = jsonify({'error': 'DB fetch failed', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row or not case_row.get('unlocked'):&#10;            response = jsonify({'error': 'Case is not unlocked'})&#10;            return add_cors_headers(response), 402&#10;&#10;        # Insert message into dmhoa_messages&#10;        message_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        message_data = {&#10;            'token': token,&#10;            'role': role,&#10;            'content': content&#10;        }&#10;        message_headers = supabase_headers()&#10;        message_headers['Prefer'] = 'return=representation'&#10;&#10;        try:&#10;            message_response = requests.post(message_url, headers=message_headers,&#10;                                           json=message_data, timeout=TIMEOUT)&#10;            message_response.raise_for_status()&#10;            inserted_message = message_response.json()&#10;        except Exception as e:&#10;            logger.error('Failed to insert message', extra={'error': str(e)})&#10;            response = jsonify({'error': 'DB insert failed', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Return the inserted message data&#10;        message_data = inserted_message[0] if inserted_message else {}&#10;        response = jsonify({'ok': True, 'message': message_data})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('store-message error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/doc-extract-start', methods=['POST', 'OPTIONS'])&#10;def doc_extract_start():&#10;    &quot;&quot;&quot;Document extraction trigger endpoint (converted from Supabase edge function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    def safe_trim(v) -&gt; str:&#10;        return str(v or '').strip()&#10;&#10;    logger.info(f&quot;[{datetime.utcnow().isoformat()}] {request.method} {request.url}&quot;)&#10;&#10;    if request.method != 'POST':&#10;        response = jsonify({'error': 'Method not allowed'})&#10;        return add_cors_headers(response), 405&#10;&#10;    try:&#10;        # Environment variables check&#10;        WEBHOOK_URL = os.environ.get('DOC_EXTRACT_WEBHOOK_URL', f&quot;{request.url_root.rstrip('/')}/webhooks/doc-extract&quot;)&#10;        DOC_BUCKET = os.environ.get('DOC_EXTRACT_BUCKET', 'dmhoa-docs')&#10;&#10;        logger.info('Env check', extra={&#10;            'hasUrl': bool(SUPABASE_URL),&#10;            'hasServiceRole': bool(SUPABASE_SERVICE_ROLE_KEY),&#10;            'hasWebhookUrl': bool(WEBHOOK_URL),&#10;            'hasWebhookSecret': bool(DOC_EXTRACT_WEBHOOK_SECRET),&#10;            'bucket': DOC_BUCKET&#10;        })&#10;&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing SUPABASE env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not DOC_EXTRACT_WEBHOOK_SECRET:&#10;            response = jsonify({'error': 'Missing webhook env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Validate secret header (optional - commented out for now like in original)&#10;        # incoming_secret = request.headers.get('x-doc-secret', '').strip()&#10;        # if not incoming_secret or incoming_secret != 'dmhoa_9baf6a13e2f847d0b52f':&#10;        #     logger.error('Unauthorized - secret mismatch')&#10;        #     response = jsonify({'error': 'Unauthorized'})&#10;        #     return add_cors_headers(response), 401&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = safe_trim(body.get('token'))&#10;        storage_path = safe_trim(body.get('storage_path'))&#10;        filename = safe_trim(body.get('filename')) or None&#10;        mime_type = safe_trim(body.get('mime_type')) or None&#10;&#10;        if not token or not storage_path:&#10;            response = jsonify({'error': 'token and storage_path are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Ensure case exists (fail fast)&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,payload,created_at'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Case lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found', 'token': token})&#10;            return add_cors_headers(response), 404&#10;&#10;        # 1) Create (or reuse) a dmhoa_documents row for this file&#10;        document_id = None&#10;&#10;        # Check for existing document&#10;        doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        doc_params = {&#10;            'token': f'eq.{token}',&#10;            'path': f'eq.{storage_path}',&#10;            'select': 'id,status'&#10;        }&#10;        doc_headers = supabase_headers()&#10;&#10;        try:&#10;            doc_response = requests.get(doc_url, params=doc_params, headers=doc_headers, timeout=TIMEOUT)&#10;            doc_response.raise_for_status()&#10;            docs = doc_response.json()&#10;            existing_doc = docs[0] if docs else None&#10;        except Exception as e:&#10;            logger.error('Doc lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading document', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if existing_doc and existing_doc.get('id'):&#10;            document_id = existing_doc['id']&#10;            logger.info('Reusing existing dmhoa_documents row', extra={&#10;                'document_id': document_id,&#10;                'status': existing_doc.get('status')&#10;            })&#10;        else:&#10;            # Insert new document&#10;            insert_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            insert_doc_data = {&#10;                'token': token,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'filename': filename,&#10;                'mime_type': mime_type,&#10;                'status': 'pending'&#10;            }&#10;            insert_doc_headers = supabase_headers()&#10;            insert_doc_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_doc_response = requests.post(insert_doc_url, headers=insert_doc_headers,&#10;                                                  json=insert_doc_data, timeout=TIMEOUT)&#10;                insert_doc_response.raise_for_status()&#10;                inserted_docs = insert_doc_response.json()&#10;                document_id = inserted_docs[0]['id'] if inserted_docs else None&#10;                logger.info('Created dmhoa_documents row', extra={'document_id': document_id})&#10;            except Exception as e:&#10;                logger.error('Doc insert error', extra={'error': str(e)})&#10;                response = jsonify({'error': 'Failed to create dmhoa_documents row', 'details': str(e)})&#10;                return add_cors_headers(response), 500&#10;&#10;        if not document_id:&#10;            response = jsonify({'error': 'Could not determine document_id'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 2) Update case payload summary status (optional, but useful for UI)&#10;        current_payload = {}&#10;        try:&#10;            payload_data = case_row.get('payload')&#10;            if isinstance(payload_data, str):&#10;                current_payload = json.loads(payload_data)&#10;            elif isinstance(payload_data, dict):&#10;                current_payload = payload_data&#10;        except Exception:&#10;            current_payload = {}&#10;&#10;        next_payload = {&#10;            **current_payload,&#10;            'extract_status': 'triggered',&#10;            'notice_storage_path': storage_path,&#10;            'notice_filename': filename,&#10;            'notice_mime_type': mime_type,&#10;            'extract_triggered_at': datetime.utcnow().isoformat(),&#10;            'document_id': document_id&#10;        }&#10;&#10;        # Update case payload&#10;        update_case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        update_case_params = {'token': f'eq.{token}'}&#10;        update_case_data = {'payload': next_payload}&#10;        update_case_headers = supabase_headers()&#10;&#10;        try:&#10;            update_case_response = requests.patch(update_case_url, params=update_case_params,&#10;                                                headers=update_case_headers, json=update_case_data, timeout=TIMEOUT)&#10;            update_case_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Case payload update error', extra={'error': str(e)})&#10;            # Not fatal—doc record exists and webhook can still run&#10;&#10;        # 3) Mark document processing BEFORE webhook&#10;        mark_proc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        mark_proc_params = {'id': f'eq.{document_id}'}&#10;        mark_proc_data = {'status': 'processing', 'error': None}&#10;        mark_proc_headers = supabase_headers()&#10;&#10;        try:&#10;            mark_proc_response = requests.patch(mark_proc_url, params=mark_proc_params,&#10;                                              headers=mark_proc_headers, json=mark_proc_data, timeout=TIMEOUT)&#10;            mark_proc_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Failed to mark document processing', extra={'error': str(e)})&#10;            # Not fatal, but you'll want to know&#10;&#10;        # 4) Call backend webhook (server-to-server)&#10;        logger.info('Calling webhook', extra={'webhook_url': WEBHOOK_URL})&#10;&#10;        webhook_payload = {&#10;            'token': token,&#10;            'document_id': document_id,&#10;            'bucket': DOC_BUCKET,&#10;            'path': storage_path,&#10;            'filename': filename,&#10;            'mime_type': mime_type,&#10;            'supabase_url': SUPABASE_URL  # optional&#10;        }&#10;&#10;        webhook_headers = {&#10;            'Content-Type': 'application/json',&#10;            'X-Webhook-Secret': WEBHOOK_SECRET,&#10;            'X-Doc-Extract-Secret': WEBHOOK_SECRET  # Alternative header name&#10;        }&#10;&#10;        try:&#10;            webhook_response = requests.post(WEBHOOK_URL, headers=webhook_headers,&#10;                                           json=webhook_payload, timeout=(10, 120))  # Longer timeout for processing&#10;&#10;            logger.info('Webhook response', extra={'status': webhook_response.status_code, 'ok': webhook_response.ok})&#10;&#10;            if not webhook_response.ok:&#10;                error_text = webhook_response.text&#10;                logger.error('Webhook failed', extra={'error': error_text})&#10;&#10;                # Update document status to failed&#10;                fail_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;                fail_doc_params = {'id': f'eq.{document_id}'}&#10;                fail_doc_data = {&#10;                    'status': 'failed',&#10;                    'error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500]&#10;                }&#10;                fail_doc_headers = supabase_headers()&#10;&#10;                try:&#10;                    requests.patch(fail_doc_url, params=fail_doc_params,&#10;                                 headers=fail_doc_headers, json=fail_doc_data, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                # Also reflect summary status on the case payload (optional)&#10;                fail_payload = {&#10;                    **next_payload,&#10;                    'extract_status': 'failed',&#10;                    'extract_error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500],&#10;                    'extract_failed_at': datetime.utcnow().isoformat()&#10;                }&#10;&#10;                try:&#10;                    requests.patch(update_case_url, params=update_case_params,&#10;                                 headers=update_case_headers, json={'payload': fail_payload}, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                response = jsonify({&#10;                    'error': 'Webhook call failed',&#10;                    'status': webhook_response.status_code,&#10;                    'details': error_text&#10;                })&#10;                return add_cors_headers(response), 502&#10;&#10;            # If webhook returns JSON, capture it (optional)&#10;            try:&#10;                webhook_json = webhook_response.json()&#10;            except Exception:&#10;                webhook_json = {}&#10;&#10;            # Mark queued/accepted (document is now in backend pipeline)&#10;            queue_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            queue_doc_params = {'id': f'eq.{document_id}'}&#10;            queue_doc_data = {'status': 'processing'}&#10;            queue_doc_headers = supabase_headers()&#10;&#10;            try:&#10;                requests.patch(queue_doc_url, params=queue_doc_params,&#10;                             headers=queue_doc_headers, json=queue_doc_data, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            ok_payload = {&#10;                **next_payload,&#10;                'extract_status': 'queued',&#10;                'webhook_response': webhook_json,&#10;                'extract_queued_at': datetime.utcnow().isoformat()&#10;            }&#10;&#10;            try:&#10;                requests.patch(update_case_url, params=update_case_params,&#10;                             headers=update_case_headers, json={'payload': ok_payload}, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            response = jsonify({&#10;                'ok': True,&#10;                'token': token,&#10;                'document_id': document_id,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'webhook': webhook_json&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        except Exception as e:&#10;            logger.error('Webhook request failed', extra={'error': str(e)})&#10;            response = jsonify({'error': f'Webhook request failed: {str(e)}'})&#10;            return add_cors_headers(response), 502&#10;&#10;    except Exception as e:&#10;        logger.error('Unexpected error in doc-extract-start', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/case-analysis', methods=['POST', 'OPTIONS'])&#10;def case_analysis():&#10;    &quot;&quot;&quot;Generate HOA case analysis using OpenAI (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY or not OPENAI_API_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = body.get('token')&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # 1) Ensure case exists + is unlocked/paid&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'token,unlocked,status,payload'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        if not case_row.get('unlocked'):&#10;            response = jsonify({'error': 'Case is not unlocked'})&#10;            return add_cors_headers(response), 402&#10;&#10;        # 1b) Load extracted documents for this case&#10;        docs_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        docs_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,filename,path,status,extracted_text,page_count,char_count,updated_at,error',&#10;            'order': 'updated_at.desc',&#10;            'limit': '10'&#10;        }&#10;        docs_headers = supabase_headers()&#10;&#10;        try:&#10;            docs_response = requests.get(docs_url, params=docs_params, headers=docs_headers, timeout=TIMEOUT)&#10;            docs_response.raise_for_status()&#10;            docs = docs_response.json()&#10;        except Exception as e:&#10;            logger.error('Docs lookup error', extra={'error': str(e)})&#10;            docs = []&#10;&#10;        docs_newest = newest_updated_at(docs)&#10;&#10;        # Consider usable if it has text, even if status still says &quot;processing&quot;&#10;        usable_docs = [&#10;            d for d in docs&#10;            if isinstance(d.get('extracted_text'), str) and d['extracted_text'].strip()&#10;        ]&#10;&#10;        logger.info('DOCS DEBUG', extra={&#10;            'count': len(docs),&#10;            'docs_newest': docs_newest,&#10;            'statuses': [{'id': d['id'], 'status': d['status'], 'hasText': bool(d.get('extracted_text', '').strip()),&#10;                         'charCount': d.get('char_count'), 'updated_at': d.get('updated_at'), 'err': d.get('error')}&#10;                        for d in docs],&#10;            'usable_count': len(usable_docs)&#10;        })&#10;&#10;        if usable_docs:&#10;            docs_block = '\n'.join([&#10;                f&quot;DOCUMENT {i + 1}: {d.get('filename') or d.get('path') or d['id']}\n&quot;&#10;                f&quot;---\n{(d.get('extracted_text', '') or '')[:12000]}\n---\n&quot;&#10;                for i, d in enumerate(usable_docs[:5])&#10;            ])&#10;        else:&#10;            statuses = ', '.join([d.get('status', 'unknown') for d in docs]) or 'none'&#10;            errors = ' | '.join([d.get('error', '') for d in docs if d.get('error')])[:100] or 'none'&#10;            docs_block = f&quot;&quot;&quot;No document text available yet.&#10;Docs found: {len(docs)}&#10;Statuses: {statuses}&#10;Errors: {errors}&quot;&quot;&quot;&#10;&#10;        logger.info('DOCS BLOCK LENGTH', extra={'length': len(docs_block)})&#10;&#10;        # 2) If outputs already exist and are ready, return cached ONLY if docs haven't changed since outputs updated_at&#10;        outputs_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_outputs&quot;&#10;        outputs_params = {&#10;            'case_token': f'eq.{token}',&#10;            'select': 'case_token,status,outputs,error,updated_at'&#10;        }&#10;        outputs_headers = supabase_headers()&#10;&#10;        try:&#10;            outputs_response = requests.get(outputs_url, params=outputs_params, headers=outputs_headers, timeout=TIMEOUT)&#10;            outputs_response.raise_for_status()&#10;            existing_outputs = outputs_response.json()&#10;            existing_out = existing_outputs[0] if existing_outputs else None&#10;        except Exception as e:&#10;            logger.error('Database error reading outputs', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading outputs', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        out_updated = safe_iso(existing_out.get('updated_at') if existing_out else None)&#10;        docs_are_newer = (&#10;            docs_newest and out_updated and&#10;            datetime.fromisoformat(docs_newest) &gt; datetime.fromisoformat(out_updated)&#10;        )&#10;&#10;        if (existing_out and existing_out.get('status') == 'ready' and&#10;            existing_out.get('outputs') and not docs_are_newer):&#10;            response = jsonify({&#10;                'ok': True,&#10;                'status': 'ready',&#10;                'cached': True,&#10;                'outputs': existing_out['outputs']&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        # 3) Mark outputs as pending (upsert)&#10;        pending_data = {&#10;            'case_token': token,&#10;            'status': 'pending',&#10;            'error': None,&#10;            'model': 'gpt-4o-mini',&#10;            'prompt_version': 'v3_docs_cache_invalidation',&#10;            'updated_at': datetime.utcnow().isoformat()&#10;        }&#10;&#10;        upsert_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_outputs&quot;&#10;        upsert_headers = supabase_headers()&#10;        upsert_headers['Prefer'] = 'resolution=merge-duplicates'&#10;&#10;        try:&#10;            upsert_response = requests.post(upsert_url, headers=upsert_headers, json=pending_data, timeout=TIMEOUT)&#10;            upsert_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Failed to mark outputs pending', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to mark outputs pending', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        payload = case_row.get('payload') or {}&#10;        draft_titles = get_draft_titles(payload)&#10;&#10;        # 4) OpenAI Responses API call (strict JSON schema)&#10;        schema = {&#10;            &quot;type&quot;: &quot;object&quot;,&#10;            &quot;additionalProperties&quot;: False,&#10;            &quot;properties&quot;: {&#10;                &quot;summary_html&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                &quot;letter_summary&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                &quot;draft_titles&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;clarification&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;extension&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;compliance&quot;: {&quot;type&quot;: &quot;string&quot;}&#10;                    },&#10;                    &quot;required&quot;: [&quot;clarification&quot;, &quot;extension&quot;, &quot;compliance&quot;]&#10;                },&#10;                &quot;risks_and_deadlines&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;deadlines&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 1},&#10;                        &quot;risks&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 3}&#10;                    },&#10;                    &quot;required&quot;: [&quot;deadlines&quot;, &quot;risks&quot;]&#10;                },&#10;                &quot;action_plan&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 6},&#10;                &quot;drafts&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;clarification&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;extension&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;compliance&quot;: {&quot;type&quot;: &quot;string&quot;}&#10;                    },&#10;                    &quot;required&quot;: [&quot;clarification&quot;, &quot;extension&quot;, &quot;compliance&quot;]&#10;                },&#10;                &quot;questions_to_ask&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 6},&#10;                &quot;lowest_cost_path&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 4}&#10;            },&#10;            &quot;required&quot;: [&#10;                &quot;summary_html&quot;, &quot;letter_summary&quot;, &quot;draft_titles&quot;, &quot;risks_and_deadlines&quot;,&#10;                &quot;action_plan&quot;, &quot;drafts&quot;, &quot;questions_to_ask&quot;, &quot;lowest_cost_path&quot;&#10;            ]&#10;        }&#10;&#10;        doc_fingerprint = {&#10;            'count': len(docs),&#10;            'usableCount': len(usable_docs),&#10;            'newestUpdatedAt': docs_newest,&#10;            'ids': [d['id'] for d in docs],&#10;            'statuses': [d.get('status') for d in docs],&#10;            'charCounts': [d.get('char_count') for d in docs]&#10;        }&#10;&#10;        messages = [&#10;            {&#10;                &quot;role&quot;: &quot;system&quot;,&#10;                &quot;content&quot;: &quot;&quot;&quot;&#10;You generate HOA dispute assistance for a homeowner.&#10;This is educational drafting help, not legal advice.&#10;&#10;OUTPUT RULES (CRITICAL):&#10;- ONLY &quot;summary_html&quot; may contain HTML.&#10;- summary_html must be valid HTML using ONLY: &lt;div&gt;, &lt;strong&gt;, &lt;ul&gt;, &lt;li&gt;.&#10;- ALL drafts (clarification/extension/compliance) MUST be PLAIN TEXT ONLY:&#10;  - NO HTML tags&#10;  - Use newlines with \\n&#10;  - Bullets: use &quot;- item&quot; lines&#10;- Return STRICT JSON that matches the schema exactly.&#10;&#10;DRAFT QUALITY REQUIREMENTS:&#10;- Each draft must be a complete, ready-to-send letter.&#10;- MUST directly quote or reference concrete facts from the extracted documents when available&#10;  (deadlines, email addresses, paragraph citations, dollar amounts, dates, etc.).&#10;- Each must include:&#10;  - Subject line&#10;  - Short opening&#10;  - 3–6 bullet-point requests (specific asks)&#10;  - Proposed timeline (e.g., &quot;Please respond within 10 business days&quot; if no deadline is provided)&#10;  - Request fines/penalties be paused/waived while pending (when relevant)&#10;  - Closing requesting confirmation in writing&#10;&#10;DEPTH REQUIREMENTS:&#10;- action_plan &gt;= 6 steps with timing hints (Today / 48 hours / Before deadline).&#10;- risks &gt;= 3 concrete risks tied to HOA enforcement.&#10;- questions_to_ask &gt;= 6 questions.&#10;- lowest_cost_path &gt;= 4 items.&#10;&#10;STYLE:&#10;- Calm, professional, firm, factual.&#10;&quot;&quot;&quot;&#10;            },&#10;            {&#10;                &quot;role&quot;: &quot;user&quot;,&#10;                &quot;content&quot;: (&#10;                    f&quot;Case payload JSON:\n{json.dumps(payload)}\n\n&quot;&#10;                    f&quot;Document fingerprint (debug):\n{json.dumps(doc_fingerprint)}\n\n&quot;&#10;                    f&quot;Extracted documents:\n{docs_block}\n\n&quot;&#10;                    f&quot;Draft types for this case (MUST follow exactly):\n&quot;&#10;                    f&quot;- drafts.clarification MUST be: \&quot;{draft_titles['clarification']}\&quot;\n&quot;&#10;                    f&quot;- drafts.extension MUST be: \&quot;{draft_titles['extension']}\&quot;\n&quot;&#10;                    f&quot;- drafts.compliance MUST be: \&quot;{draft_titles['compliance']}\&quot;\n\n&quot;&#10;                    f&quot;Also include draft_titles using these exact same strings.\n\n&quot;&#10;                    f&quot;summary_html must be valid HTML using ONLY: &lt;div&gt;, &lt;strong&gt;, &lt;ul&gt;, &lt;li&gt;.\n&quot;&#10;                    f&quot;Drafts must be PLAIN TEXT ONLY with \\n, and must NOT include any HTML tags.\n\n&quot;&#10;                    f&quot;Make this feel like a $30 deliverable: concrete, specific, complete.\n&quot;&#10;                )&#10;            }&#10;        ]&#10;&#10;        openai_payload = {&#10;            &quot;model&quot;: &quot;gpt-4o-mini&quot;,&#10;            &quot;input&quot;: messages,&#10;            &quot;text&quot;: {&#10;                &quot;format&quot;: {&#10;                    &quot;type&quot;: &quot;json_schema&quot;,&#10;                    &quot;name&quot;: &quot;dmhoa_case_outputs&quot;,&#10;                    &quot;strict&quot;: True,&#10;                    &quot;schema&quot;: schema&#10;                }&#10;            }&#10;        }&#10;&#10;        # Make OpenAI API call&#10;        try:&#10;            openai_response = requests.post(&#10;                'https://api.openai.com/v1/responses',&#10;                headers={&#10;                    'Authorization': f'Bearer {OPENAI_API_KEY}',&#10;                    'Content-Type': 'application/json'&#10;                },&#10;                json=openai_payload,&#10;                timeout=(10, 120)  # 10s connect, 120s read&#10;            )&#10;&#10;            if not openai_response.ok:&#10;                error_text = openai_response.text&#10;                logger.error('OpenAI call failed', extra={'status': openai_response.status_code, 'error': error_text})&#10;&#10;                # Update outputs table with error&#10;                error_data = {&#10;                    'case_token': token,&#10;                    'status': 'error',&#10;                    'error': error_text or 'OpenAI call failed',&#10;                    'updated_at': datetime.utcnow().isoformat()&#10;                }&#10;                try:&#10;                    requests.post(upsert_url, headers=upsert_headers, json=error_data, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                response = jsonify({'error': 'OpenAI call failed', 'details': error_text})&#10;                return add_cors_headers(response), 500&#10;&#10;            openai_json = openai_response.json()&#10;            structured = extract_structured_result(openai_json)&#10;&#10;            if structured:&#10;                outputs_to_store = {&#10;                    **structured,&#10;                    'draft_titles': structured.get('draft_titles', draft_titles),&#10;                    'doc_fingerprint': doc_fingerprint  # helpful for debugging what it saw&#10;                }&#10;            else:&#10;                outputs_to_store = {&#10;                    'raw': openai_json,&#10;                    'draft_titles': draft_titles,&#10;                    'doc_fingerprint': doc_fingerprint&#10;                }&#10;&#10;            # Save successful outputs&#10;            success_data = {&#10;                'case_token': token,&#10;                'status': 'ready',&#10;                'outputs': outputs_to_store,&#10;                'error': None,&#10;                'model': 'gpt-4o-mini',&#10;                'prompt_version': 'v3_docs_cache_invalidation',&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;&#10;            try:&#10;                requests.post(upsert_url, headers=upsert_headers, json=success_data, timeout=TIMEOUT)&#10;            except Exception as e:&#10;                logger.error('Failed saving outputs', extra={'error': str(e)})&#10;                response = jsonify({'error': 'Failed saving outputs', 'details': str(e)})&#10;                return add_cors_headers(response), 500&#10;&#10;            # Update case updated_at timestamp&#10;            try:&#10;                case_update_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;                case_update_params = {'token': f'eq.{token}'}&#10;                case_update_data = {'updated_at': datetime.utcnow().isoformat()}&#10;                case_update_headers = supabase_headers()&#10;                requests.patch(case_update_url, params=case_update_params,&#10;                             headers=case_update_headers, json=case_update_data, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            response = jsonify({&#10;                'ok': True,&#10;                'status': 'ready',&#10;                'cached': False,&#10;                'outputs': outputs_to_store&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        except Exception as e:&#10;            logger.error('OpenAI API error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'OpenAI API error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;    except Exception as e:&#10;        logger.error('case-analysis error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/case-data', methods=['GET', 'OPTIONS'])&#10;def get_case_data():&#10;    &quot;&quot;&quot;Get case data by token (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Get token from query parameters&#10;        token = request.args.get('token', '').strip()&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Fetch case data from Supabase&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'token,unlocked,status,created_at,payload,amount_total,currency'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;&#10;            if not cases:&#10;                response = jsonify({'error': 'Case not found'})&#10;                return add_cors_headers(response), 404&#10;&#10;            case_data = cases[0]&#10;&#10;        except requests.exceptions.RequestException as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Return case data&#10;        response = jsonify(case_data)&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('get-case-data error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/read-messages', methods=['GET', 'OPTIONS'])&#10;def read_messages():&#10;    &quot;&quot;&quot;Read chat messages for a case (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', 'https://disputemyhoa.com')  # or &quot;*&quot; while testing&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        response.headers.add('Access-Control-Max-Age', '86400')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', 'https://disputemyhoa.com')  # or &quot;*&quot; while testing&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        response.headers.add('Access-Control-Max-Age', '86400')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Get parameters from query string&#10;        token = request.args.get('token', '').strip()&#10;        limit_param = request.args.get('limit', '50')&#10;&#10;        # Parse and validate limit (min 1, max 200, default 50)&#10;        try:&#10;            limit = max(1, min(int(limit_param) or 50, 200))&#10;        except (ValueError, TypeError):&#10;            limit = 50&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Check if case exists and is unlocked&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'unlocked'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        if not case_row.get('unlocked'):&#10;            # Return empty messages array if case is not unlocked&#10;            response = jsonify({'ok': True, 'messages': []})&#10;            return add_cors_headers(response), 200&#10;&#10;        # Fetch messages for the case&#10;        messages_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        messages_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,role,content,created_at',&#10;            'order': 'created_at.asc',&#10;            'limit': str(limit)&#10;        }&#10;        messages_headers = supabase_headers()&#10;&#10;        try:&#10;            messages_response = requests.get(messages_url, params=messages_params, headers=messages_headers, timeout=TIMEOUT)&#10;            messages_response.raise_for_status()&#10;            messages = messages_response.json()&#10;        except Exception as e:&#10;            logger.error('Database error reading messages', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading messages'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Return messages&#10;        response = jsonify({'ok': True, 'messages': messages or []})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('read-messages error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/read-outputs', methods=['GET', 'POST', 'OPTIONS'])&#10;def read_outputs():&#10;    &quot;&quot;&quot;Read case analysis outputs by token (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing required environment variables'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Extract token from GET params or POST body&#10;        token = &quot;&quot;&#10;        if request.method == 'GET':&#10;            token = request.args.get('token', '').strip()&#10;        elif request.method == 'POST':&#10;            try:&#10;                body = request.get_json() or {}&#10;                token = (body.get('token') or '').strip()&#10;            except Exception:&#10;                token = &quot;&quot;&#10;        else:&#10;            response = jsonify({'error': 'Method not allowed'})&#10;            return add_cors_headers(response), 405&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'Token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Fetch case outputs from Supabase&#10;        outputs_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_outputs&quot;&#10;        outputs_params = {&#10;            'case_token': f'eq.{token}',&#10;            'select': 'case_token,status,outputs,error,created_at,updated_at,model,prompt_version'&#10;        }&#10;        outputs_headers = supabase_headers()&#10;&#10;        try:&#10;            outputs_response = requests.get(outputs_url, params=outputs_params, headers=outputs_headers, timeout=TIMEOUT)&#10;            outputs_response.raise_for_status()&#10;            outputs_data = outputs_response.json()&#10;            data = outputs_data[0] if outputs_data else None&#10;        except Exception as e:&#10;            logger.error('[read-outputs] DB error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not data:&#10;            # Return 200 with missing status so client can poll without treating as error&#10;            response = jsonify({&#10;                'case_token': token,&#10;                'status': 'missing',&#10;                'outputs': None,&#10;                'error': None&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        # Return the outputs data&#10;        response = jsonify({&#10;            'case_token': data.get('case_token'),&#10;            'status': data.get('status'),&#10;            'outputs': data.get('outputs'),&#10;            'error': data.get('error'),&#10;            'model': data.get('model'),&#10;            'prompt_version': data.get('prompt_version'),&#10;            'created_at': data.get('created_at'),&#10;            'updated_at': data.get('updated_at')&#10;        })&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('[read-outputs] Error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'Internal server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;def trigger_document_extraction_async(token: str, payload: dict):&#10;    &quot;&quot;&quot;&#10;    Async function to trigger document extraction without blocking the save operation&#10;    &quot;&quot;&quot;&#10;    try:&#10;        logger.info(f&quot;Checking if document extraction is needed for token: {token}&quot;)&#10;&#10;        # Check if there are uploaded documents that need processing&#10;        needs_extraction = (&#10;            (payload.get('pastedText') or (payload.get('additional_docs') and len(payload.get('additional_docs', [])) &gt; 0)) and&#10;            payload.get('extract_status') == 'pending'&#10;        )&#10;&#10;        if not needs_extraction:&#10;            logger.info(&quot;No document extraction needed&quot;)&#10;            return&#10;&#10;        logger.info(&quot;Document extraction needed, preparing to trigger...&quot;)&#10;&#10;        # Get environment variables for doc-extract-start&#10;        if not DOC_EXTRACT_WEBHOOK_SECRET:&#10;            logger.warning(&quot;DOC_EXTRACT_WEBHOOK_SECRET not configured, skipping document extraction&quot;)&#10;&#10;            # Update case with error status&#10;            try:&#10;                url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;                params = {'token': f'eq.{token}'}&#10;                headers = supabase_headers()&#10;&#10;                updated_payload = {&#10;                    **payload,&#10;                    'extract_status': 'not_configured',&#10;                    'extract_error': 'DOC_EXTRACT_WEBHOOK_SECRET environment variable not set'&#10;                }&#10;&#10;                requests.patch(url, params=params, headers=headers,&#10;                             json={'payload': updated_payload}, timeout=TIMEOUT)&#10;            except Exception as e:&#10;                logger.error(f&quot;Failed to update case with config error: {str(e)}&quot;)&#10;            return&#10;&#10;        # Determine what to extract&#10;        storage_path = None&#10;        filename = None&#10;        mime_type = None&#10;&#10;        if payload.get('pastedText'):&#10;            storage_path = f&quot;virtual/{token}/pasted_text.txt&quot;&#10;            filename = &quot;pasted_text.txt&quot;&#10;            mime_type = &quot;text/plain&quot;&#10;            logger.info(&quot;Processing pasted text as virtual document&quot;)&#10;        elif payload.get('additional_docs') and len(payload.get('additional_docs', [])) &gt; 0:&#10;            first_doc = payload['additional_docs'][0]&#10;            storage_path = first_doc.get('storage_path') or first_doc.get('path')&#10;            filename = first_doc.get('filename') or first_doc.get('name')&#10;            mime_type = first_doc.get('mime_type') or first_doc.get('type')&#10;            logger.info(f&quot;Processing uploaded document: {filename}&quot;)&#10;&#10;        if not storage_path:&#10;            logger.warning(&quot;No storage path found for document extraction&quot;)&#10;            return&#10;&#10;        # Call doc-extract-start function&#10;        logger.info(&quot;Calling doc-extract-start function...&quot;)&#10;        doc_extract_url = f&quot;{request.url_root.rstrip('/')}/api/doc-extract-start&quot;&#10;&#10;        extract_response = requests.post(&#10;            doc_extract_url,&#10;            headers={&#10;                'Content-Type': 'application/json',&#10;                'x-doc-secret': DOC_EXTRACT_WEBHOOK_SECRET,&#10;                'Authorization': f'Bearer {SUPABASE_SERVICE_ROLE_KEY}'&#10;            },&#10;            json={&#10;                'token': token,&#10;                'storage_path': storage_path,&#10;                'filename': filename,&#10;                'mime_type': mime_type&#10;            },&#10;            timeout=TIMEOUT&#10;        )&#10;&#10;        logger.info(f&quot;Extract response status: {extract_response.status_code}&quot;)&#10;&#10;        if extract_response.ok:&#10;            logger.info(&quot;Document extraction triggered successfully&quot;)&#10;&#10;            try:&#10;                url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;                params = {'token': f'eq.{token}'}&#10;                headers = supabase_headers()&#10;&#10;                updated_payload = {&#10;                    **payload,&#10;                    'extract_status': 'triggered',&#10;                    'extract_triggered_at': datetime.utcnow().isoformat()&#10;                }&#10;&#10;                requests.patch(url, params=params, headers=headers,&#10;                             json={'payload': updated_payload}, timeout=TIMEOUT)&#10;            except Exception as e:&#10;                logger.error(f&quot;Failed to update case status after triggering: {str(e)}&quot;)&#10;            return&#10;&#10;        if extract_response.status_code == 404:&#10;            logger.warning(&quot;doc-extract-start function not deployed yet, skipping&quot;)&#10;            try:&#10;                url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;                params = {'token': f'eq.{token}'}&#10;                headers = supabase_headers()&#10;&#10;                updated_payload = {&#10;                    **payload,&#10;                    'extract_status': 'not_deployed',&#10;                    'extract_error': 'Document extraction function not yet deployed'&#10;                }&#10;&#10;                requests.patch(url, params=params, headers=headers,&#10;                             json={'payload': updated_payload}, timeout=TIMEOUT)&#10;            except Exception as e:&#10;                logger.error(f&quot;Failed to update case with not deployed error: {str(e)}&quot;)&#10;            return&#10;&#10;        if extract_response.status_code == 401:&#10;            logger.error(&quot;Unauthorized - check DOC_EXTRACT_WEBHOOK_SECRET&quot;)&#10;            error_text = extract_response.text if hasattr(extract_response, 'text') else &quot;&quot;&#10;            try:&#10;                url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;                params = {'token': f'eq.{token}'}&#10;                headers = supabase_headers()&#10;&#10;                updated_payload = {&#10;                    **payload,&#10;                    'extract_status': 'auth_failed',&#10;                    'extract_error': 'Authentication failed - check webhook secret configuration',&#10;                    'extract_error_detail': error_text[:500] if error_text else &quot;&quot;&#10;                }&#10;&#10;                requests.patch(url, params=params, headers=headers,&#10;                             json={'payload': updated_payload}, timeout=TIMEOUT)&#10;            except Exception as e:&#10;                logger.error(f&quot;Failed to update case with auth error: {str(e)}&quot;)&#10;            return&#10;&#10;        # Other failure&#10;        error_text = extract_response.text if hasattr(extract_response, 'text') else &quot;&quot;&#10;        logger.error(f&quot;Failed to trigger document extraction: {extract_response.status_code}, {error_text}&quot;)&#10;&#10;        try:&#10;            url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            params = {'token': f'eq.{token}'}&#10;            headers = supabase_headers()&#10;&#10;            updated_payload = {&#10;                **payload,&#10;                'extract_status': 'failed',&#10;                'extract_error': f&quot;HTTP {extract_response.status_code}: {error_text}&quot;[:500]&#10;            }&#10;&#10;            requests.patch(url, params=params, headers=headers,&#10;                         json={'payload': updated_payload}, timeout=TIMEOUT)&#10;        except Exception as e:&#10;            logger.error(f&quot;Failed to update case with failure: {str(e)}&quot;)&#10;&#10;    except Exception as error:&#10;        logger.error(f&quot;Error in trigger_document_extraction_async: {str(error)}&quot;)&#10;&#10;&#10;@app.route('/api/save-case', methods=['POST', 'OPTIONS'])&#10;def save_case():&#10;    &quot;&quot;&quot;Save case endpoint (converted from Deno/TypeScript save-case function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing required environment variables'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = body.get('token')&#10;        payload = body.get('payload')&#10;&#10;        if not token or not payload:&#10;            response = jsonify({'error': 'Token and payload are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Validate token format&#10;        if not str(token).startswith('case_'):&#10;            response = jsonify({'error': 'Invalid token format'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Check if case already exists&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,payload,created_at'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            existing_case = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error(f&quot;Database error reading case: {str(e)}&quot;)&#10;            response = jsonify({'error': 'Failed to check existing case'})&#10;            return add_cors_headers(response), 500&#10;&#10;        result = None&#10;&#10;        if existing_case:&#10;            # Case exists - update with merged payload&#10;            existing_payload = existing_case.get('payload') or {}&#10;            if isinstance(existing_payload, str):&#10;                try:&#10;                    existing_payload = json.loads(existing_payload)&#10;                except:&#10;                    existing_payload = {}&#10;&#10;            merged_payload = {**existing_payload, **payload}&#10;&#10;            update_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            update_params = {'token': f'eq.{token}'}&#10;            update_data = {&#10;                'payload': merged_payload,&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            update_headers = supabase_headers()&#10;            update_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                update_response = requests.patch(update_url, params=update_params,&#10;                                               headers=update_headers, json=update_data, timeout=TIMEOUT)&#10;                update_response.raise_for_status()&#10;                result = update_response.json()&#10;                logger.info(f&quot;Case updated: {token}&quot;)&#10;            except Exception as e:&#10;                logger.error(f&quot;Database update error: {str(e)}&quot;)&#10;                response = jsonify({'error': 'Failed to update case data'})&#10;                return add_cors_headers(response), 500&#10;&#10;        else:&#10;            # Case doesn't exist - create new&#10;            insert_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            insert_data = {&#10;                'token': token,&#10;                'payload': payload,&#10;                'status': 'new',&#10;                'unlocked': False,&#10;                'created_at': datetime.utcnow().isoformat(),&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            insert_headers = supabase_headers()&#10;            insert_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_response = requests.post(insert_url, headers=insert_headers,&#10;                                              json=insert_data, timeout=TIMEOUT)&#10;                insert_response.raise_for_status()&#10;                result = insert_response.json()&#10;                logger.info(f&quot;Case created: {token}&quot;)&#10;            except Exception as e:&#10;                logger.error(f&quot;Database insert error: {str(e)}&quot;)&#10;                response = jsonify({'error': 'Failed to create case data'})&#10;                return add_cors_headers(response), 500&#10;&#10;        # Log the save event for audit (non-critical)&#10;        try:&#10;            event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;            event_data = {&#10;                'token': token,&#10;                'type': 'case_updated' if existing_case else 'case_created',&#10;                'data': {&#10;                    'payload_keys': list((payload or {}).keys()),&#10;                    'timestamp': datetime.utcnow().isoformat()&#10;                }&#10;            }&#10;            event_headers = supabase_headers()&#10;&#10;            requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;        except Exception as e:&#10;            logger.warning(f&quot;Failed to log event (non-critical): {str(e)}&quot;)&#10;&#10;        # Start document extraction in background thread with delay&#10;        def delayed_extraction():&#10;            time.sleep(2)  # 2 second delay to ensure commit propagation&#10;            trigger_document_extraction_async(token, payload)&#10;&#10;        extraction_thread = threading.Thread(target=delayed_extraction)&#10;        extraction_thread.daemon = True&#10;        extraction_thread.start()&#10;&#10;        case_id = result[0].get('id') if result and len(result) &gt; 0 else None&#10;        response = jsonify({'success': True, 'case_id': case_id})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Save case error: {str(e)}&quot;)&#10;        response = jsonify({'error': str(e) or 'Internal server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;def clamp_text(s: str, max_length: int = 1200) -&gt; str:&#10;    &quot;&quot;&quot;Clamp text to maximum length&quot;&quot;&quot;&#10;    text = str(s or &quot;&quot;).strip()&#10;    if not text:&#10;        return &quot;&quot;&#10;    return text[:max_length] if len(text) &gt; max_length else text&#10;&#10;&#10;@app.route('/api/send-message', methods=['POST', 'OPTIONS'])&#10;def send_message():&#10;    &quot;&quot;&quot;Send chat message endpoint (converted from Deno/TypeScript send-message function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    if request.method != 'POST':&#10;        response = jsonify({'error': 'Method not allowed'})&#10;        return add_cors_headers(response), 405&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY or not OPENAI_API_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = str(body.get('token', '')).strip()&#10;        user_content = clamp_text(body.get('content', ''), 1000)&#10;&#10;        if not token or not user_content:&#10;            response = jsonify({'error': 'token and content are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # 1) Ensure case exists + is unlocked&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'token,unlocked,payload'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        if not case_row.get('unlocked'):&#10;            response = jsonify({'error': 'Case is not unlocked'})&#10;            return add_cors_headers(response), 402&#10;&#10;        # 2) Save user message&#10;        user_message_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        user_message_data = {&#10;            'token': token,&#10;            'role': 'user',&#10;            'content': user_content&#10;        }&#10;        user_message_headers = supabase_headers()&#10;        user_message_headers['Prefer'] = 'return=representation'&#10;&#10;        try:&#10;            user_message_response = requests.post(user_message_url, headers=user_message_headers,&#10;                                                json=user_message_data, timeout=TIMEOUT)&#10;            user_message_response.raise_for_status()&#10;            user_insert = user_message_response.json()&#10;            user_message = user_insert[0] if user_insert else None&#10;        except Exception as e:&#10;            logger.error('Failed to save user message', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to save user message'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 3) Load recent history (keep it lightweight)&#10;        history_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        history_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'role,content,created_at',&#10;            'order': 'created_at.asc',&#10;            'limit': '20'&#10;        }&#10;        history_headers = supabase_headers()&#10;&#10;        try:&#10;            history_response = requests.get(history_url, params=history_params, headers=history_headers, timeout=TIMEOUT)&#10;            history_response.raise_for_status()&#10;            history = history_response.json() or []&#10;        except Exception as e:&#10;            logger.error('Failed to load chat history', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to load chat history'})&#10;            return add_cors_headers(response), 500&#10;&#10;        payload = case_row.get('payload') or {}&#10;&#10;        system_prompt = &quot;&quot;&quot;&#10;You are &quot;Dispute My HOA&quot; chat support.&#10;This is educational drafting assistance, not legal advice.&#10;&#10;You help the homeowner with:&#10;- understanding the notice&#10;- drafting a practical response&#10;- next steps / timelines&#10;- reducing escalation risk&#10;&#10;Rules:&#10;- Be calm, practical, specific.&#10;- Ask 1-2 clarifying questions only if truly needed.&#10;- If the user asks for a new letter, produce a ready-to-send draft (plain text).&#10;- Do NOT claim to be a lawyer.&#10;&quot;&quot;&quot;&#10;&#10;        # 4) Call OpenAI (Responses API)&#10;        history_text = '\n'.join([&#10;            f&quot;{msg['role'].upper()}: {msg['content']}&quot;&#10;            for msg in history&#10;        ])&#10;&#10;        input_messages = [&#10;            {'role': 'system', 'content': system_prompt},&#10;            {&#10;                'role': 'user',&#10;                'content': (&#10;                    f&quot;Case payload JSON:\n{json.dumps(payload)}\n\n&quot;&#10;                    f&quot;Recent chat history:\n{history_text}\n\n&quot;&#10;                    f&quot;User message:\n{user_content}\n\nRespond as the assistant.&quot;&#10;                )&#10;            }&#10;        ]&#10;&#10;        openai_payload = {&#10;            'model': 'gpt-4o-mini',&#10;            'input': input_messages&#10;        }&#10;&#10;        try:&#10;            openai_response = requests.post(&#10;                'https://api.openai.com/v1/responses',&#10;                headers={&#10;                    'Authorization': f'Bearer {OPENAI_API_KEY}',&#10;                    'Content-Type': 'application/json'&#10;                },&#10;                json=openai_payload,&#10;                timeout=(10, 60)&#10;            )&#10;&#10;            if not openai_response.ok:&#10;                error_text = openai_response.text&#10;                logger.error('OpenAI call failed', extra={'status': openai_response.status_code, 'error': error_text})&#10;                response = jsonify({'error': 'OpenAI call failed', 'details': error_text})&#10;                return add_cors_headers(response), 500&#10;&#10;            openai_json = openai_response.json()&#10;&#10;            # Extract assistant text from Responses API output safely&#10;            assistant_text = &quot;&quot;&#10;            output = openai_json.get('output')&#10;            if isinstance(output, list):&#10;                for item in output:&#10;                    content = item.get('content') if item else None&#10;                    if isinstance(content, list):&#10;                        for c in content:&#10;                            if (c and c.get('type') == 'output_text' and&#10;                                isinstance(c.get('text'), str)):&#10;                                assistant_text = c['text']&#10;                                break&#10;                        if assistant_text:&#10;                            break&#10;&#10;            assistant_text = clamp_text(&#10;                assistant_text or &quot;I can help—what do you want to do next?&quot;,&#10;                2000&#10;            )&#10;&#10;        except Exception as e:&#10;            logger.error('OpenAI API error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'OpenAI API error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 5) Save assistant message&#10;        assistant_message_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        assistant_message_data = {&#10;            'token': token,&#10;            'role': 'assistant',&#10;            'content': assistant_text&#10;        }&#10;        assistant_message_headers = supabase_headers()&#10;        assistant_message_headers['Prefer'] = 'return=representation'&#10;&#10;        try:&#10;            assistant_message_response = requests.post(assistant_message_url, headers=assistant_message_headers,&#10;                                                     json=assistant_message_data, timeout=TIMEOUT)&#10;            assistant_message_response.raise_for_status()&#10;            assistant_insert = assistant_message_response.json()&#10;            assistant_message = assistant_insert[0] if assistant_insert else None&#10;        except Exception as e:&#10;            logger.error('Failed to save assistant message', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to save assistant message'})&#10;            return add_cors_headers(response), 500&#10;&#10;        response = jsonify({&#10;            'ok': True,&#10;            'token': token,&#10;            'user_message': user_message,&#10;            'assistant_message': assistant_message&#10;        })&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('send-message error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/start-extraction', methods=['POST', 'OPTIONS'])&#10;def start_extraction():&#10;    &quot;&quot;&quot;Document extraction start endpoint (converted from Deno/TypeScript start-extraction function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    def safe_trim(v) -&gt; str:&#10;        return str(v or '').strip()&#10;&#10;    logger.info(f&quot;[{datetime.utcnow().isoformat()}] {request.method} {request.url}&quot;)&#10;&#10;    if request.method != 'POST':&#10;        response = jsonify({'error': 'Method not allowed'})&#10;        return add_cors_headers(response), 405&#10;&#10;    try:&#10;        # Environment variables check&#10;        WEBHOOK_URL = os.environ.get('DOC_EXTRACT_WEBHOOK_URL', f&quot;{request.url_root.rstrip('/')}/webhooks/doc-extract&quot;)&#10;        WEBHOOK_SECRET = os.environ.get('DOC_EXTRACT_WEBHOOK_SECRET')&#10;        DOC_BUCKET = os.environ.get('DOC_EXTRACT_BUCKET', 'dmhoa-docs')&#10;&#10;        logger.info('Env check', extra={&#10;            'hasUrl': bool(SUPABASE_URL),&#10;            'hasServiceRole': bool(SUPABASE_SERVICE_ROLE_KEY),&#10;            'hasWebhookUrl': bool(WEBHOOK_URL),&#10;            'hasWebhookSecret': bool(DOC_EXTRACT_WEBHOOK_SECRET),&#10;            'bucket': DOC_BUCKET&#10;        })&#10;&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing SUPABASE env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not WEBHOOK_URL or not WEBHOOK_SECRET:&#10;            response = jsonify({'error': 'Missing webhook env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Validate secret header&#10;        incoming_secret = request.headers.get('x-doc-secret', '').strip()&#10;        if not incoming_secret or incoming_secret != WEBHOOK_SECRET:&#10;            logger.error('Unauthorized - secret mismatch')&#10;            response = jsonify({'error': 'Unauthorized'})&#10;            return add_cors_headers(response), 401&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = safe_trim(body.get('token'))&#10;        storage_path = safe_trim(body.get('storage_path'))&#10;        filename = safe_trim(body.get('filename')) or None&#10;        mime_type = safe_trim(body.get('mime_type')) or None&#10;&#10;        if not token or not storage_path:&#10;            response = jsonify({'error': 'token and storage_path are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Ensure case exists (fail fast)&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,payload,created_at'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Case lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found', 'token': token})&#10;            return add_cors_headers(response), 404&#10;&#10;        # 1) Create (or reuse) a dmhoa_documents row for this file&#10;        document_id = None&#10;&#10;        # Check for existing document&#10;        doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        doc_params = {&#10;            'token': f'eq.{token}',&#10;            'path': f'eq.{storage_path}',&#10;            'select': 'id,status'&#10;        }&#10;        doc_headers = supabase_headers()&#10;&#10;        try:&#10;            doc_response = requests.get(doc_url, params=doc_params, headers=doc_headers, timeout=TIMEOUT)&#10;            doc_response.raise_for_status()&#10;            docs = doc_response.json()&#10;            existing_doc = docs[0] if docs else None&#10;        except Exception as e:&#10;            logger.error('Doc lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading document', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if existing_doc and existing_doc.get('id'):&#10;            document_id = existing_doc['id']&#10;            logger.info('Reusing existing dmhoa_documents row', extra={&#10;                'document_id': document_id,&#10;                'status': existing_doc.get('status')&#10;            })&#10;        else:&#10;            # Insert new document&#10;            insert_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            insert_doc_data = {&#10;                'token': token,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'filename': filename,&#10;                'mime_type': mime_type,&#10;                'status': 'pending'&#10;            }&#10;            insert_doc_headers = supabase_headers()&#10;            insert_doc_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_doc_response = requests.post(insert_doc_url, headers=insert_doc_headers,&#10;                                                  json=insert_doc_data, timeout=TIMEOUT)&#10;                insert_doc_response.raise_for_status()&#10;                inserted_docs = insert_doc_response.json()&#10;                document_id = inserted_docs[0]['id'] if inserted_docs else None&#10;                logger.info('Created dmhoa_documents row', extra={'document_id': document_id})&#10;            except Exception as e:&#10;                logger.error('Doc insert error', extra={'error': str(e)})&#10;                response = jsonify({'error': 'Failed to create dmhoa_documents row', 'details': str(e)})&#10;                return add_cors_headers(response), 500&#10;&#10;        if not document_id:&#10;            response = jsonify({'error': 'Could not determine document_id'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 2) Update case payload summary status (optional, but useful for UI)&#10;        current_payload = {}&#10;        try:&#10;            payload_data = case_row.get('payload')&#10;            if isinstance(payload_data, str):&#10;                current_payload = json.loads(payload_data)&#10;            elif isinstance(payload_data, dict):&#10;                current_payload = payload_data&#10;        except Exception:&#10;            current_payload = {}&#10;&#10;        next_payload = {&#10;            **current_payload,&#10;            'extract_status': 'triggered',&#10;            'notice_storage_path': storage_path,&#10;            'notice_filename': filename,&#10;            'notice_mime_type': mime_type,&#10;            'extract_triggered_at': datetime.utcnow().isoformat(),&#10;            'document_id': document_id&#10;        }&#10;&#10;        # Update case payload&#10;        update_case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        update_case_params = {'token': f'eq.{token}'}&#10;        update_case_data = {'payload': next_payload}&#10;        update_case_headers = supabase_headers()&#10;&#10;        try:&#10;            update_case_response = requests.patch(update_case_url, params=update_case_params,&#10;                                                headers=update_case_headers, json=update_case_data, timeout=TIMEOUT)&#10;            update_case_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Case payload update error', extra={'error': str(e)})&#10;            # Not fatal—doc record exists and webhook can still run&#10;&#10;        # 3) Mark document processing BEFORE webhook&#10;        mark_proc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        mark_proc_params = {'id': f'eq.{document_id}'}&#10;        mark_proc_data = {'status': 'processing', 'error': None}&#10;        mark_proc_headers = supabase_headers()&#10;&#10;        try:&#10;            mark_proc_response = requests.patch(mark_proc_url, params=mark_proc_params,&#10;                                              headers=mark_proc_headers, json=mark_proc_data, timeout=TIMEOUT)&#10;            mark_proc_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Failed to mark document processing', extra={'error': str(e)})&#10;            # Not fatal, but you'll want to know&#10;&#10;        # 4) Call backend webhook (server-to-server)&#10;        logger.info('Calling webhook', extra={'webhook_url': WEBHOOK_URL})&#10;&#10;        webhook_payload = {&#10;            'token': token,&#10;            'document_id': document_id,&#10;            'bucket': DOC_BUCKET,&#10;            'path': storage_path,&#10;            'filename': filename,&#10;            'mime_type': mime_type,&#10;            'supabase_url': SUPABASE_URL  # optional&#10;        }&#10;&#10;        webhook_headers = {&#10;            'Content-Type': 'application/json',&#10;            'X-Webhook-Secret': WEBHOOK_SECRET,&#10;            'X-Doc-Extract-Secret': WEBHOOK_SECRET  # Alternative header name&#10;        }&#10;&#10;        try:&#10;            webhook_response = requests.post(WEBHOOK_URL, headers=webhook_headers,&#10;                                           json=webhook_payload, timeout=(10, 120))  # Longer timeout for processing&#10;&#10;            logger.info('Webhook response', extra={'status': webhook_response.status_code, 'ok': webhook_response.ok})&#10;&#10;            if not webhook_response.ok:&#10;                error_text = webhook_response.text&#10;                logger.error('Webhook failed', extra={'error': error_text})&#10;&#10;                # Update document status to failed&#10;                fail_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;                fail_doc_params = {'id': f'eq.{document_id}'}&#10;                fail_doc_data = {&#10;                    'status': 'failed',&#10;                    'error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500]&#10;                }&#10;                fail_doc_headers = supabase_headers()&#10;&#10;                try:&#10;                    requests.patch(fail_doc_url, params=fail_doc_params,&#10;                                 headers=fail_doc_headers, json=fail_doc_data, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                # Also reflect summary status on the case payload (optional)&#10;                fail_payload = {&#10;                    **next_payload,&#10;                    'extract_status': 'failed',&#10;                    'extract_error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500],&#10;                    'extract_failed_at': datetime.utcnow().isoformat()&#10;                }&#10;&#10;                try:&#10;                    requests.patch(update_case_url, params=update_case_params,&#10;                                 headers=update_case_headers, json={'payload': fail_payload}, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                response = jsonify({&#10;                    'error': 'Webhook call failed',&#10;                    'status': webhook_response.status_code,&#10;                    'details': error_text&#10;                })&#10;                return add_cors_headers(response), 502&#10;&#10;            # If webhook returns JSON, capture it (optional)&#10;            try:&#10;                webhook_json = webhook_response.json()&#10;            except Exception:&#10;                webhook_json = {}&#10;&#10;            # Mark queued/accepted (document is now in backend pipeline)&#10;            queue_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            queue_doc_params = {'id': f'eq.{document_id}'}&#10;            queue_doc_data = {'status': 'processing'}&#10;            queue_doc_headers = supabase_headers()&#10;&#10;            try:&#10;                requests.patch(queue_doc_url, params=queue_doc_params,&#10;                             headers=queue_doc_headers, json=queue_doc_data, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            ok_payload = {&#10;                **next_payload,&#10;                'extract_status': 'queued',&#10;                'webhook_response': webhook_json,&#10;                'extract_queued_at': datetime.utcnow().isoformat()&#10;            }&#10;&#10;            try:&#10;                requests.patch(update_case_url, params=update_case_params,&#10;                             headers=update_case_headers, json={'payload': ok_payload}, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            response = jsonify({&#10;                'ok': True,&#10;                'token': token,&#10;                'document_id': document_id,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'webhook': webhook_json&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        except Exception as e:&#10;            logger.error('Webhook request failed', extra={'error': str(e)})&#10;            response = jsonify({'error': f'Webhook request failed: {str(e)}'})&#10;            return add_cors_headers(response), 502&#10;&#10;    except Exception as e:&#10;        logger.error('Unexpected error in doc-extract-start', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/case-analysis', methods=['POST', 'OPTIONS'])&#10;def case_analysis():&#10;    &quot;&quot;&quot;Generate HOA case analysis using OpenAI (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY or not OPENAI_API_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = body.get('token')&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # 1) Ensure case exists + is unlocked/paid&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'token,unlocked,status,payload'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        if not case_row.get('unlocked'):&#10;            response = jsonify({'error': 'Case is not unlocked'})&#10;            return add_cors_headers(response), 402&#10;&#10;        # 1b) Load extracted documents for this case&#10;        docs_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        docs_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,filename,path,status,extracted_text,page_count,char_count,updated_at,error',&#10;            'order': 'updated_at.desc',&#10;            'limit': '10'&#10;        }&#10;        docs_headers = supabase_headers()&#10;&#10;        try:&#10;            docs_response = requests.get(docs_url, params=docs_params, headers=docs_headers, timeout=TIMEOUT)&#10;            docs_response.raise_for_status()&#10;            docs = docs_response.json()&#10;        except Exception as e:&#10;            logger.error('Docs lookup error', extra={'error': str(e)})&#10;            docs = []&#10;&#10;        docs_newest = newest_updated_at(docs)&#10;&#10;        # Consider usable if it has text, even if status still says &quot;processing&quot;&#10;        usable_docs = [&#10;            d for d in docs&#10;            if isinstance(d.get('extracted_text'), str) and d['extracted_text'].strip()&#10;        ]&#10;&#10;        logger.info('DOCS DEBUG', extra={&#10;            'count': len(docs),&#10;            'docs_newest': docs_newest,&#10;            'statuses': [{'id': d['id'], 'status': d['status'], 'hasText': bool(d.get('extracted_text', '').strip()),&#10;                         'charCount': d.get('char_count'), 'updated_at': d.get('updated_at'), 'err': d.get('error')}&#10;                        for d in docs],&#10;            'usable_count': len(usable_docs)&#10;        })&#10;&#10;        if usable_docs:&#10;            docs_block = '\n'.join([&#10;                f&quot;DOCUMENT {i + 1}: {d.get('filename') or d.get('path') or d['id']}\n&quot;&#10;                f&quot;---\n{(d.get('extracted_text', '') or '')[:12000]}\n---\n&quot;&#10;                for i, d in enumerate(usable_docs[:5])&#10;            ])&#10;        else:&#10;            statuses = ', '.join([d.get('status', 'unknown') for d in docs]) or 'none'&#10;            errors = ' | '.join([d.get('error', '') for d in docs if d.get('error')])[:100] or 'none'&#10;            docs_block = f&quot;&quot;&quot;No document text available yet.&#10;Docs found: {len(docs)}&#10;Statuses: {statuses}&#10;Errors: {errors}&quot;&quot;&quot;&#10;&#10;        logger.info('DOCS BLOCK LENGTH', extra={'length': len(docs_block)})&#10;&#10;        # 2) If outputs already exist and are ready, return cached ONLY if docs haven't changed since outputs updated_at&#10;        outputs_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_outputs&quot;&#10;        outputs_params = {&#10;            'case_token': f'eq.{token}',&#10;            'select': 'case_token,status,outputs,error,updated_at'&#10;        }&#10;        outputs_headers = supabase_headers()&#10;&#10;        try:&#10;            outputs_response = requests.get(outputs_url, params=outputs_params, headers=outputs_headers, timeout=TIMEOUT)&#10;            outputs_response.raise_for_status()&#10;            existing_outputs = outputs_response.json()&#10;            existing_out = existing_outputs[0] if existing_outputs else None&#10;        except Exception as e:&#10;            logger.error('Database error reading outputs', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading outputs', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        out_updated = safe_iso(existing_out.get('updated_at') if existing_out else None)&#10;        docs_are_newer = (&#10;            docs_newest and out_updated and&#10;            datetime.fromisoformat(docs_newest) &gt; datetime.fromisoformat(out_updated)&#10;        )&#10;&#10;        if (existing_out and existing_out.get('status') == 'ready' and&#10;            existing_out.get('outputs') and not docs_are_newer):&#10;            response = jsonify({&#10;                'ok': True,&#10;                'status': 'ready',&#10;                'cached': True,&#10;                'outputs': existing_out['outputs']&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        # 3) Mark outputs as pending (upsert)&#10;        pending_data = {&#10;            'case_token': token,&#10;            'status': 'pending',&#10;            'error': None,&#10;            'model': 'gpt-4o-mini',&#10;            'prompt_version': 'v3_docs_cache_invalidation',&#10;            'updated_at': datetime.utcnow().isoformat()&#10;        }&#10;&#10;        upsert_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_outputs&quot;&#10;        upsert_headers = supabase_headers()&#10;        upsert_headers['Prefer'] = 'resolution=merge-duplicates'&#10;&#10;        try:&#10;            upsert_response = requests.post(upsert_url, headers=upsert_headers, json=pending_data, timeout=TIMEOUT)&#10;            upsert_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Failed to mark outputs pending', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to mark outputs pending', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        payload = case_row.get('payload') or {}&#10;        draft_titles = get_draft_titles(payload)&#10;&#10;        # 4) OpenAI Responses API call (strict JSON schema)&#10;        schema = {&#10;            &quot;type&quot;: &quot;object&quot;,&#10;            &quot;additionalProperties&quot;: False,&#10;            &quot;properties&quot;: {&#10;                &quot;summary_html&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                &quot;letter_summary&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                &quot;draft_titles&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;clarification&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;extension&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;compliance&quot;: {&quot;type&quot;: &quot;string&quot;}&#10;                    },&#10;                    &quot;required&quot;: [&quot;clarification&quot;, &quot;extension&quot;, &quot;compliance&quot;]&#10;                },&#10;                &quot;risks_and_deadlines&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;deadlines&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 1},&#10;                        &quot;risks&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 3}&#10;                    },&#10;                    &quot;required&quot;: [&quot;deadlines&quot;, &quot;risks&quot;]&#10;                },&#10;                &quot;action_plan&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 6},&#10;                &quot;drafts&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;clarification&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;extension&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;compliance&quot;: {&quot;type&quot;: &quot;string&quot;}&#10;                    },&#10;                    &quot;required&quot;: [&quot;clarification&quot;, &quot;extension&quot;, &quot;compliance&quot;]&#10;                },&#10;                &quot;questions_to_ask&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 6},&#10;                &quot;lowest_cost_path&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 4}&#10;            },&#10;            &quot;required&quot;: [&#10;                &quot;summary_html&quot;, &quot;letter_summary&quot;, &quot;draft_titles&quot;, &quot;risks_and_deadlines&quot;,&#10;                &quot;action_plan&quot;, &quot;drafts&quot;, &quot;questions_to_ask&quot;, &quot;lowest_cost_path&quot;&#10;            ]&#10;        }&#10;&#10;        doc_fingerprint = {&#10;            'count': len(docs),&#10;            'usableCount': len(usable_docs),&#10;            'newestUpdatedAt': docs_newest,&#10;            'ids': [d['id'] for d in docs],&#10;            'statuses': [d.get('status') for d in docs],&#10;            'charCounts': [d.get('char_count') for d in docs]&#10;        }&#10;&#10;        messages = [&#10;            {&#10;                &quot;role&quot;: &quot;system&quot;,&#10;                &quot;content&quot;: &quot;&quot;&quot;&#10;You generate HOA dispute assistance for a homeowner.&#10;This is educational drafting help, not legal advice.&#10;&#10;OUTPUT RULES (CRITICAL):&#10;- ONLY &quot;summary_html&quot; may contain HTML.&#10;- summary_html must be valid HTML using ONLY: &lt;div&gt;, &lt;strong&gt;, &lt;ul&gt;, &lt;li&gt;.&#10;- ALL drafts (clarification/extension/compliance) MUST be PLAIN TEXT ONLY:&#10;  - NO HTML tags&#10;  - Use newlines with \\n&#10;  - Bullets: use &quot;- item&quot; lines&#10;- Return STRICT JSON that matches the schema exactly.&#10;&#10;DRAFT QUALITY REQUIREMENTS:&#10;- Each draft must be a complete, ready-to-send letter.&#10;- MUST directly quote or reference concrete facts from the extracted documents when available&#10;  (deadlines, email addresses, paragraph citations, dollar amounts, dates, etc.).&#10;- Each must include:&#10;  - Subject line&#10;  - Short opening&#10;  - 3–6 bullet-point requests (specific asks)&#10;  - Proposed timeline (e.g., &quot;Please respond within 10 business days&quot; if no deadline is provided)&#10;  - Request fines/penalties be paused/waived while pending (when relevant)&#10;  - Closing requesting confirmation in writing&#10;&#10;DEPTH REQUIREMENTS:&#10;- action_plan &gt;= 6 steps with timing hints (Today / 48 hours / Before deadline).&#10;- risks &gt;= 3 concrete risks tied to HOA enforcement.&#10;- questions_to_ask &gt;= 6 questions.&#10;- lowest_cost_path &gt;= 4 items.&#10;&#10;STYLE:&#10;- Calm, professional, firm, factual.&#10;&quot;&quot;&quot;&#10;            },&#10;            {&#10;                &quot;role&quot;: &quot;user&quot;,&#10;                &quot;content&quot;: (&#10;                    f&quot;Case payload JSON:\n{json.dumps(payload)}\n\n&quot;&#10;                    f&quot;Document fingerprint (debug):\n{json.dumps(doc_fingerprint)}\n\n&quot;&#10;                    f&quot;Extracted documents:\n{docs_block}\n\n&quot;&#10;                    f&quot;Draft types for this case (MUST follow exactly):\n&quot;&#10;                    f&quot;- drafts.clarification MUST be: \&quot;{draft_titles['clarification']}\&quot;\n&quot;&#10;                    f&quot;- drafts.extension MUST be: \&quot;{draft_titles['extension']}\&quot;\n&quot;&#10;                    f&quot;- drafts.compliance MUST be: \&quot;{draft_titles['compliance']}\&quot;\n\n&quot;&#10;                    f&quot;Also include draft_titles using these exact same strings.\n\n&quot;&#10;                    f&quot;summary_html must be valid HTML using ONLY: &lt;div&gt;, &lt;strong&gt;, &lt;ul&gt;, &lt;li&gt;.\n&quot;&#10;                    f&quot;Drafts must be PLAIN TEXT ONLY with \\n, and must NOT include any HTML tags.\n\n&quot;&#10;                    f&quot;Make this feel like a $30 deliverable: concrete, specific, complete.\n&quot;&#10;                )&#10;            }&#10;        ]&#10;&#10;        openai_payload = {&#10;            &quot;model&quot;: &quot;gpt-4o-mini&quot;,&#10;            &quot;input&quot;: messages,&#10;            &quot;text&quot;: {&#10;                &quot;format&quot;: {&#10;                    &quot;type&quot;: &quot;json_schema&quot;,&#10;                    &quot;name&quot;: &quot;dmhoa_case_outputs&quot;,&#10;                    &quot;strict&quot;: True,&#10;                    &quot;schema&quot;: schema&#10;                }&#10;            }&#10;        }&#10;&#10;        # Make OpenAI API call&#10;        try:&#10;            openai_response = requests.post(&#10;                'https://api.openai.com/v1/responses',&#10;                headers={&#10;                    'Authorization': f'Bearer {OPENAI_API_KEY}',&#10;                    'Content-Type': 'application/json'&#10;                },&#10;                json=openai_payload,&#10;                timeout=(10, 120)  # 10s connect, 120s read&#10;            )&#10;&#10;            if not openai_response.ok:&#10;                error_text = openai_response.text&#10;                logger.error('OpenAI call failed', extra={'status': openai_response.status_code, 'error': error_text})&#10;&#10;                # Update outputs table with error&#10;                error_data = {&#10;                    'case_token': token,&#10;                    'status': 'error',&#10;                    'error': error_text or 'OpenAI call failed',&#10;                    'updated_at': datetime.utcnow().isoformat()&#10;                }&#10;                try:&#10;                    requests.post(upsert_url, headers=upsert_headers, json=error_data, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                response = jsonify({'error': 'OpenAI call failed', 'details': error_text})&#10;                return add_cors_headers(response), 500&#10;&#10;            openai_json = openai_response.json()&#10;            structured = extract_structured_result(openai_json)&#10;&#10;            if structured:&#10;                outputs_to_store = {&#10;                    **structured,&#10;                    'draft_titles': structured.get('draft_titles', draft_titles),&#10;                    'doc_fingerprint': doc_fingerprint  # helpful for debugging what it saw&#10;                }&#10;            else:&#10;                outputs_to_store = {&#10;                    'raw': openai_json,&#10;                    'draft_titles': draft_titles,&#10;                    'doc_fingerprint': doc_fingerprint&#10;                }&#10;&#10;            # Save successful outputs&#10;            success_data = {&#10;                'case_token': token,&#10;                'status': 'ready',&#10;                'outputs': outputs_to_store,&#10;                'error': None,&#10;                'model': 'gpt-4o-mini',&#10;                'prompt_version': 'v3_docs_cache_invalidation',&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;&#10;            try:&#10;                requests.post(upsert_url, headers=upsert_headers, json=success_data, timeout=TIMEOUT)&#10;            except Exception as e:&#10;                logger.error('Failed saving outputs', extra={'error': str(e)})&#10;                response = jsonify({'error': 'Failed saving outputs', 'details': str(e)})&#10;                return add_cors_headers(response), 500&#10;&#10;            # Update case updated_at timestamp&#10;            try:&#10;                case_update_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;                case_update_params = {'token': f'eq.{token}'}&#10;                case_update_data = {'updated_at': datetime.utcnow().isoformat()}&#10;                case_update_headers = supabase_headers()&#10;                requests.patch(case_update_url, params=case_update_params,&#10;                             headers=case_update_headers, json=case_update_data, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            response = jsonify({&#10;                'ok': True,&#10;                'status': 'ready',&#10;                'cached': False,&#10;                'outputs': outputs_to_store&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        except Exception as e:&#10;            logger.error('OpenAI API error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'OpenAI API error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;    except Exception as e:&#10;        logger.error('case-analysis error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/case-data', methods=['GET', 'OPTIONS'])&#10;def get_case_data():&#10;    &quot;&quot;&quot;Get case data by token (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Get token from query parameters&#10;        token = request.args.get('token', '').strip()&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Fetch case data from Supabase&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'token,unlocked,status,created_at,payload,amount_total,currency'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;&#10;            if not cases:&#10;                response = jsonify({'error': 'Case not found'})&#10;                return add_cors_headers(response), 404&#10;&#10;            case_data = cases[0]&#10;&#10;        except requests.exceptions.RequestException as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Return case data&#10;        response = jsonify(case_data)&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('get-case-data error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/read-messages', methods=['GET', 'OPTIONS'])&#10;def read_messages():&#10;    &quot;&quot;&quot;Read chat messages for a case (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', 'https://disputemyhoa.com')  # or &quot;*&quot; while testing&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        response.headers.add('Access-Control-Max-Age', '86400')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', 'https://disputemyhoa.com')  # or &quot;*&quot; while testing&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        response.headers.add('Access-Control-Max-Age', '86400')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Get parameters from query string&#10;        token = request.args.get('token', '').strip()&#10;        limit_param = request.args.get('limit', '50')&#10;&#10;        # Parse and validate limit (min 1, max 200, default 50)&#10;        try:&#10;            limit = max(1, min(int(limit_param) or 50, 200))&#10;        except (ValueError, TypeError):&#10;            limit = 50&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Check if case exists and is unlocked&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'unlocked'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        if not case_row.get('unlocked'):&#10;            # Return empty messages array if case is not unlocked&#10;            response = jsonify({'ok': True, 'messages': []})&#10;            return add_cors_headers(response), 200&#10;&#10;        # Fetch messages for the case&#10;        messages_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        messages_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,role,content,created_at',&#10;            'order': 'created_at.asc',&#10;            'limit': str(limit)&#10;        }&#10;        messages_headers = supabase_headers()&#10;&#10;        try:&#10;            messages_response = requests.get(messages_url, params=messages_params, headers=messages_headers, timeout=TIMEOUT)&#10;            messages_response.raise_for_status()&#10;            messages = messages_response.json()&#10;        except Exception as e:&#10;            logger.error('Database error reading messages', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading messages'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Return messages&#10;        response = jsonify({'ok': True, 'messages': messages or []})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('read-messages error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/read-outputs', methods=['GET', 'POST', 'OPTIONS'])&#10;def read_outputs():&#10;    &quot;&quot;&quot;Read case analysis outputs by token (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing required environment variables'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Extract token from GET params or POST body&#10;        token = &quot;&quot;&#10;        if request.method == 'GET':&#10;            token = request.args.get('token', '').strip()&#10;        elif request.method == 'POST':&#10;            try:&#10;                body = request.get_json() or {}&#10;                token = (body.get('token') or '').strip()&#10;            except Exception:&#10;                token = &quot;&quot;&#10;        else:&#10;            response = jsonify({'error': 'Method not allowed'})&#10;            return add_cors_headers(response), 405&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'Token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Fetch case outputs from Supabase&#10;        outputs_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_outputs&quot;&#10;        outputs_params = {&#10;            'case_token': f'eq.{token}',&#10;            'select': 'case_token,status,outputs,error,created_at,updated_at,model,prompt_version'&#10;        }&#10;        outputs_headers = supabase_headers()&#10;&#10;        try:&#10;            outputs_response = requests.get(outputs_url, params=outputs_params, headers=outputs_headers, timeout=TIMEOUT)&#10;            outputs_response.raise_for_status()&#10;            outputs_data = outputs_response.json()&#10;            data = outputs_data[0] if outputs_data else None&#10;        except Exception as e:&#10;            logger.error('[read-outputs] DB error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not data:&#10;            # Return 200 with missing status so client can poll without treating as error&#10;            response = jsonify({&#10;                'case_token': token,&#10;                'status': 'missing',&#10;                'outputs': None,&#10;                'error': None&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        # Return the outputs data&#10;        response = jsonify({&#10;            'case_token': data.get('case_token'),&#10;            'status': data.get('status'),&#10;            'outputs': data.get('outputs'),&#10;            'error': data.get('error'),&#10;            'model': data.get('model'),&#10;            'prompt_version': data.get('prompt_version'),&#10;            'created_at': data.get('created_at'),&#10;            'updated_at': data.get('updated_at')&#10;        })&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('[read-outputs] Error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'Internal server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/save-case', methods=['POST', 'OPTIONS'])&#10;def save_case():&#10;    &quot;&quot;&quot;Save case endpoint (converted from Deno/TypeScript save-case function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing required environment variables'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = body.get('token')&#10;        payload = body.get('payload')&#10;&#10;        if not token or not payload:&#10;            response = jsonify({'error': 'Token and payload are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Validate token format&#10;        if not str(token).startswith('case_'):&#10;            response = jsonify({'error': 'Invalid token format'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Check if case already exists&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,payload,created_at'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            existing_case = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error(f&quot;Database error reading case: {str(e)}&quot;)&#10;            response = jsonify({'error': 'Failed to check existing case'})&#10;            return add_cors_headers(response), 500&#10;&#10;        result = None&#10;&#10;        if existing_case:&#10;            # Case exists - update with merged payload&#10;            existing_payload = existing_case.get('payload') or {}&#10;            if isinstance(existing_payload, str):&#10;                try:&#10;                    existing_payload = json.loads(existing_payload)&#10;                except:&#10;                    existing_payload = {}&#10;&#10;            merged_payload = {**existing_payload, **payload}&#10;&#10;            update_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            update_params = {'token': f'eq.{token}'}&#10;            update_data = {&#10;                'payload': merged_payload,&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            update_headers = supabase_headers()&#10;            update_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                update_response = requests.patch(update_url, params=update_params,&#10;                                               headers=update_headers, json=update_data, timeout=TIMEOUT)&#10;                update_response.raise_for_status()&#10;                result = update_response.json()&#10;                logger.info(f&quot;Case updated: {token}&quot;)&#10;            except Exception as e:&#10;                logger.error(f&quot;Database update error: {str(e)}&quot;)&#10;                response = jsonify({'error': 'Failed to update case data'})&#10;                return add_cors_headers(response), 500&#10;&#10;        else:&#10;            # Case doesn't exist - create new&#10;            insert_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            insert_data = {&#10;                'token': token,&#10;                'payload': payload,&#10;                'status': 'new',&#10;                'unlocked': False,&#10;                'created_at': datetime.utcnow().isoformat(),&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            insert_headers = supabase_headers()&#10;            insert_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_response = requests.post(insert_url, headers=insert_headers,&#10;                                              json=insert_data, timeout=TIMEOUT)&#10;                insert_response.raise_for_status()&#10;                result = insert_response.json()&#10;                logger.info(f&quot;Case created: {token}&quot;)&#10;            except Exception as e:&#10;                logger.error(f&quot;Database insert error: {str(e)}&quot;)&#10;                response = jsonify({'error': 'Failed to create case data'})&#10;                return add_cors_headers(response), 500&#10;&#10;        # Log the save event for audit (non-critical)&#10;        try:&#10;            event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;            event_data = {&#10;                'token': token,&#10;                'type': 'case_updated' if existing_case else 'case_created',&#10;                'data': {&#10;                    'payload_keys': list((payload or {}).keys()),&#10;                    'timestamp': datetime.utcnow().isoformat()&#10;                }&#10;            }&#10;            event_headers = supabase_headers()&#10;&#10;            requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;        except Exception as e:&#10;            logger.warning(f&quot;Failed to log event (non-critical): {str(e)}&quot;)&#10;&#10;        # Start document extraction in background thread with delay&#10;        def delayed_extraction():&#10;            time.sleep(2)  # 2 second delay to ensure commit propagation&#10;            trigger_document_extraction_async(token, payload)&#10;&#10;        extraction_thread = threading.Thread(target=delayed_extraction)&#10;        extraction_thread.daemon = True&#10;        extraction_thread.start()&#10;&#10;        case_id = result[0].get('id') if result and len(result) &gt; 0 else None&#10;        response = jsonify({'success': True, 'case_id': case_id})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Save case error: {str(e)}&quot;)&#10;        response = jsonify({'error': str(e) or 'Internal server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/send-message', methods=['POST', 'OPTIONS'])&#10;def send_message():&#10;    &quot;&quot;&quot;Send chat message endpoint (converted from Deno/TypeScript send-message function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    if request.method != 'POST':&#10;        response = jsonify({'error': 'Method not allowed'})&#10;        return add_cors_headers(response), 405&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY or not OPENAI_API_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = str(body.get('token', '')).strip()&#10;        user_content = clamp_text(body.get('content', ''), 1000)&#10;&#10;        if not token or not user_content:&#10;            response = jsonify({'error': 'token and content are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # 1) Ensure case exists + is unlocked&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'token,unlocked,payload'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        if not case_row.get('unlocked'):&#10;            response = jsonify({'error': 'Case is not unlocked'})&#10;            return add_cors_headers(response), 402&#10;&#10;        # 2) Save user message&#10;        user_message_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        user_message_data = {&#10;            'token': token,&#10;            'role': 'user',&#10;            'content': user_content&#10;        }&#10;        user_message_headers = supabase_headers()&#10;        user_message_headers['Prefer'] = 'return=representation'&#10;&#10;        try:&#10;            user_message_response = requests.post(user_message_url, headers=user_message_headers,&#10;                                                json=user_message_data, timeout=TIMEOUT)&#10;            user_message_response.raise_for_status()&#10;            user_insert = user_message_response.json()&#10;            user_message = user_insert[0] if user_insert else None&#10;        except Exception as e:&#10;            logger.error('Failed to save user message', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to save user message'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 3) Load recent history (keep it lightweight)&#10;        history_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        history_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'role,content,created_at',&#10;            'order': 'created_at.asc',&#10;            'limit': '20'&#10;        }&#10;        history_headers = supabase_headers()&#10;&#10;        try:&#10;            history_response = requests.get(history_url, params=history_params, headers=history_headers, timeout=TIMEOUT)&#10;            history_response.raise_for_status()&#10;            history = history_response.json() or []&#10;        except Exception as e:&#10;            logger.error('Failed to load chat history', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to load chat history'})&#10;            return add_cors_headers(response), 500&#10;&#10;        payload = case_row.get('payload') or {}&#10;&#10;        system_prompt = &quot;&quot;&quot;&#10;You are &quot;Dispute My HOA&quot; chat support.&#10;This is educational drafting assistance, not legal advice.&#10;&#10;You help the homeowner with:&#10;- understanding the notice&#10;- drafting a practical response&#10;- next steps / timelines&#10;- reducing escalation risk&#10;&#10;Rules:&#10;- Be calm, practical, specific.&#10;- Ask 1-2 clarifying questions only if truly needed.&#10;- If the user asks for a new letter, produce a ready-to-send draft (plain text).&#10;- Do NOT claim to be a lawyer.&#10;&quot;&quot;&quot;&#10;&#10;        # 4) Call OpenAI (Responses API)&#10;        history_text = '\n'.join([&#10;            f&quot;{msg['role'].upper()}: {msg['content']}&quot;&#10;            for msg in history&#10;        ])&#10;&#10;        input_messages = [&#10;            {'role': 'system', 'content': system_prompt},&#10;            {&#10;                'role': 'user',&#10;                'content': (&#10;                    f&quot;Case payload JSON:\n{json.dumps(payload)}\n\n&quot;&#10;                    f&quot;Recent chat history:\n{history_text}\n\n&quot;&#10;                    f&quot;User message:\n{user_content}\n\nRespond as the assistant.&quot;&#10;                )&#10;            }&#10;        ]&#10;&#10;        openai_payload = {&#10;            'model': 'gpt-4o-mini',&#10;            'input': input_messages&#10;        }&#10;&#10;        try:&#10;            openai_response = requests.post(&#10;                'https://api.openai.com/v1/responses',&#10;                headers={&#10;                    'Authorization': f'Bearer {OPENAI_API_KEY}',&#10;                    'Content-Type': 'application/json'&#10;                },&#10;                json=openai_payload,&#10;                timeout=(10, 60)&#10;            )&#10;&#10;            if not openai_response.ok:&#10;                error_text = openai_response.text&#10;                logger.error('OpenAI call failed', extra={'status': openai_response.status_code, 'error': error_text})&#10;                response = jsonify({'error': 'OpenAI call failed', 'details': error_text})&#10;                return add_cors_headers(response), 500&#10;&#10;            openai_json = openai_response.json()&#10;&#10;            # Extract assistant text from Responses API output safely&#10;            assistant_text = &quot;&quot;&#10;            output = openai_json.get('output')&#10;            if isinstance(output, list):&#10;                for item in output:&#10;                    content = item.get('content') if item else None&#10;                    if isinstance(content, list):&#10;                        for c in content:&#10;                            if (c and c.get('type') == 'output_text' and&#10;                                isinstance(c.get('text'), str)):&#10;                                assistant_text = c['text']&#10;                                break&#10;                        if assistant_text:&#10;                            break&#10;&#10;            assistant_text = clamp_text(&#10;                assistant_text or &quot;I can help—what do you want to do next?&quot;,&#10;                2000&#10;            )&#10;&#10;        except Exception as e:&#10;            logger.error('OpenAI API error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'OpenAI API error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 5) Save assistant message&#10;        assistant_message_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        assistant_message_data = {&#10;            'token': token,&#10;            'role': 'assistant',&#10;            'content': assistant_text&#10;        }&#10;        assistant_message_headers = supabase_headers()&#10;        assistant_message_headers['Prefer'] = 'return=representation'&#10;&#10;        try:&#10;            assistant_message_response = requests.post(assistant_message_url, headers=assistant_message_headers,&#10;                                                     json=assistant_message_data, timeout=TIMEOUT)&#10;            assistant_message_response.raise_for_status()&#10;            assistant_insert = assistant_message_response.json()&#10;            assistant_message = assistant_insert[0] if assistant_insert else None&#10;        except Exception as e:&#10;            logger.error('Failed to save assistant message', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to save assistant message'})&#10;            return add_cors_headers(response), 500&#10;&#10;        response = jsonify({&#10;            'ok': True,&#10;            'token': token,&#10;            'user_message': user_message,&#10;            'assistant_message': assistant_message&#10;        })&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('send-message error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/start-extraction', methods=['POST', 'OPTIONS'])&#10;def start_extraction():&#10;    &quot;&quot;&quot;Document extraction start endpoint (converted from Deno/TypeScript start-extraction function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    def safe_trim(v) -&gt; str:&#10;        return str(v or '').strip()&#10;&#10;    logger.info(f&quot;[{datetime.utcnow().isoformat()}] {request.method} {request.url}&quot;)&#10;&#10;    if request.method != 'POST':&#10;        response = jsonify({'error': 'Method not allowed'})&#10;        return add_cors_headers(response), 405&#10;&#10;    try:&#10;        # Environment variables check&#10;        WEBHOOK_URL = os.environ.get('DOC_EXTRACT_WEBHOOK_URL', f&quot;{request.url_root.rstrip('/')}/webhooks/doc-extract&quot;)&#10;        WEBHOOK_SECRET = os.environ.get('DOC_EXTRACT_WEBHOOK_SECRET')&#10;        DOC_BUCKET = os.environ.get('DOC_EXTRACT_BUCKET', 'dmhoa-docs')&#10;&#10;        logger.info('Env check', extra={&#10;            'hasUrl': bool(SUPABASE_URL),&#10;            'hasServiceRole': bool(SUPABASE_SERVICE_ROLE_KEY),&#10;            'hasWebhookUrl': bool(WEBHOOK_URL),&#10;            'hasWebhookSecret': bool(DOC_EXTRACT_WEBHOOK_SECRET),&#10;            'bucket': DOC_BUCKET&#10;        })&#10;&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing SUPABASE env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not WEBHOOK_URL or not WEBHOOK_SECRET:&#10;            response = jsonify({'error': 'Missing webhook env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Validate secret header&#10;        incoming_secret = request.headers.get('x-doc-secret', '').strip()&#10;        if not incoming_secret or incoming_secret != WEBHOOK_SECRET:&#10;            logger.error('Unauthorized - secret mismatch')&#10;            response = jsonify({'error': 'Unauthorized'})&#10;            return add_cors_headers(response), 401&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = safe_trim(body.get('token'))&#10;        storage_path = safe_trim(body.get('storage_path'))&#10;        filename = safe_trim(body.get('filename')) or None&#10;        mime_type = safe_trim(body.get('mime_type')) or None&#10;&#10;        if not token or not storage_path:&#10;            response = jsonify({'error': 'token and storage_path are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Ensure case exists (fail fast)&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,payload,created_at'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Case lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found', 'token': token})&#10;            return add_cors_headers(response), 404&#10;&#10;        # 1) Create (or reuse) a dmhoa_documents row for this file&#10;        document_id = None&#10;&#10;        # Check for existing document&#10;        doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        doc_params = {&#10;            'token': f'eq.{token}',&#10;            'path': f'eq.{storage_path}',&#10;            'select': 'id,status'&#10;        }&#10;        doc_headers = supabase_headers()&#10;&#10;        try:&#10;            doc_response = requests.get(doc_url, params=doc_params, headers=doc_headers, timeout=TIMEOUT)&#10;            doc_response.raise_for_status()&#10;            docs = doc_response.json()&#10;            existing_doc = docs[0] if docs else None&#10;        except Exception as e:&#10;            logger.error('Doc lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading document', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if existing_doc and existing_doc.get('id'):&#10;            document_id = existing_doc['id']&#10;            logger.info('Reusing existing dmhoa_documents row', extra={&#10;                'document_id': document_id,&#10;                'status': existing_doc.get('status')&#10;            })&#10;        else:&#10;            # Insert new document&#10;            insert_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            insert_doc_data = {&#10;                'token': token,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'filename': filename,&#10;                'mime_type': mime_type,&#10;                'status': 'pending'&#10;            }&#10;            insert_doc_headers = supabase_headers()&#10;            insert_doc_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_doc_response = requests.post(insert_doc_url, headers=insert_doc_headers,&#10;                                                  json=insert_doc_data, timeout=TIMEOUT)&#10;                insert_doc_response.raise_for_status()&#10;                inserted_docs = insert_doc_response.json()&#10;                document_id = inserted_docs[0]['id'] if inserted_docs else None&#10;                logger.info('Created dmhoa_documents row', extra={'document_id': document_id})&#10;            except Exception as e:&#10;                logger.error('Doc insert error', extra={'error': str(e)})&#10;                response = jsonify({'error': 'Failed to create dmhoa_documents row', 'details': str(e)})&#10;                return add_cors_headers(response), 500&#10;&#10;        if not document_id:&#10;            response = jsonify({'error': 'Could not determine document_id'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 2) Update case payload summary status (optional, but useful for UI)&#10;        current_payload = {}&#10;        try:&#10;            payload_data = case_row.get('payload')&#10;            if isinstance(payload_data, str):&#10;                current_payload = json.loads(payload_data)&#10;            elif isinstance(payload_data, dict):&#10;                current_payload = payload_data&#10;        except Exception:&#10;            current_payload = {}&#10;&#10;        next_payload = {&#10;            **current_payload,&#10;            'extract_status': 'triggered',&#10;            'notice_storage_path': storage_path,&#10;            'notice_filename': filename,&#10;            'notice_mime_type': mime_type,&#10;            'extract_triggered_at': datetime.utcnow().isoformat(),&#10;            'document_id': document_id&#10;        }&#10;&#10;        # Update case payload&#10;        update_case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        update_case_params = {'token': f'eq.{token}'}&#10;        update_case_data = {'payload': next_payload}&#10;        update_case_headers = supabase_headers()&#10;&#10;        try:&#10;            update_case_response = requests.patch(update_case_url, params=update_case_params,&#10;                                                headers=update_case_headers, json=update_case_data, timeout=TIMEOUT)&#10;            update_case_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Case payload update error', extra={'error': str(e)})&#10;            # Not fatal—doc record exists and webhook can still run&#10;&#10;        # 3) Mark document processing BEFORE webhook&#10;        mark_proc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        mark_proc_params = {'id': f'eq.{document_id}'}&#10;        mark_proc_data = {'status': 'processing', 'error': None}&#10;        mark_proc_headers = supabase_headers()&#10;&#10;        try:&#10;            mark_proc_response = requests.patch(mark_proc_url, params=mark_proc_params,&#10;                                              headers=mark_proc_headers, json=mark_proc_data, timeout=TIMEOUT)&#10;            mark_proc_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Failed to mark document processing', extra={'error': str(e)})&#10;            # Not fatal, but you'll want to know&#10;&#10;        # 4) Call backend webhook (server-to-server)&#10;        logger.info('Calling webhook', extra={'webhook_url': WEBHOOK_URL})&#10;&#10;        webhook_payload = {&#10;            'token': token,&#10;            'document_id': document_id,&#10;            'bucket': DOC_BUCKET,&#10;            'path': storage_path,&#10;            'filename': filename,&#10;            'mime_type': mime_type,&#10;            'supabase_url': SUPABASE_URL  # optional&#10;        }&#10;&#10;        webhook_headers = {&#10;            'Content-Type': 'application/json',&#10;            'X-Webhook-Secret': WEBHOOK_SECRET,&#10;            'X-Doc-Extract-Secret': WEBHOOK_SECRET  # Alternative header name&#10;        }&#10;&#10;        try:&#10;            webhook_response = requests.post(WEBHOOK_URL, headers=webhook_headers,&#10;                                           json=webhook_payload, timeout=(10, 120))  # Longer timeout for processing&#10;&#10;            logger.info('Webhook response', extra={'status': webhook_response.status_code, 'ok': webhook_response.ok})&#10;&#10;            if not webhook_response.ok:&#10;                error_text = webhook_response.text&#10;                logger.error('Webhook failed', extra={'error': error_text})&#10;&#10;                # Update document status to failed&#10;                fail_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;                fail_doc_params = {'id': f'eq.{document_id}'}&#10;                fail_doc_data = {&#10;                    'status': 'failed',&#10;                    'error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500]&#10;                }&#10;                fail_doc_headers = supabase_headers()&#10;&#10;                try:&#10;                    requests.patch(fail_doc_url, params=fail_doc_params,&#10;                                 headers=fail_doc_headers, json=fail_doc_data, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                # Also reflect summary status on the case payload (optional)&#10;                fail_payload = {&#10;                    **next_payload,&#10;                    'extract_status': 'failed',&#10;                    'extract_error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500],&#10;                    'extract_failed_at': datetime.utcnow().isoformat()&#10;                }&#10;&#10;                try:&#10;                    requests.patch(update_case_url, params=update_case_params,&#10;                                 headers=update_case_headers, json={'payload': fail_payload}, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                response = jsonify({&#10;                    'error': 'Webhook call failed',&#10;                    'status': webhook_response.status_code,&#10;                    'details': error_text&#10;                })&#10;                return add_cors_headers(response), 502&#10;&#10;            # If webhook returns JSON, capture it (optional)&#10;            try:&#10;                webhook_json = webhook_response.json()&#10;            except Exception:&#10;                webhook_json = {}&#10;&#10;            # Mark queued/accepted (document is now in backend pipeline)&#10;            queue_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            queue_doc_params = {'id': f'eq.{document_id}'}&#10;            queue_doc_data = {'status': 'processing'}&#10;            queue_doc_headers = supabase_headers()&#10;&#10;            try:&#10;                requests.patch(queue_doc_url, params=queue_doc_params,&#10;                             headers=queue_doc_headers, json=queue_doc_data, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            ok_payload = {&#10;                **next_payload,&#10;                'extract_status': 'queued',&#10;                'webhook_response': webhook_json,&#10;                'extract_queued_at': datetime.utcnow().isoformat()&#10;            }&#10;&#10;            try:&#10;                requests.patch(update_case_url, params=update_case_params,&#10;                             headers=update_case_headers, json={'payload': ok_payload}, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            response = jsonify({&#10;                'ok': True,&#10;                'token': token,&#10;                'document_id': document_id,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'webhook': webhook_json&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        except Exception as e:&#10;            logger.error('Webhook request failed', extra={'error': str(e)})&#10;            response = jsonify({'error': f'Webhook request failed: {str(e)}'})&#10;            return add_cors_headers(response), 502&#10;&#10;    except Exception as e:&#10;        logger.error('Unexpected error in start-extraction', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/webhooks/stripe', methods=['POST'])&#10;def stripe_webhook():&#10;    &quot;&quot;&quot;Stripe webhook handler for processing payment events (converted from Deno/TypeScript)&quot;&quot;&quot;&#10;    try:&#10;        # Environment variables validation&#10;        if not STRIPE_SECRET_KEY or not STRIPE_WEBHOOK_SECRET or not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            logger.error(&quot;Missing required environment variables&quot;, extra={&#10;                'hasStripeKey': bool(STRIPE_SECRET_KEY),&#10;                'hasWebhookSecret': bool(STRIPE_WEBHOOK_SECRET),&#10;                'hasSupabaseUrl': bool(SUPABASE_URL),&#10;                'hasServiceRole': bool(SUPABASE_SERVICE_ROLE_KEY),&#10;            })&#10;            return jsonify({'error': 'Missing environment variables'}), 500&#10;&#10;        # Get raw body and signature&#10;        payload = request.get_data()&#10;        sig_header = request.headers.get('stripe-signature')&#10;&#10;        if not sig_header:&#10;            return jsonify({'error': 'No signature'}), 400&#10;&#10;        # Verify webhook signature&#10;        try:&#10;            event = stripe.Webhook.construct_event(&#10;                payload, sig_header, STRIPE_WEBHOOK_SECRET&#10;            )&#10;        except ValueError:&#10;            logger.error(&quot;Invalid payload&quot;)&#10;            return jsonify({'error': 'Invalid payload'}), 400&#10;        except stripe.error.SignatureVerificationError:&#10;            logger.error(&quot;Invalid signature&quot;)&#10;            return jsonify({'error': 'Invalid signature'}), 400&#10;&#10;        logger.info(f&quot;Webhook event type: {event['type']}&quot;)&#10;&#10;        if event['type'] == 'checkout.session.completed':&#10;            session = event['data']['object']&#10;&#10;            # Get token from client_reference_id or metadata&#10;            token = session.get('client_reference_id') or session.get('metadata', {}).get('token')&#10;            if not token:&#10;                return jsonify({'error': 'No token in session'}), 400&#10;&#10;            # Get email (prefer customer_details.email)&#10;            email = (&#10;                session.get('customer_details', {}).get('email') or&#10;                session.get('customer_email') or&#10;                None&#10;            )&#10;&#10;            logger.info(f&quot;Processing payment completion for token: {token}&quot;)&#10;&#10;            # Update case to unlocked&#10;            case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            case_params = {'token': f'eq.{token}'}&#10;            case_data = {&#10;                'unlocked': True,&#10;                'status': 'paid',&#10;                'stripe_checkout_session_id': session['id'],&#10;                'stripe_payment_intent_id': session.get('payment_intent'),&#10;                'amount_total': session.get('amount_total'),&#10;                'currency': session.get('currency'),&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            case_headers = supabase_headers()&#10;            case_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                case_response = requests.patch(case_url, params=case_params, headers=case_headers,&#10;                                             json=case_data, timeout=TIMEOUT)&#10;                case_response.raise_for_status()&#10;                updated_cases = case_response.json()&#10;&#10;                if not updated_cases:&#10;                    logger.error(f&quot;Case not found for token: {token}&quot;)&#10;                    return jsonify({'error': 'Case not found'}), 404&#10;&#10;                updated_case = updated_cases[0]&#10;                logger.info(f&quot;Successfully updated case: {updated_case.get('id')}&quot;)&#10;&#10;                # Fallback email from DB if Stripe didn't provide it&#10;                if not email:&#10;                    email = updated_case.get('email')&#10;&#10;            except Exception as e:&#10;                logger.error(f&quot;Failed to update case: {str(e)}&quot;)&#10;                return jsonify({'error': 'Database update failed'}), 500&#10;&#10;            # --- Send receipt email (non-fatal) ---&#10;            if not email:&#10;                logger.warning(&quot;No email available (Stripe + DB). Skipping receipt email send.&quot;)&#10;            elif not SMTP_SENDER_WEBHOOK_URL or not SMTP_SENDER_WEBHOOK_SECRET:&#10;                logger.warning(&quot;SMTP sender webhook env vars missing; skipping email send&quot;)&#10;            else:&#10;                case_url_link = f&quot;{SITE_URL}/case.html?case={token}&quot;&#10;                email_payload = {&#10;                    'token': token,&#10;                    'email': email,&#10;                    'case_url': case_url_link,&#10;                    'amount_total': session.get('amount_total'),&#10;                    'currency': session.get('currency'),&#10;                    'customer_name': session.get('customer_details', {}).get('name'),&#10;                    'stripe_session_id': session['id']&#10;                }&#10;&#10;                try:&#10;                    email_response = requests.post(&#10;                        SMTP_SENDER_WEBHOOK_URL,&#10;                        headers={&#10;                            'Content-Type': 'application/json',&#10;                            'X-Webhook-Secret': SMTP_SENDER_WEBHOOK_SECRET&#10;                        },&#10;                        json=email_payload,&#10;                        timeout=TIMEOUT&#10;                    )&#10;&#10;                    if not email_response.ok:&#10;                        error_text = email_response.text&#10;                        logger.warning(f&quot;Receipt email send failed (non-fatal): {email_response.status_code}, {error_text}&quot;)&#10;&#10;                        # Log failed email event&#10;                        try:&#10;                            event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;                            event_data = {&#10;                                'token': token,&#10;                                'type': 'receipt_email_failed',&#10;                                'data': {&#10;                                    'status': email_response.status_code,&#10;                                    'body': error_text[:1000]&#10;                                }&#10;                            }&#10;                            event_headers = supabase_headers()&#10;                            requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;                        except Exception:&#10;                            pass  # Best effort&#10;                    else:&#10;                        # Log successful email event&#10;                        try:&#10;                            event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;                            event_data = {&#10;                                'token': token,&#10;                                'type': 'receipt_email_sent',&#10;                                'data': {&#10;                                    'to': email,&#10;                                    'case_url': case_url_link&#10;                                }&#10;                            }&#10;                            event_headers = supabase_headers()&#10;                            requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;                        except Exception:&#10;                            pass  # Best effort&#10;&#10;                except Exception as e:&#10;                    logger.warning(f&quot;Receipt email send threw (non-fatal): {str(e)}&quot;)&#10;                    # Log error event&#10;                    try:&#10;                        event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;                        event_data = {&#10;                            'token': token,&#10;                            'type': 'receipt_email_failed',&#10;                            'data': {&#10;                                'error': str(e)[:1000]&#10;                            }&#10;                        }&#10;                        event_headers = supabase_headers()&#10;                        requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;                    except Exception:&#10;                        pass  # Best effort&#10;&#10;            # Log payment completion event (also non-fatal)&#10;            try:&#10;                event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;                event_data = {&#10;                    'token': token,&#10;                    'type': 'payment_completed',&#10;                    'data': {&#10;                        'session_id': session['id'],&#10;                        'payment_intent': session.get('payment_intent'),&#10;                        'amount_total': session.get('amount_total'),&#10;                        'currency': session.get('currency'),&#10;                        'customer_email': session.get('customer_email'),&#10;                        'payment_status': session.get('payment_status')&#10;                    }&#10;                }&#10;                event_headers = supabase_headers()&#10;                requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;            except Exception as e:&#10;                logger.warning(f&quot;Failed to log payment_completed event (non-fatal): {str(e)}&quot;)&#10;&#10;            logger.info(f&quot;Payment completion processed successfully for token: {token}&quot;)&#10;&#10;        return jsonify({'received': True}), 200&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Webhook error: {str(e)}&quot;)&#10;        return jsonify({'error': 'Webhook error'}), 500&#10;" />
              <option name="updatedContent" value="import os&#10;import io&#10;import json&#10;import logging&#10;from typing import Dict, Any, Optional, Tuple, List&#10;import re&#10;from datetime import datetime&#10;import threading&#10;import time&#10;&#10;import requests&#10;from flask import Flask, request, jsonify&#10;from pypdf import PdfReader&#10;import stripe&#10;&#10;import smtplib&#10;from email.mime.text import MIMEText&#10;from email.mime.multipart import MIMEMultipart&#10;&#10;# Image processing and OCR imports&#10;from PIL import Image&#10;import pytesseract&#10;&#10;&#10;# Configure logging&#10;logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')&#10;logger = logging.getLogger(__name__)&#10;&#10;app = Flask(__name__)&#10;&#10;# Configuration&#10;SUPABASE_URL = os.environ.get('SUPABASE_URL')&#10;SUPABASE_SERVICE_ROLE_KEY = os.environ.get('SUPABASE_SERVICE_ROLE_KEY')&#10;DOC_EXTRACT_WEBHOOK_SECRET = os.environ.get('DOC_EXTRACT_WEBHOOK_SECRET')&#10;&#10;# Stripe Configuration&#10;STRIPE_SECRET_KEY = os.environ.get('STRIPE_SECRET_KEY')&#10;STRIPE_WEBHOOK_SECRET = os.environ.get('STRIPE_WEBHOOK_SECRET')&#10;STRIPE_PRICE_ID = os.environ.get('STRIPE_PRICE_ID')&#10;SITE_URL = os.environ.get('SITE_URL', 'https://disputemyhoa.com')&#10;&#10;# OpenAI Configuration&#10;OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')&#10;&#10;# Configure Stripe&#10;if STRIPE_SECRET_KEY:&#10;    stripe.api_key = STRIPE_SECRET_KEY&#10;&#10;# SMTP Configuration - Optional, only needed for email functionality&#10;SMTP_HOST = os.environ.get(&quot;SMTP_HOST&quot;)&#10;SMTP_PORT = int(os.environ.get(&quot;SMTP_PORT&quot;, &quot;587&quot;))&#10;# Clean SMTP credentials to handle non-ASCII characters like non-breaking spaces&#10;SMTP_USER = (os.environ.get(&quot;SMTP_USER&quot;) or &quot;&quot;).strip().replace('\xa0', ' ')&#10;SMTP_PASS = (os.environ.get(&quot;SMTP_PASS&quot;) or &quot;&quot;).strip().replace('\xa0', ' ')&#10;SMTP_FROM = os.environ.get(&quot;SMTP_FROM&quot;, &quot;support@disputemyhoa.com&quot;)&#10;&#10;SMTP_SENDER_WEBHOOK_SECRET = os.environ.get(&quot;SMTP_SENDER_WEBHOOK_SECRET&quot;)&#10;SMTP_SENDER_WEBHOOK_URL = os.environ.get(&quot;SMTP_SENDER_WEBHOOK_URL&quot;)&#10;&#10;# Request timeouts&#10;TIMEOUT = (5, 60)  # (connect, read)&#10;&#10;def supabase_headers() -&gt; Dict[str, str]:&#10;    &quot;&quot;&quot;Return headers for Supabase API requests.&quot;&quot;&quot;&#10;    return {&#10;        'apikey': SUPABASE_SERVICE_ROLE_KEY,&#10;        'Authorization': f'Bearer {SUPABASE_SERVICE_ROLE_KEY}',&#10;        'Content-Type': 'application/json'&#10;    }&#10;&#10;def fetch_document_status(document_id: str) -&gt; Optional[Dict[str, Any]]:&#10;    &quot;&quot;&quot;Fetch current document status from Supabase.&quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        params = {&#10;            'id': f'eq.{document_id}',&#10;            'select': 'id,token,status'&#10;        }&#10;        headers = supabase_headers()&#10;&#10;        response = requests.get(url, params=params, headers=headers, timeout=TIMEOUT)&#10;        response.raise_for_status()&#10;&#10;        data = response.json()&#10;        return data[0] if data else None&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Failed to fetch document status for {document_id}: {str(e)}&quot;)&#10;        return None&#10;&#10;def update_document(document_id: str, token: str, updates: Dict[str, Any]) -&gt; bool:&#10;    &quot;&quot;&quot;Update document in Supabase database.&quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        params = {&#10;            'id': f'eq.{document_id}',&#10;            'token': f'eq.{token}'&#10;        }&#10;        headers = supabase_headers()&#10;        headers['Prefer'] = 'return=representation'&#10;&#10;        response = requests.patch(url, params=params, headers=headers,&#10;                                json=updates, timeout=TIMEOUT)&#10;        response.raise_for_status()&#10;&#10;        logger.info(f&quot;Updated document {document_id} with: {updates}&quot;)&#10;        return True&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Failed to update document {document_id}: {str(e)}&quot;)&#10;        return False&#10;&#10;def download_storage_object(bucket: str, path: str) -&gt; Optional[bytes]:&#10;    &quot;&quot;&quot;Download file from Supabase Storage.&quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/storage/v1/object/{bucket}/{path}&quot;&#10;        headers = {&#10;            'apikey': SUPABASE_SERVICE_ROLE_KEY,&#10;            'Authorization': f'Bearer {SUPABASE_SERVICE_ROLE_KEY}'&#10;        }&#10;&#10;        response = requests.get(url, headers=headers, timeout=TIMEOUT)&#10;&#10;        if response.status_code == 404:&#10;            logger.error(f&quot;File not found: {bucket}/{path}&quot;)&#10;            return None&#10;&#10;        response.raise_for_status()&#10;&#10;        logger.info(f&quot;Downloaded {len(response.content)} bytes from {bucket}/{path}&quot;)&#10;        return response.content&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Failed to download {bucket}/{path}: {str(e)}&quot;)&#10;        return None&#10;&#10;def extract_pdf_text(pdf_bytes: bytes) -&gt; Tuple[str, int, int, Optional[str]]:&#10;    &quot;&quot;&quot;&#10;    Extract text from PDF bytes.&#10;    Returns: (extracted_text, page_count, char_count, error_message)&#10;    &quot;&quot;&quot;&#10;    try:&#10;        reader = PdfReader(io.BytesIO(pdf_bytes))&#10;        page_count = len(reader.pages)&#10;&#10;        text_parts = []&#10;        for page in reader.pages:&#10;            try:&#10;                page_text = page.extract_text() or &quot;&quot;&#10;                text_parts.append(page_text)&#10;            except Exception as e:&#10;                logger.warning(f&quot;Failed to extract text from page: {str(e)}&quot;)&#10;                text_parts.append(&quot;&quot;)&#10;&#10;        extracted_text = &quot;\n\n&quot;.join(text_parts)&#10;        char_count = len(extracted_text)&#10;&#10;        # Check if text is empty or only whitespace&#10;        if not extracted_text or extracted_text.strip() == &quot;&quot;:&#10;            return &quot;&quot;, page_count, 0, &quot;No text layer found - document may be scanned and require OCR&quot;&#10;&#10;        logger.info(f&quot;Extracted {char_count} characters from {page_count} pages&quot;)&#10;        return extracted_text, page_count, char_count, None&#10;&#10;    except Exception as e:&#10;        error_msg = f&quot;Failed to extract text from PDF: {str(e)}&quot;&#10;        logger.error(error_msg)&#10;        return &quot;&quot;, 0, 0, error_msg&#10;&#10;&#10;def extract_image_text(image_bytes: bytes, filename: str = &quot;&quot;) -&gt; Tuple[str, int, int, Optional[str]]:&#10;    &quot;&quot;&quot;&#10;    Extract text from image bytes using OCR.&#10;    Returns: (extracted_text, page_count=1, char_count, error_message)&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Open image from bytes&#10;        image = Image.open(io.BytesIO(image_bytes))&#10;&#10;        # Convert to RGB if necessary (some formats like RGBA or P need conversion)&#10;        if image.mode not in ('RGB', 'L'):&#10;            image = image.convert('RGB')&#10;&#10;        logger.info(f&quot;Processing image: {image.size[0]}x{image.size[1]} pixels, mode: {image.mode}&quot;)&#10;&#10;        # Set TESSDATA_PREFIX if not already set (for Heroku compatibility)&#10;        if 'TESSDATA_PREFIX' not in os.environ:&#10;            possible_paths = [&#10;                '/usr/share/tesseract-ocr/5/tessdata',&#10;                '/usr/share/tesseract-ocr/tessdata',&#10;                '/usr/share/tessdata',&#10;                '/app/.apt/usr/share/tesseract-ocr/5/tessdata',&#10;                '/app/.apt/usr/share/tesseract-ocr/tessdata'&#10;            ]&#10;            for path in possible_paths:&#10;                if os.path.exists(path):&#10;                    os.environ['TESSDATA_PREFIX'] = path&#10;                    logger.info(f&quot;Set TESSDATA_PREFIX to: {path}&quot;)&#10;                    break&#10;            else:&#10;                logger.warning(&quot;Could not find tessdata directory in any expected location&quot;)&#10;&#10;        # Try multiple OCR configurations for better compatibility&#10;        configs_to_try = [&#10;            r'--oem 1 --psm 1 -l eng',   # Automatic page segmentation with OSD&#10;            r'--oem 1 --psm 3 -l eng',   # Fully automatic page segmentation, but no OSD&#10;            r'--oem 1 --psm 4 -l eng',   # Assume a single column of text of variable sizes&#10;            r'--oem 1 --psm 6 -l eng',   # Assume a single uniform block of text&#10;            r'--oem 3 --psm 1 -l eng',   # LSTM with automatic page segmentation&#10;            r'--oem 3 --psm 3 -l eng',   # LSTM with fully automatic page segmentation&#10;            r'--oem 3 --psm 6 -l eng',   # LSTM standard config&#10;            r'--oem 3 --psm 11 -l eng',  # Sparse text - find as much text as possible&#10;            r'--oem 3 --psm 12 -l eng',  # Sparse text with OSD&#10;            r'--psm 6',                  # No language specified fallback&#10;        ]&#10;&#10;        extracted_text = &quot;&quot;&#10;        best_text = &quot;&quot;&#10;        best_char_count = 0&#10;        last_error = None&#10;&#10;        for config in configs_to_try:&#10;            try:&#10;                logger.info(f&quot;Trying OCR with config: {config}&quot;)&#10;                current_text = pytesseract.image_to_string(image, config=config)&#10;                current_text = current_text.strip()&#10;                char_count = len(current_text)&#10;&#10;                # Keep track of the best result (most text that looks reasonable)&#10;                if char_count &gt; best_char_count:&#10;                    # Basic heuristic: prefer results with more alphanumeric content&#10;                    alphanumeric_ratio = sum(c.isalnum() or c.isspace() for c in current_text) / max(len(current_text), 1)&#10;                    if alphanumeric_ratio &gt; 0.3:  # At least 30% should be readable characters&#10;                        best_text = current_text&#10;                        best_char_count = char_count&#10;                        logger.info(f&quot;New best result: {char_count} chars, {alphanumeric_ratio:.2f} alphanumeric ratio&quot;)&#10;&#10;                # If we got a decent amount of readable text, we can stop&#10;                if char_count &gt; 50 and best_text:&#10;                    extracted_text = best_text&#10;                    break&#10;&#10;            except Exception as e:&#10;                last_error = str(e)&#10;                logger.warning(f&quot;OCR config failed: {config}, error: {str(e)}&quot;)&#10;                continue&#10;&#10;        # Use the best result we found&#10;        if not extracted_text and best_text:&#10;            extracted_text = best_text&#10;&#10;        # Clean up the extracted text&#10;        extracted_text = extracted_text.strip()&#10;        char_count = len(extracted_text)&#10;&#10;        if char_count == 0:&#10;            error_msg = f&quot;No text found in image - image may be blank or contain no readable text. Last OCR error: {last_error}&quot;&#10;            return &quot;&quot;, 1, 0, error_msg&#10;&#10;        logger.info(f&quot;OCR extracted {char_count} characters from image {filename}&quot;)&#10;        return extracted_text, 1, char_count, None&#10;&#10;    except Exception as e:&#10;        error_msg = f&quot;Failed to extract text from image: {str(e)}&quot;&#10;        logger.error(error_msg)&#10;        return &quot;&quot;, 0, 0, error_msg&#10;&#10;&#10;def is_image_file(filename: str, mime_type: str = &quot;&quot;) -&gt; bool:&#10;    &quot;&quot;&quot;Check if file is a supported image format.&quot;&quot;&quot;&#10;    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.tif', '.webp'}&#10;    image_mime_types = {&#10;        'image/jpeg', 'image/jpg', 'image/png', 'image/gif',&#10;        'image/bmp', 'image/tiff', 'image/webp'&#10;    }&#10;&#10;    # Check by file extension&#10;    if filename:&#10;        ext = os.path.splitext(filename.lower())[1]&#10;        if ext in image_extensions:&#10;            return True&#10;&#10;    # Check by MIME type&#10;    if mime_type and mime_type.lower() in image_mime_types:&#10;        return True&#10;&#10;    return False&#10;&#10;&#10;def is_pdf_file(filename: str, mime_type: str = &quot;&quot;) -&gt; bool:&#10;    &quot;&quot;&quot;Check if file is a PDF.&quot;&quot;&quot;&#10;    if filename and filename.lower().endswith('.pdf'):&#10;        return True&#10;    if mime_type and mime_type.lower() == 'application/pdf':&#10;        return True&#10;    return False&#10;&#10;&#10;@app.route('/health', methods=['GET'])&#10;def health_check():&#10;    &quot;&quot;&quot;Health check endpoint.&quot;&quot;&quot;&#10;    return jsonify({'status': 'healthy'}), 200&#10;&#10;&#10;@app.route('/debug/env', methods=['GET'])&#10;def debug_env():&#10;    &quot;&quot;&quot;Return presence of critical env vars (gated by DOC_EXTRACT_WEBHOOK_SECRET).&#10;&#10;    This does NOT return any secret values, only boolean flags indicating whether each&#10;    required configuration item is set. Intended for quick diagnostics on deployed app.&#10;    &quot;&quot;&quot;&#10;    secret = request.headers.get('X-Webhook-Secret')&#10;    if not secret or secret != DOC_EXTRACT_WEBHOOK_SECRET:&#10;        logger.warning(&quot;Unauthorized request to /debug/env&quot;)&#10;        return jsonify({'error': 'Unauthorized'}), 401&#10;&#10;    keys = [&#10;        'SUPABASE_URL', 'SUPABASE_SERVICE_ROLE_KEY', 'DOC_EXTRACT_WEBHOOK_SECRET',&#10;        'SMTP_HOST', 'SMTP_PORT', 'SMTP_USER', 'SMTP_PASS', 'SMTP_FROM', 'SMTP_SENDER_WEBHOOK_SECRET'&#10;    ]&#10;    presence = {k: bool(os.environ.get(k)) for k in keys}&#10;    logger.info(f&quot;/debug/env requested; presence: { {k: presence[k] for k in presence} }&quot;)&#10;    return jsonify({'env_presence': presence}), 200&#10;&#10;@app.route('/webhooks/doc-extract', methods=['POST'])&#10;def doc_extract_webhook():&#10;    &quot;&quot;&quot;Main webhook endpoint for document extraction.&quot;&quot;&quot;&#10;    # Validate webhook secret&#10;    webhook_secret = request.headers.get('X-Webhook-Secret')&#10;    if not webhook_secret or webhook_secret != DOC_EXTRACT_WEBHOOK_SECRET:&#10;        logger.warning(&quot;Invalid or missing webhook secret&quot;)&#10;        return jsonify({'error': 'Unauthorized'}), 401&#10;&#10;    document_id = None&#10;    token = None&#10;&#10;    try:&#10;        # Parse JSON body&#10;        data = request.get_json()&#10;        if not data:&#10;            return jsonify({'error': 'Invalid JSON body'}), 400&#10;&#10;        # Validate required fields&#10;        required_fields = ['token', 'document_id', 'bucket', 'path']&#10;        missing_fields = [field for field in required_fields if not data.get(field)]&#10;        if missing_fields:&#10;            return jsonify({&#10;                'error': f'Missing required fields: {&quot;, &quot;.join(missing_fields)}'&#10;            }), 400&#10;&#10;        token = data['token']&#10;        document_id = data['document_id']&#10;        bucket = data['bucket']&#10;        path = data['path']&#10;        filename = data.get('filename', '') or ''  # Handle null values&#10;        mime_type = data.get('mime_type', '') or ''  # Handle null values&#10;&#10;        logger.info(f&quot;Processing document extraction - ID: {document_id}, Token: {token[:8]}...&quot;)&#10;        logger.info(f&quot;Raw payload data - filename: {repr(filename)}, mime_type: {repr(mime_type)}, path: {path}&quot;)&#10;&#10;        # Check if document is already processed&#10;        current_doc = fetch_document_status(document_id)&#10;        if current_doc and current_doc.get('status') == 'ready':&#10;            logger.info(f&quot;Document {document_id} already processed&quot;)&#10;            return jsonify({&#10;                'message': 'Document already processed',&#10;                'document_id': document_id,&#10;                'status': 'ready'&#10;            }), 200&#10;&#10;        # Mark document as processing&#10;        if not update_document(document_id, token, {'status': 'processing'}):&#10;            return jsonify({&#10;                'error': 'Failed to update document status to processing',&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        # Download file from Supabase Storage&#10;        file_bytes = download_storage_object(bucket, path)&#10;        if file_bytes is None:&#10;            error_msg = f&quot;Failed to download file from {bucket}/{path}&quot;&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': error_msg[:2000]&#10;            })&#10;            return jsonify({&#10;                'error': error_msg,&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        # Determine file type with multiple fallback strategies&#10;        logger.info(f&quot;Initial file detection - filename: '{filename}', mime_type: '{mime_type}'&quot;)&#10;&#10;        # Strategy 1: If filename is empty/null, extract from path&#10;        if not filename or filename.lower() == 'null':&#10;            filename = os.path.basename(path)&#10;            logger.info(f&quot;Extracted filename from path: '{filename}'&quot;)&#10;&#10;        # Strategy 2: If mime_type is empty/null, guess from filename&#10;        if not mime_type or mime_type.lower() == 'null':&#10;            if filename:&#10;                ext = os.path.splitext(filename.lower())[1]&#10;                mime_type_map = {&#10;                    '.pdf': 'application/pdf',&#10;                    '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg',&#10;                    '.png': 'image/png', '.gif': 'image/gif',&#10;                    '.bmp': 'image/bmp', '.tiff': 'image/tiff', '.tif': 'image/tiff',&#10;                    '.webp': 'image/webp'&#10;                }&#10;                mime_type = mime_type_map.get(ext, '')&#10;                logger.info(f&quot;Guessed MIME type from extension '{ext}': '{mime_type}'&quot;)&#10;&#10;        # Strategy 3: If still no filename, try extracting just the filename from the full path&#10;        if not filename:&#10;            # Handle paths like &quot;dmhoa-docs/case_xxx/original/image.jpg&quot;&#10;            path_parts = path.split('/')&#10;            if path_parts:&#10;                filename = path_parts[-1]  # Get the last part&#10;                logger.info(f&quot;Extracted filename from path parts: '{filename}'&quot;)&#10;&#10;        # Strategy 4: If we still have no clear type, try to detect from file content&#10;        detected_type = None&#10;        if not (is_pdf_file(filename, mime_type) or is_image_file(filename, mime_type)):&#10;            # Check file magic bytes as last resort&#10;            if file_bytes and len(file_bytes) &gt;= 4:&#10;                # PDF magic bytes&#10;                if file_bytes.startswith(b'%PDF'):&#10;                    detected_type = 'pdf'&#10;                    logger.info(&quot;Detected PDF from file magic bytes&quot;)&#10;                # JPEG magic bytes&#10;                elif file_bytes.startswith(b'\xff\xd8\xff'):&#10;                    detected_type = 'image'&#10;                    mime_type = 'image/jpeg'&#10;                    logger.info(&quot;Detected JPEG from file magic bytes&quot;)&#10;                # PNG magic bytes&#10;                elif file_bytes.startswith(b'\x89PNG'):&#10;                    detected_type = 'image'&#10;                    mime_type = 'image/png'&#10;                    logger.info(&quot;Detected PNG from file magic bytes&quot;)&#10;&#10;        logger.info(f&quot;Final file detection - filename: '{filename}', mime_type: '{mime_type}', detected_type: {detected_type}&quot;)&#10;&#10;        # Process based on detected file type&#10;        if is_pdf_file(filename, mime_type) or detected_type == 'pdf':&#10;            logger.info(f&quot;Processing as PDF: {filename}&quot;)&#10;            extracted_text, page_count, char_count, extraction_error = extract_pdf_text(file_bytes)&#10;        elif is_image_file(filename, mime_type) or detected_type == 'image':&#10;            logger.info(f&quot;Processing as image using OCR: {filename}&quot;)&#10;            extracted_text, page_count, char_count, extraction_error = extract_image_text(file_bytes, filename)&#10;        else:&#10;            error_msg = f&quot;Unsupported file type: filename='{filename}', mime_type='{mime_type}', path='{path}'. Supported formats: PDF, JPG, JPEG, PNG, GIF, BMP, TIFF, WEBP&quot;&#10;            logger.warning(error_msg)&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': error_msg[:2000]&#10;            })&#10;            return jsonify({&#10;                'error': error_msg,&#10;                'document_id': document_id&#10;            }, 400)&#10;&#10;        if extraction_error:&#10;            # Handle extraction failure&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': extraction_error[:2000],&#10;                'page_count': page_count&#10;            })&#10;            return jsonify({&#10;                'error': extraction_error,&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        if char_count == 0:&#10;            # Handle no text found case&#10;            error_msg = &quot;No text found in document - document may be blank or contain no readable text&quot;&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': error_msg,&#10;                'page_count': page_count,&#10;                'char_count': 0&#10;            })&#10;            return jsonify({&#10;                'error': error_msg,&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        # Update document with extracted text&#10;        success = update_document(document_id, token, {&#10;            'status': 'ready',&#10;            'extracted_text': extracted_text,&#10;            'page_count': page_count,&#10;            'char_count': char_count,&#10;            'error': None&#10;        })&#10;&#10;        if not success:&#10;            return jsonify({&#10;                'error': 'Failed to update document with extracted text',&#10;                'document_id': document_id&#10;            }), 500&#10;&#10;        file_type = &quot;PDF&quot; if is_pdf_file(filename, mime_type) else &quot;image&quot;&#10;        logger.info(f&quot;Successfully processed {file_type} document {document_id} - {page_count} pages, {char_count} characters&quot;)&#10;&#10;        return jsonify({&#10;            'message': f'{file_type} document processed successfully',&#10;            'document_id': document_id,&#10;            'status': 'ready',&#10;            'page_count': page_count,&#10;            'char_count': char_count,&#10;            'file_type': file_type.lower()&#10;        }), 200&#10;&#10;    except Exception as e:&#10;        error_msg = str(e)[:2000]  # Truncate error message&#10;        logger.error(f&quot;Unexpected error processing document: {error_msg}&quot;)&#10;&#10;        # Try to update document status to failed if we have the required data&#10;        if document_id and token:&#10;            update_document(document_id, token, {&#10;                'status': 'failed',&#10;                'error': error_msg&#10;            })&#10;            return jsonify({&#10;                'error': error_msg,&#10;                'document_id': document_id&#10;            }), 500&#10;        else:&#10;            return jsonify({'error': error_msg}), 500&#10;&#10;@app.route(&quot;/webhooks/send-receipt-email&quot;, methods=[&quot;POST&quot;])&#10;def send_receipt_email():&#10;    secret = request.headers.get(&quot;X-Webhook-Secret&quot;)&#10;    logger.info(&quot;Received send-receipt-email webhook&quot;)&#10;&#10;    if not secret or secret != SMTP_SENDER_WEBHOOK_SECRET:&#10;        logger.warning(&quot;Unauthorized send-receipt-email attempt: missing or invalid webhook secret&quot;)&#10;        return jsonify({&quot;error&quot;: &quot;Unauthorized&quot;}), 401&#10;&#10;    # Check which SMTP environment variables are missing so we can diagnose quickly&#10;    required = {&#10;        'SMTP_HOST': SMTP_HOST,&#10;        'SMTP_PORT': SMTP_PORT,&#10;        'SMTP_USER': SMTP_USER,&#10;        'SMTP_PASS': SMTP_PASS,&#10;        'SMTP_SENDER_WEBHOOK_SECRET': SMTP_SENDER_WEBHOOK_SECRET,&#10;    }&#10;    missing = [name for name, val in required.items() if not val]&#10;    if missing:&#10;        # Log the missing variable names (not their values) for diagnostics&#10;        logger.error(f&quot;SMTP not configured - missing environment variables: {missing}&quot;)&#10;        return jsonify({&quot;error&quot;: &quot;SMTP not configured&quot;, &quot;missing&quot;: missing}), 500&#10;&#10;    data = request.get_json() or {}&#10;    token = data.get(&quot;token&quot;)&#10;    to_email = data.get(&quot;email&quot;)&#10;    case_url = data.get(&quot;case_url&quot;)&#10;    amount_total = data.get(&quot;amount_total&quot;)&#10;    currency = (data.get(&quot;currency&quot;) or &quot;usd&quot;).upper()&#10;    customer_name = data.get(&quot;customer_name&quot;)&#10;    stripe_session_id = data.get(&quot;stripe_session_id&quot;)&#10;&#10;    logger.info(f&quot;send-receipt-email payload: token_present={bool(token)}, to_email={to_email}, case_url_present={bool(case_url)}, customer_name={customer_name}&quot;)&#10;&#10;    if not token or not to_email or not case_url:&#10;        logger.warning(&quot;send-receipt-email missing required fields&quot;)&#10;        return jsonify({&quot;error&quot;: &quot;Missing token/email/case_url&quot;}), 400&#10;&#10;    # Personalized greeting&#10;    greeting = f&quot;Hi {customer_name},&quot; if customer_name else &quot;Hi,&quot;&#10;&#10;    # Format payment amount&#10;    dollars = f&quot;${(amount_total or 0)/100:.2f}&quot; if isinstance(amount_total, int) else &quot;&quot;&#10;    payment_info = f&quot; for {dollars} {currency}&quot; if dollars else &quot;&quot;&#10;&#10;    # Enhanced email content&#10;    subject = &quot;Payment Confirmed - Your Dispute My HOA Case is Ready&quot;&#10;&#10;    text = f&quot;&quot;&quot;{greeting}&#10;&#10;Thank you for your payment{payment_info}! Your payment has been successfully processed and your Dispute My HOA case is now unlocked and ready for access.&#10;&#10; ACCESS YOUR CASE:&#10;{case_url}&#10;&#10; IMPORTANT: Please save this email for your records. You can use the link above to access your case anytime in the future.&#10;&#10; WHAT'S NEXT:&#10;• Review your case documents and analysis&#10;• Use the AI-powered insights to understand your dispute&#10;• Access legal templates and guidance specific to your situation&#10;• Get step-by-step instructions for resolving your HOA dispute&#10;&#10; NEED HELP?&#10;If you have any questions or need assistance accessing your case, simply reply to this email and we'll get back to you promptly.&#10;&#10;Your case token for reference: {token[:8]}...&#10;{f'Transaction ID: {stripe_session_id}' if stripe_session_id else ''}&#10;&#10;Best regards,&#10;The Dispute My HOA Team&#10;https://disputemyhoa.com&#10;&#10;---&#10;This email confirms your payment and provides access to your case. Keep this email safe for future reference.&quot;&quot;&quot;&#10;&#10;    msg = MIMEMultipart()&#10;    msg[&quot;From&quot;] = SMTP_FROM&#10;    msg[&quot;To&quot;] = to_email&#10;    msg[&quot;Subject&quot;] = subject&#10;    msg.attach(MIMEText(text, &quot;plain&quot;))&#10;&#10;    try:&#10;        logger.info(f&quot;Connecting to SMTP {SMTP_HOST}:{SMTP_PORT} to send to {to_email}&quot;)&#10;        logger.info(f&quot;SMTP_USER after cleaning: '{SMTP_USER}' (length: {len(SMTP_USER)})&quot;)&#10;        logger.info(f&quot;SMTP_PASS after cleaning: length={len(SMTP_PASS)}, starts_with='{SMTP_PASS[:4]}...'&quot;)&#10;&#10;        with smtplib.SMTP(SMTP_HOST, SMTP_PORT, timeout=20) as server:&#10;            server.ehlo()&#10;            server.starttls()&#10;            server.ehlo()&#10;            server.login(SMTP_USER, SMTP_PASS)&#10;            server.sendmail(SMTP_FROM, [to_email], msg.as_string())&#10;&#10;        logger.info(f&quot;Receipt email sent to {to_email} (token={token[:8]}...&quot; )&#10;        return jsonify({&quot;ok&quot;: True}), 200&#10;&#10;    except smtplib.SMTPAuthenticationError as e:&#10;        error_msg = f&quot;Gmail authentication failed. For Gmail, you need: 1) Enable 2-Step Verification, 2) Create App Password. Error: {str(e)}&quot;&#10;        logger.error(error_msg)&#10;        return jsonify({&quot;ok&quot;: False, &quot;error&quot;: error_msg}), 500&#10;    except Exception as e:&#10;        # Log full exception with traceback to help diagnose mail failures&#10;        logger.exception(&quot;Failed to send receipt email&quot;)&#10;        return jsonify({&quot;ok&quot;: False, &quot;error&quot;: str(e)}), 500&#10;&#10;&#10;def preview_env(name: str, value: str) -&gt; Dict[str, Any]:&#10;    &quot;&quot;&quot;Helper: safely preview env values without leaking secrets&quot;&quot;&quot;&#10;    if not value:&#10;        return {'name': name, 'present': False, 'preview': None, 'length': 0}&#10;&#10;    lower = name.lower()&#10;    is_secret = (&#10;        'secret' in lower or&#10;        'service_role' in lower or&#10;        'key' in lower&#10;    )&#10;&#10;    preview = f&quot;{value[:6]}…({len(value)})&quot; if is_secret else f&quot;{value[:24]}{'…' if len(value) &gt; 24 else ''}&quot;&#10;&#10;    return {'name': name, 'present': True, 'preview': preview, 'length': len(value)}&#10;&#10;def extract_structured_result(responses_json: Any) -&gt; Optional[Dict[str, Any]]:&#10;    &quot;&quot;&quot;Safer JSON extraction from OpenAI Responses API payload&quot;&quot;&quot;&#10;    output = responses_json.get('output') if responses_json else None&#10;&#10;    if isinstance(output, list) and len(output) &gt; 0:&#10;        for item in output:&#10;            content = item.get('content') if item else None&#10;&#10;            if isinstance(content, list):&#10;                # Look for output_json type first&#10;                cj = next((c for c in content&#10;                          if c and c.get('type') == 'output_json' and c.get('json')), None)&#10;                if not cj:&#10;                    # Fallback to any content with json&#10;                    cj = next((c for c in content&#10;                              if c and c.get('json') and isinstance(c['json'], dict)), None)&#10;&#10;                if cj and cj.get('json') and isinstance(cj['json'], dict):&#10;                    return cj['json']&#10;&#10;                # Look for text content to parse as JSON&#10;                ct = next((c for c in content&#10;                          if c and c.get('type') == 'output_text' and isinstance(c.get('text'), str)), None)&#10;                if not ct:&#10;                    ct = next((c for c in content&#10;                              if c and isinstance(c.get('text'), str)), None)&#10;&#10;                if ct and ct.get('text'):&#10;                    try:&#10;                        parsed = json.loads(ct['text'])&#10;                        if parsed and isinstance(parsed, dict):&#10;                            return parsed&#10;                    except Exception:&#10;                        pass  # ignore parse errors&#10;&#10;    return None&#10;&#10;&#10;def get_draft_titles(payload: Dict[str, Any]) -&gt; Dict[str, str]:&#10;    &quot;&quot;&quot;&#10;    Keeps DB keys stable (drafts.clarification/extension/compliance),&#10;    but changes what those &quot;slots&quot; mean based on the user's selection.&#10;    &quot;&quot;&quot;&#10;    outcome = str(payload.get('outcome', '')).lower()&#10;&#10;    titles = {&#10;        'clarification': 'Request Clarification / Rule Citation',&#10;        'extension': 'Request Extension / Pause Enforcement',&#10;        'compliance': 'Confirm Compliance Plan'&#10;    }&#10;&#10;    if outcome == 'clarification':&#10;        titles = {&#10;            'clarification': 'Request Clarification / Rule Citation',&#10;            'extension': 'Request Extension While Clarifying',&#10;            'compliance': 'Confirm Compliance Plan (If Needed)'&#10;        }&#10;    elif outcome == 'extension':&#10;        titles = {&#10;            'clarification': 'Request Clarification + Confirm Requirements',&#10;            'extension': 'Request Extension / New Deadline',&#10;            'compliance': 'Confirm Compliance Plan + Timeline'&#10;        }&#10;    elif outcome == 'alternative':&#10;        titles = {&#10;            'clarification': 'Request Approved Options / Standards',&#10;            'extension': 'Request Temporary Variance / Extra Time',&#10;            'compliance': 'Propose Alternative Remedy Plan'&#10;        }&#10;    elif outcome == 'comply':&#10;        titles = {&#10;            'clarification': 'Confirm Requirements Before Starting Work',&#10;            'extension': 'Request Extra Time to Complete Work',&#10;            'compliance': 'Confirm Compliance Completion'&#10;        }&#10;    elif outcome == 'dispute':&#10;        titles = {&#10;            'clarification': 'Formal Dispute / Appeal Letter',&#10;            'extension': 'Request Hearing Extension / Reschedule',&#10;            'compliance': 'Evidence Submission Cover Letter'&#10;        }&#10;    elif outcome == 'not-sure':&#10;        titles = {&#10;            'clarification': 'Request Clarification / Rule Citation',&#10;            'extension': 'Request Extension to Evaluate Options',&#10;            'compliance': 'Provisional Compliance Plan (If Required)'&#10;        }&#10;&#10;    return titles&#10;&#10;&#10;def safe_iso(s: Any) -&gt; Optional[str]:&#10;    &quot;&quot;&quot;Convert value to ISO string safely&quot;&quot;&quot;&#10;    v = str(s or '').strip()&#10;    if not v:&#10;        return None&#10;    try:&#10;        d = datetime.fromisoformat(v.replace('Z', '+00:00'))&#10;        return d.isoformat()&#10;    except Exception:&#10;        try:&#10;            d = datetime.strptime(v, '%Y-%m-%d %H:%M:%S')&#10;            return d.isoformat()&#10;        except Exception:&#10;            return None&#10;&#10;&#10;def newest_updated_at(docs: List[Dict[str, Any]]) -&gt; Optional[str]:&#10;    &quot;&quot;&quot;Find the newest updated_at timestamp from documents&quot;&quot;&quot;&#10;    newest = None&#10;    for d in docs:&#10;        iso = safe_iso(d.get('updated_at'))&#10;        if not iso:&#10;            continue&#10;        if not newest or datetime.fromisoformat(iso) &gt; datetime.fromisoformat(newest):&#10;            newest = iso&#10;    return newest&#10;&#10;&#10;@app.route('/api/create-checkout-session', methods=['POST', 'OPTIONS'])&#10;def create_checkout_session():&#10;    &quot;&quot;&quot;Create Stripe checkout session endpoint (converted from Supabase edge function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    logger.info('[create-checkout-session] request', extra={&#10;        'method': request.method,&#10;        'url': request.url,&#10;        'has_auth_header': bool(request.headers.get('authorization')),&#10;        'has_apikey_header': bool(request.headers.get('apikey')),&#10;        'origin': request.headers.get('origin')&#10;    })&#10;&#10;    try:&#10;        # Environment variables validation&#10;        env_report = [&#10;            preview_env('STRIPE_SECRET_KEY', STRIPE_SECRET_KEY or ''),&#10;            preview_env('STRIPE_PRICE_ID', STRIPE_PRICE_ID or ''),&#10;            preview_env('SITE_URL', SITE_URL),&#10;            preview_env('SUPABASE_URL', SUPABASE_URL or ''),&#10;            preview_env('SUPABASE_SERVICE_ROLE_KEY', SUPABASE_SERVICE_ROLE_KEY or ''),&#10;        ]&#10;        logger.info('[create-checkout-session] env report', extra={'env_report': env_report})&#10;&#10;        missing = [v['name'] for v in env_report if not v['present']]&#10;        if missing:&#10;            logger.error('[create-checkout-session] missing env vars', extra={'missing': missing})&#10;            response = jsonify({'error': 'Missing required environment variables', 'missing': missing})&#10;            return add_cors_headers(response), 500&#10;&#10;        logger.info('[create-checkout-session] initializing clients')&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = body.get('token')&#10;        email = body.get('email')&#10;        payload = body.get('payload')&#10;&#10;        logger.info('[create-checkout-session] parsed body', extra={&#10;            'has_token': bool(token),&#10;            'token_preview': f&quot;{token[:12]}…&quot; if isinstance(token, str) else None,&#10;            'has_email': bool(email),&#10;            'email_domain': email.split('@')[1] if isinstance(email, str) and '@' in email else None,&#10;            'has_payload': bool(payload)&#10;        })&#10;&#10;        if not token or not email:&#10;            response = jsonify({'error': 'Token and email are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Validate email format&#10;        email_regex = re.compile(r'^[^\s@]+@[^\s@]+\.[^\s@]+$')&#10;        if not email_regex.match(email):&#10;            response = jsonify({'error': 'Invalid email format'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # 1) Fetch case (it may not exist yet — that's OK)&#10;        logger.info('[create-checkout-session] fetching case', extra={'token_preview': f&quot;{token[:12]}…&quot;})&#10;&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,status,stripe_checkout_session_id'&#10;        }&#10;        headers = supabase_headers()&#10;&#10;        try:&#10;            response_data = requests.get(url, params=params, headers=headers, timeout=TIMEOUT)&#10;            response_data.raise_for_status()&#10;            cases = response_data.json()&#10;            existing_case = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('[create-checkout-session] database fetch error', extra={&#10;                'message': str(e)&#10;            })&#10;            response = jsonify({'error': 'Database error'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 2) Create case if missing&#10;        if not existing_case:&#10;            logger.warning('[create-checkout-session] case not found, creating new case',&#10;                         extra={'token_preview': f&quot;{token[:12]}…&quot;})&#10;&#10;            insert_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            insert_data = {&#10;                'token': token,&#10;                'email': email,&#10;                'status': 'pending_payment',&#10;                'unlocked': False,&#10;                'payload': payload,&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            insert_headers = supabase_headers()&#10;            insert_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_response = requests.post(insert_url, headers=insert_headers,&#10;                                              json=insert_data, timeout=TIMEOUT)&#10;                insert_response.raise_for_status()&#10;            except Exception as e:&#10;                logger.error('[create-checkout-session] failed to create case', extra={&#10;                    'message': str(e)&#10;                })&#10;                response = jsonify({'error': 'Failed to create case'})&#10;                return add_cors_headers(response), 500&#10;        else:&#10;            logger.info('[create-checkout-session] case found', extra={&#10;                'status': existing_case.get('status'),&#10;                'has_existing_session': bool(existing_case.get('stripe_checkout_session_id'))&#10;            })&#10;&#10;            # Update existing case&#10;            logger.info('[create-checkout-session] updating case status -&gt; pending_payment')&#10;            update_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            update_params = {'token': f'eq.{token}'}&#10;            update_data = {&#10;                'email': email,&#10;                'payload': payload,&#10;                'status': 'pending_payment',&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            update_headers = supabase_headers()&#10;&#10;            try:&#10;                update_response = requests.patch(update_url, params=update_params,&#10;                                               headers=update_headers, json=update_data, timeout=TIMEOUT)&#10;                update_response.raise_for_status()&#10;            except Exception as e:&#10;                logger.error('[create-checkout-session] database update error', extra={&#10;                    'message': str(e)&#10;                })&#10;                response = jsonify({'error': 'Failed to update case'})&#10;                return add_cors_headers(response), 500&#10;&#10;        # 3) Create Stripe Checkout Session&#10;        logger.info('[create-checkout-session] creating stripe checkout session', extra={&#10;            'price_id': STRIPE_PRICE_ID,&#10;            'site_url': SITE_URL,&#10;            'expires_in_minutes': 30&#10;        })&#10;&#10;        try:&#10;            session = stripe.checkout.Session.create(&#10;                mode='payment',&#10;                line_items=[{'price': STRIPE_PRICE_ID, 'quantity': 1}],&#10;                success_url=f&quot;{SITE_URL}/case.html?case={token}&amp;session_id={{CHECKOUT_SESSION_ID}}&quot;,&#10;                cancel_url=f&quot;{SITE_URL}/case-preview.html?case={token}&quot;,&#10;                client_reference_id=token,&#10;                customer_email=email,&#10;                metadata={'token': token, 'source': 'dispute-my-hoa'},&#10;                expires_at=int(datetime.utcnow().timestamp()) + (30 * 60)  # 30 minutes&#10;            )&#10;        except Exception as e:&#10;            logger.error('[create-checkout-session] stripe session creation failed', extra={&#10;                'message': str(e)&#10;            })&#10;            response = jsonify({'error': f'Stripe error: {str(e)}'})&#10;            return add_cors_headers(response), 500&#10;&#10;        logger.info('[create-checkout-session] stripe session created', extra={&#10;            'session_id': session.id,&#10;            'has_url': bool(session.url),&#10;            'amount_total': session.amount_total,&#10;            'currency': session.currency&#10;        })&#10;&#10;        # 4) Save session id on the case&#10;        save_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        save_params = {'token': f'eq.{token}'}&#10;        save_data = {&#10;            'stripe_checkout_session_id': session.id,&#10;            'updated_at': datetime.utcnow().isoformat()&#10;        }&#10;        save_headers = supabase_headers()&#10;&#10;        try:&#10;            save_response = requests.patch(save_url, params=save_params,&#10;                                         headers=save_headers, json=save_data, timeout=TIMEOUT)&#10;            save_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.warning('[create-checkout-session] failed saving stripe session id (non-fatal)', extra={&#10;                'message': str(e)&#10;            })&#10;&#10;        # 5) Log event (non-fatal)&#10;        event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;        event_data = {&#10;            'token': token,&#10;            'type': 'checkout_session_created',&#10;            'data': {&#10;                'session_id': session.id,&#10;                'email_domain': email.split('@')[1] if '@' in email else None,&#10;                'amount': session.amount_total,&#10;                'currency': session.currency&#10;            }&#10;        }&#10;        event_headers = supabase_headers()&#10;&#10;        try:&#10;            event_response = requests.post(event_url, headers=event_headers,&#10;                                         json=event_data, timeout=TIMEOUT)&#10;            event_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.warning('[create-checkout-session] failed to insert dmhoa_events (non-fatal)', extra={&#10;                'message': str(e)&#10;            })&#10;&#10;        response = jsonify({'url': session.url})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('[create-checkout-session] error', extra={&#10;            'message': str(e),&#10;            'name': type(e).__name__&#10;        })&#10;        response = jsonify({'error': str(e) or 'Internal server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/store-message', methods=['POST', 'OPTIONS'])&#10;def store_message():&#10;    &quot;&quot;&quot;Store chat message endpoint (converted from Supabase edge function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        origin = request.headers.get('Origin')&#10;        allowed_origins = [&#10;            'https://disputemyhoa.com',&#10;            'https://dmhoadev.netlify.app',&#10;            'http://localhost:5173',&#10;            'http://localhost:3000',&#10;            'http://127.0.0.1:5173'&#10;        ]&#10;        if origin in allowed_origins:&#10;            response.headers.add('Access-Control-Allow-Origin', origin)&#10;        else:&#10;            response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        origin = request.headers.get('Origin')&#10;        allowed_origins = [&#10;            'https://disputemyhoa.com',&#10;            'https://dmhoadev.netlify.app',&#10;            'http://localhost:5173',&#10;            'http://localhost:3000',&#10;            'http://127.0.0.1:5173'&#10;        ]&#10;        if origin in allowed_origins:&#10;            response.headers.add('Access-Control-Allow-Origin', origin)&#10;        else:&#10;            response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = (body.get('token') or '').strip()&#10;        role = (body.get('role') or '').strip()&#10;        content = (body.get('content') or '').strip()&#10;&#10;        if not token or not role or not content:&#10;            response = jsonify({'error': 'token, role, content are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        if role not in ['user', 'assistant', 'system']:&#10;            response = jsonify({'error': 'invalid role'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Check if case is unlocked&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'unlocked'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Failed to fetch case for unlock check', extra={'error': str(e)})&#10;            response = jsonify({'error': 'DB fetch failed', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row or not case_row.get('unlocked'):&#10;            response = jsonify({'error': 'Case is not unlocked'})&#10;            return add_cors_headers(response), 402&#10;&#10;        # Insert message into dmhoa_messages&#10;        message_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        message_data = {&#10;            'token': token,&#10;            'role': role,&#10;            'content': content&#10;        }&#10;        message_headers = supabase_headers()&#10;        message_headers['Prefer'] = 'return=representation'&#10;&#10;        try:&#10;            message_response = requests.post(message_url, headers=message_headers,&#10;                                           json=message_data, timeout=TIMEOUT)&#10;            message_response.raise_for_status()&#10;            inserted_message = message_response.json()&#10;        except Exception as e:&#10;            logger.error('Failed to insert message', extra={'error': str(e)})&#10;            response = jsonify({'error': 'DB insert failed', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Return the inserted message data&#10;        message_data = inserted_message[0] if inserted_message else {}&#10;        response = jsonify({'ok': True, 'message': message_data})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('store-message error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/doc-extract-start', methods=['POST', 'OPTIONS'])&#10;def doc_extract_start():&#10;    &quot;&quot;&quot;Document extraction trigger endpoint (converted from Supabase edge function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    def safe_trim(v) -&gt; str:&#10;        return str(v or '').strip()&#10;&#10;    logger.info(f&quot;[{datetime.utcnow().isoformat()}] {request.method} {request.url}&quot;)&#10;&#10;    if request.method != 'POST':&#10;        response = jsonify({'error': 'Method not allowed'})&#10;        return add_cors_headers(response), 405&#10;&#10;    try:&#10;        # Environment variables check&#10;        WEBHOOK_URL = os.environ.get('DOC_EXTRACT_WEBHOOK_URL', f&quot;{request.url_root.rstrip('/')}/webhooks/doc-extract&quot;)&#10;        DOC_BUCKET = os.environ.get('DOC_EXTRACT_BUCKET', 'dmhoa-docs')&#10;&#10;        logger.info('Env check', extra={&#10;            'hasUrl': bool(SUPABASE_URL),&#10;            'hasServiceRole': bool(SUPABASE_SERVICE_ROLE_KEY),&#10;            'hasWebhookUrl': bool(WEBHOOK_URL),&#10;            'hasWebhookSecret': bool(DOC_EXTRACT_WEBHOOK_SECRET),&#10;            'bucket': DOC_BUCKET&#10;        })&#10;&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing SUPABASE env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not DOC_EXTRACT_WEBHOOK_SECRET:&#10;            response = jsonify({'error': 'Missing webhook env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Validate secret header (optional - commented out for now like in original)&#10;        # incoming_secret = request.headers.get('x-doc-secret', '').strip()&#10;        # if not incoming_secret or incoming_secret != 'dmhoa_9baf6a13e2f847d0b52f':&#10;        #     logger.error('Unauthorized - secret mismatch')&#10;        #     response = jsonify({'error': 'Unauthorized'})&#10;        #     return add_cors_headers(response), 401&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = safe_trim(body.get('token'))&#10;        storage_path = safe_trim(body.get('storage_path'))&#10;        filename = safe_trim(body.get('filename')) or None&#10;        mime_type = safe_trim(body.get('mime_type')) or None&#10;&#10;        if not token or not storage_path:&#10;            response = jsonify({'error': 'token and storage_path are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Ensure case exists (fail fast)&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,payload,created_at'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Case lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found', 'token': token})&#10;            return add_cors_headers(response), 404&#10;&#10;        # 1) Create (or reuse) a dmhoa_documents row for this file&#10;        document_id = None&#10;&#10;        # Check for existing document&#10;        doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        doc_params = {&#10;            'token': f'eq.{token}',&#10;            'path': f'eq.{storage_path}',&#10;            'select': 'id,status'&#10;        }&#10;        doc_headers = supabase_headers()&#10;&#10;        try:&#10;            doc_response = requests.get(doc_url, params=doc_params, headers=doc_headers, timeout=TIMEOUT)&#10;            doc_response.raise_for_status()&#10;            docs = doc_response.json()&#10;            existing_doc = docs[0] if docs else None&#10;        except Exception as e:&#10;            logger.error('Doc lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading document', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if existing_doc and existing_doc.get('id'):&#10;            document_id = existing_doc['id']&#10;            logger.info('Reusing existing dmhoa_documents row', extra={&#10;                'document_id': document_id,&#10;                'status': existing_doc.get('status')&#10;            })&#10;        else:&#10;            # Insert new document&#10;            insert_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            insert_doc_data = {&#10;                'token': token,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'filename': filename,&#10;                'mime_type': mime_type,&#10;                'status': 'pending'&#10;            }&#10;            insert_doc_headers = supabase_headers()&#10;            insert_doc_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_doc_response = requests.post(insert_doc_url, headers=insert_doc_headers,&#10;                                                  json=insert_doc_data, timeout=TIMEOUT)&#10;                insert_doc_response.raise_for_status()&#10;                inserted_docs = insert_doc_response.json()&#10;                document_id = inserted_docs[0]['id'] if inserted_docs else None&#10;                logger.info('Created dmhoa_documents row', extra={'document_id': document_id})&#10;            except Exception as e:&#10;                logger.error('Doc insert error', extra={'error': str(e)})&#10;                response = jsonify({'error': 'Failed to create dmhoa_documents row', 'details': str(e)})&#10;                return add_cors_headers(response), 500&#10;&#10;        if not document_id:&#10;            response = jsonify({'error': 'Could not determine document_id'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 2) Update case payload summary status (optional, but useful for UI)&#10;        current_payload = {}&#10;        try:&#10;            payload_data = case_row.get('payload')&#10;            if isinstance(payload_data, str):&#10;                current_payload = json.loads(payload_data)&#10;            elif isinstance(payload_data, dict):&#10;                current_payload = payload_data&#10;        except Exception:&#10;            current_payload = {}&#10;&#10;        next_payload = {&#10;            **current_payload,&#10;            'extract_status': 'triggered',&#10;            'notice_storage_path': storage_path,&#10;            'notice_filename': filename,&#10;            'notice_mime_type': mime_type,&#10;            'extract_triggered_at': datetime.utcnow().isoformat(),&#10;            'document_id': document_id&#10;        }&#10;&#10;        # Update case payload&#10;        update_case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        update_case_params = {'token': f'eq.{token}'}&#10;        update_case_data = {'payload': next_payload}&#10;        update_case_headers = supabase_headers()&#10;&#10;        try:&#10;            update_case_response = requests.patch(update_case_url, params=update_case_params,&#10;                                                headers=update_case_headers, json=update_case_data, timeout=TIMEOUT)&#10;            update_case_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Case payload update error', extra={'error': str(e)})&#10;            # Not fatal—doc record exists and webhook can still run&#10;&#10;        # 3) Mark document processing BEFORE webhook&#10;        mark_proc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        mark_proc_params = {'id': f'eq.{document_id}'}&#10;        mark_proc_data = {'status': 'processing', 'error': None}&#10;        mark_proc_headers = supabase_headers()&#10;&#10;        try:&#10;            mark_proc_response = requests.patch(mark_proc_url, params=mark_proc_params,&#10;                                              headers=mark_proc_headers, json=mark_proc_data, timeout=TIMEOUT)&#10;            mark_proc_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Failed to mark document processing', extra={'error': str(e)})&#10;            # Not fatal, but you'll want to know&#10;&#10;        # 4) Call backend webhook (server-to-server)&#10;        logger.info('Calling webhook', extra={'webhook_url': WEBHOOK_URL})&#10;&#10;        webhook_payload = {&#10;            'token': token,&#10;            'document_id': document_id,&#10;            'bucket': DOC_BUCKET,&#10;            'path': storage_path,&#10;            'filename': filename,&#10;            'mime_type': mime_type,&#10;            'supabase_url': SUPABASE_URL  # optional&#10;        }&#10;&#10;        webhook_headers = {&#10;            'Content-Type': 'application/json',&#10;            'X-Webhook-Secret': WEBHOOK_SECRET,&#10;            'X-Doc-Extract-Secret': WEBHOOK_SECRET  # Alternative header name&#10;        }&#10;&#10;        try:&#10;            webhook_response = requests.post(WEBHOOK_URL, headers=webhook_headers,&#10;                                           json=webhook_payload, timeout=(10, 120))  # Longer timeout for processing&#10;&#10;            logger.info('Webhook response', extra={'status': webhook_response.status_code, 'ok': webhook_response.ok})&#10;&#10;            if not webhook_response.ok:&#10;                error_text = webhook_response.text&#10;                logger.error('Webhook failed', extra={'error': error_text})&#10;&#10;                # Update document status to failed&#10;                fail_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;                fail_doc_params = {'id': f'eq.{document_id}'}&#10;                fail_doc_data = {&#10;                    'status': 'failed',&#10;                    'error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500]&#10;                }&#10;                fail_doc_headers = supabase_headers()&#10;&#10;                try:&#10;                    requests.patch(fail_doc_url, params=fail_doc_params,&#10;                                 headers=fail_doc_headers, json=fail_doc_data, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                # Also reflect summary status on the case payload (optional)&#10;                fail_payload = {&#10;                    **next_payload,&#10;                    'extract_status': 'failed',&#10;                    'extract_error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500],&#10;                    'extract_failed_at': datetime.utcnow().isoformat()&#10;                }&#10;&#10;                try:&#10;                    requests.patch(update_case_url, params=update_case_params,&#10;                                 headers=update_case_headers, json={'payload': fail_payload}, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                response = jsonify({&#10;                    'error': 'Webhook call failed',&#10;                    'status': webhook_response.status_code,&#10;                    'details': error_text&#10;                })&#10;                return add_cors_headers(response), 502&#10;&#10;            # If webhook returns JSON, capture it (optional)&#10;            try:&#10;                webhook_json = webhook_response.json()&#10;            except Exception:&#10;                webhook_json = {}&#10;&#10;            # Mark queued/accepted (document is now in backend pipeline)&#10;            queue_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            queue_doc_params = {'id': f'eq.{document_id}'}&#10;            queue_doc_data = {'status': 'processing'}&#10;            queue_doc_headers = supabase_headers()&#10;&#10;            try:&#10;                requests.patch(queue_doc_url, params=queue_doc_params,&#10;                             headers=queue_doc_headers, json=queue_doc_data, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            ok_payload = {&#10;                **next_payload,&#10;                'extract_status': 'queued',&#10;                'webhook_response': webhook_json,&#10;                'extract_queued_at': datetime.utcnow().isoformat()&#10;            }&#10;&#10;            try:&#10;                requests.patch(update_case_url, params=update_case_params,&#10;                             headers=update_case_headers, json={'payload': ok_payload}, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            response = jsonify({&#10;                'ok': True,&#10;                'token': token,&#10;                'document_id': document_id,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'webhook': webhook_json&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        except Exception as e:&#10;            logger.error('Webhook request failed', extra={'error': str(e)})&#10;            response = jsonify({'error': f'Webhook request failed: {str(e)}'})&#10;            return add_cors_headers(response), 502&#10;&#10;    except Exception as e:&#10;        logger.error('Unexpected error in doc-extract-start', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;# Helpers for case preview feature&#10;def read_case_by_token(token: str) -&gt; Optional[Dict[str, Any]]:&#10;    &quot;&quot;&quot;Read case row by token (select id, token, unlocked, payload, updated_at)&quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,unlocked,payload,updated_at'&#10;        }&#10;        headers = supabase_headers()&#10;        resp = requests.get(url, params=params, headers=headers, timeout=TIMEOUT)&#10;        resp.raise_for_status()&#10;        rows = resp.json()&#10;        return rows[0] if rows else None&#10;    except Exception as e:&#10;        logger.error('read_case_by_token error', extra={'error': str(e)})&#10;        return None&#10;&#10;&#10;def read_active_preview(case_id: str) -&gt; Optional[Dict[str, Any]]:&#10;    &quot;&quot;&quot;Return the most recent active preview for a case_id if any&quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_previews&quot;&#10;        params = {&#10;            'case_id': f'eq.{case_id}',&#10;            'is_active': 'eq.true',&#10;            'select': 'id,case_id,preview_content,preview_snippet,model,prompt_version,token_input,token_output,cost_usd,latency_ms,created_at',&#10;            'order': 'created_at.desc',&#10;            'limit': '1'&#10;        }&#10;        headers = supabase_headers()&#10;        resp = requests.get(url, params=params, headers=headers, timeout=TIMEOUT)&#10;        resp.raise_for_status()&#10;        rows = resp.json()&#10;        return rows[0] if rows else None&#10;    except Exception as e:&#10;        logger.error('read_active_preview error', extra={'error': str(e)})&#10;        return None&#10;&#10;&#10;def deactivate_previews(case_id: str) -&gt; bool:&#10;    &quot;&quot;&quot;Mark existing active previews for a case_id as inactive&quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_previews&quot;&#10;        params = {'case_id': f'eq.{case_id}', 'is_active': 'eq.true'}&#10;        headers = supabase_headers()&#10;        update_data = {'is_active': False}&#10;        resp = requests.patch(url, params=params, headers=headers, json=update_data, timeout=TIMEOUT)&#10;        resp.raise_for_status()&#10;        return True&#10;    except Exception as e:&#10;        logger.error('deactivate_previews error', extra={'error': str(e)})&#10;        return False&#10;&#10;&#10;def insert_preview(case_id: str, preview_content: Dict[str, Any], preview_snippet: str, meta: Dict[str, Any]) -&gt; Optional[Dict[str, Any]]:&#10;    &quot;&quot;&quot;Insert a new preview row into dmhoa_case_previews and return the inserted row (representation)&#10;&#10;    meta keys: model, prompt_version, token_input, token_output, cost_usd, latency_ms&#10;    &quot;&quot;&quot;&#10;    try:&#10;        url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_previews&quot;&#10;        headers = supabase_headers()&#10;        headers['Prefer'] = 'return=representation'&#10;&#10;        insert_data = {&#10;            'case_id': case_id,&#10;            'preview_content': preview_content,&#10;            'preview_snippet': preview_snippet,&#10;            'model': meta.get('model'),&#10;            'prompt_version': meta.get('prompt_version'),&#10;            'token_input': meta.get('token_input'),&#10;            'token_output': meta.get('token_output'),&#10;            'cost_usd': meta.get('cost_usd'),&#10;            'latency_ms': meta.get('latency_ms'),&#10;            'is_active': True,&#10;            'created_at': datetime.utcnow().isoformat()&#10;        }&#10;&#10;        resp = requests.post(url, headers=headers, json=insert_data, timeout=TIMEOUT)&#10;        resp.raise_for_status()&#10;        rows = resp.json()&#10;        return rows[0] if rows else None&#10;    except Exception as e:&#10;        logger.error('insert_preview error', extra={'error': str(e)})&#10;        return None&#10;&#10;&#10;@app.route('/api/case-preview', methods=['POST', 'OPTIONS'])&#10;def case_preview():&#10;    &quot;&quot;&quot;Generate or return a cached personalized preview for a case token&#10;    &#10;    Frontend flow (intended):&#10;    1) Frontend calls /api/save-case to create/update the case and receive the token&#10;    2) Frontend calls /api/case-preview with {token, force:false} to generate and store a preview before payment&#10;    3) Preview page fetches from /api/case-preview (cached) to render the preview using the stored record&#10;    &quot;&quot;&quot;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate env&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY or not OPENAI_API_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = (body.get('token') or '').strip()&#10;        force = bool(body.get('force'))&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        if not str(token).startswith('case_'):&#10;            response = jsonify({'error': 'Invalid token format'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # 1) Fetch case&#10;        case_row = read_case_by_token(token)&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        case_id = case_row.get('id')&#10;&#10;        # 2) Check for existing active preview&#10;        existing = read_active_preview(case_id)&#10;        if existing and not force:&#10;            logger.info('Returning cached preview', extra={'case_id': case_id, 'preview_id': existing.get('id')})&#10;            resp = jsonify({'ok': True, 'cached': True, 'preview': existing.get('preview_content')})&#10;            return add_cors_headers(resp), 200&#10;&#10;        # If forcing, deactivate old previews&#10;        if force and existing:&#10;            deactivate_previews(case_id)&#10;&#10;        # 3) Build prompt + schema&#10;        payload = case_row.get('payload') or {}&#10;&#10;        system_prompt = (&#10;            &quot;You generate a short, personalized preview for a homeowner's HOA notice.&quot;&#10;            &quot; This is educational drafting assistance only, not legal advice. Be calm, neutral, and professional.&quot;&#10;            &quot; Do NOT say 'I am an AI' or provide legal conclusions. Avoid em-dashes. Keep concise (total ~250-400 words).&quot;&#10;        )&#10;&#10;        user_content = (&#10;            f&quot;Case payload JSON:\n{json.dumps(payload)}\n\n&quot;&#10;            &quot;Produce a STRICT JSON object matching the provided JSON Schema. Be concise and personalize using fields from the payload.&quot;&#10;            &quot; Emphasize educational tone and avoid legal advice language.&quot;&#10;        )&#10;&#10;        schema = {&#10;            &quot;type&quot;: &quot;object&quot;,&#10;            &quot;additionalProperties&quot;: False,&#10;            &quot;properties&quot;: {&#10;                &quot;preview_title&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                &quot;what_this_means&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                &quot;risk_and_timeline&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;deadline&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;risk_level&quot;: {&quot;type&quot;: &quot;string&quot;, &quot;enum&quot;: [&quot;Low&quot;, &quot;Low-Medium&quot;, &quot;Medium&quot;, &quot;Medium-High&quot;, &quot;High&quot;]},&#10;                        &quot;why&quot;: {&quot;type&quot;: &quot;string&quot;}&#10;                    },&#10;                    &quot;required&quot;: [&quot;deadline&quot;, &quot;risk_level&quot;, &quot;why&quot;]&#10;                },&#10;                &quot;recommended_next_step&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;headline&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;bullets&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;maxItems&quot;: 3}&#10;                    },&#10;                    &quot;required&quot;: [&quot;headline&quot;, &quot;bullets&quot;]&#10;                },&#10;                &quot;response_opening_preview&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;subject&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;opening_paragraph&quot;: {&quot;type&quot;: &quot;string&quot;}&#10;                    },&#10;                    &quot;required&quot;: [&quot;subject&quot;, &quot;opening_paragraph&quot;]&#10;                },&#10;                &quot;unlock_teaser&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;headline&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;includes&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 1}&#10;                    },&#10;                    &quot;required&quot;: [&quot;headline&quot;, &quot;includes&quot;]&#10;                }&#10;            },&#10;            &quot;required&quot;: [&quot;preview_title&quot;, &quot;what_this_means&quot;, &quot;risk_and_timeline&quot;, &quot;recommended_next_step&quot;, &quot;response_opening_preview&quot;, &quot;unlock_teaser&quot;]&#10;        }&#10;&#10;        messages = [&#10;            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt},&#10;            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_content}&#10;        ]&#10;&#10;        openai_payload = {&#10;            &quot;model&quot;: &quot;gpt-4o-mini&quot;,&#10;            &quot;input&quot;: messages,&#10;            &quot;text&quot;: {&#10;                &quot;format&quot;: {&#10;                    &quot;type&quot;: &quot;json_schema&quot;,&#10;                    &quot;name&quot;: &quot;dmhoa_case_preview&quot;,&#10;                    &quot;strict&quot;: True,&#10;                    &quot;schema&quot;: schema&#10;                }&#10;            }&#10;        }&#10;&#10;        # 4) Call OpenAI and measure latency&#10;        start_t = time.time()&#10;        try:&#10;            openai_resp = requests.post(&#10;                'https://api.openai.com/v1/responses',&#10;                headers={&#10;                    'Authorization': f'Bearer {OPENAI_API_KEY}',&#10;                    'Content-Type': 'application/json'&#10;                },&#10;                json=openai_payload,&#10;                timeout=(10, 120)&#10;            )&#10;            latency_ms = int((time.time() - start_t) * 1000)&#10;&#10;            if not openai_resp.ok:&#10;                error_text = openai_resp.text&#10;                logger.error('OpenAI preview call failed', extra={'status': openai_resp.status_code, 'error': error_text})&#10;                response = jsonify({'error': 'OpenAI call failed', 'details': error_text})&#10;                return add_cors_headers(response), 500&#10;&#10;            openai_json = openai_resp.json()&#10;            structured = extract_structured_result(openai_json)&#10;&#10;            if not structured:&#10;                logger.error('OpenAI preview did not return structured JSON', extra={'openai': openai_json})&#10;                response = jsonify({'error': 'OpenAI returned unexpected format'})&#10;                return add_cors_headers(response), 500&#10;&#10;            # Build preview_snippet&#10;            try:&#10;                rl = structured.get('risk_and_timeline', {}).get('risk_level', 'Unknown')&#10;            except Exception:&#10;                rl = 'Unknown'&#10;            try:&#10;                headline = structured.get('recommended_next_step', {}).get('headline', '')&#10;            except Exception:&#10;                headline = ''&#10;            preview_snippet = f&quot;{rl}: {headline}&quot;.strip()&#10;&#10;            # Extract token usage if present&#10;            usage = openai_json.get('usage') or {}&#10;            token_input = usage.get('input_tokens') if isinstance(usage.get('input_tokens'), int) else usage.get('prompt_tokens') if isinstance(usage.get('prompt_tokens'), int) else None&#10;            token_output = usage.get('output_tokens') if isinstance(usage.get('output_tokens'), int) else usage.get('completion_tokens') if isinstance(usage.get('completion_tokens'), int) else None&#10;&#10;            meta = {&#10;                'model': 'gpt-4o-mini',&#10;                'prompt_version': 'v1_preview_basic',&#10;                'token_input': token_input,&#10;                'token_output': token_output,&#10;                'cost_usd': None,&#10;                'latency_ms': latency_ms&#10;            }&#10;&#10;            # 5) Persist preview (deactivate old then insert)&#10;            try:&#10;                deactivate_previews(case_id)&#10;            except Exception:&#10;                logger.warning('Failed to deactivate old previews (non-fatal)')&#10;&#10;            inserted = insert_preview(case_id, structured, preview_snippet, meta)&#10;            if not inserted:&#10;                logger.error('Failed to persist preview')&#10;                response = jsonify({'error': 'Failed to save preview'})&#10;                return add_cors_headers(response), 500&#10;&#10;            logger.info('Preview generated and saved', extra={'case_id': case_id, 'preview_id': inserted.get('id')})&#10;&#10;            resp = jsonify({'ok': True, 'cached': False, 'preview': structured})&#10;            return add_cors_headers(resp), 200&#10;&#10;        except Exception as e:&#10;            logger.error('OpenAI preview error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'OpenAI API error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;    except Exception as e:&#10;        logger.exception('case-preview error')&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/case-analysis', methods=['POST', 'OPTIONS'])&#10;def case_analysis():&#10;    &quot;&quot;&quot;Generate HOA case analysis using OpenAI (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY or not OPENAI_API_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = body.get('token')&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # 1) Ensure case exists + is unlocked/paid&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'token,unlocked,status,payload'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        if not case_row.get('unlocked'):&#10;            response = jsonify({'error': 'Case is not unlocked'})&#10;            return add_cors_headers(response), 402&#10;&#10;        # 1b) Load extracted documents for this case&#10;        docs_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        docs_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,filename,path,status,extracted_text,page_count,char_count,updated_at,error',&#10;            'order': 'updated_at.desc',&#10;            'limit': '10'&#10;        }&#10;        docs_headers = supabase_headers()&#10;&#10;        try:&#10;            docs_response = requests.get(docs_url, params=docs_params, headers=docs_headers, timeout=TIMEOUT)&#10;            docs_response.raise_for_status()&#10;            docs = docs_response.json()&#10;        except Exception as e:&#10;            logger.error('Docs lookup error', extra={'error': str(e)})&#10;            docs = []&#10;&#10;        docs_newest = newest_updated_at(docs)&#10;&#10;        # Consider usable if it has text, even if status still says &quot;processing&quot;&#10;        usable_docs = [&#10;            d for d in docs&#10;            if isinstance(d.get('extracted_text'), str) and d['extracted_text'].strip()&#10;        ]&#10;&#10;        logger.info('DOCS DEBUG', extra={&#10;            'count': len(docs),&#10;            'docs_newest': docs_newest,&#10;            'statuses': [{'id': d['id'], 'status': d['status'], 'hasText': bool(d.get('extracted_text', '').strip()),&#10;                         'charCount': d.get('char_count'), 'updated_at': d.get('updated_at'), 'err': d.get('error')}&#10;                        for d in docs],&#10;            'usable_count': len(usable_docs)&#10;        })&#10;&#10;        if usable_docs:&#10;            docs_block = '\n'.join([&#10;                f&quot;DOCUMENT {i + 1}: {d.get('filename') or d.get('path') or d['id']}\n&quot;&#10;                f&quot;---\n{(d.get('extracted_text', '') or '')[:12000]}\n---\n&quot;&#10;                for i, d in enumerate(usable_docs[:5])&#10;            ])&#10;        else:&#10;            statuses = ', '.join([d.get('status', 'unknown') for d in docs]) or 'none'&#10;            errors = ' | '.join([d.get('error', '') for d in docs if d.get('error')])[:100] or 'none'&#10;            docs_block = f&quot;&quot;&quot;No document text available yet.&#10;Docs found: {len(docs)}&#10;Statuses: {statuses}&#10;Errors: {errors}&quot;&quot;&quot;&#10;&#10;        logger.info('DOCS BLOCK LENGTH', extra={'length': len(docs_block)})&#10;&#10;        # 2) If outputs already exist and are ready, return cached ONLY if docs haven't changed since outputs updated_at&#10;        outputs_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_outputs&quot;&#10;        outputs_params = {&#10;            'case_token': f'eq.{token}',&#10;            'select': 'case_token,status,outputs,error,updated_at'&#10;        }&#10;        outputs_headers = supabase_headers()&#10;&#10;        try:&#10;            outputs_response = requests.get(outputs_url, params=outputs_params, headers=outputs_headers, timeout=TIMEOUT)&#10;            outputs_response.raise_for_status()&#10;            existing_outputs = outputs_response.json()&#10;            existing_out = existing_outputs[0] if existing_outputs else None&#10;        except Exception as e:&#10;            logger.error('Database error reading outputs', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading outputs', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        out_updated = safe_iso(existing_out.get('updated_at') if existing_out else None)&#10;        docs_are_newer = (&#10;            docs_newest and out_updated and&#10;            datetime.fromisoformat(docs_newest) &gt; datetime.fromisoformat(out_updated)&#10;        )&#10;&#10;        if (existing_out and existing_out.get('status') == 'ready' and&#10;            existing_out.get('outputs') and not docs_are_newer):&#10;            response = jsonify({&#10;                'ok': True,&#10;                'status': 'ready',&#10;                'cached': True,&#10;                'outputs': existing_out['outputs']&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        # 3) Mark outputs as pending (upsert)&#10;        pending_data = {&#10;            'case_token': token,&#10;            'status': 'pending',&#10;            'error': None,&#10;            'model': 'gpt-4o-mini',&#10;            'prompt_version': 'v3_docs_cache_invalidation',&#10;            'updated_at': datetime.utcnow().isoformat()&#10;        }&#10;&#10;        upsert_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_outputs&quot;&#10;        upsert_headers = supabase_headers()&#10;        upsert_headers['Prefer'] = 'resolution=merge-duplicates'&#10;&#10;        try:&#10;            upsert_response = requests.post(upsert_url, headers=upsert_headers, json=pending_data, timeout=TIMEOUT)&#10;            upsert_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Failed to mark outputs pending', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to mark outputs pending', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        payload = case_row.get('payload') or {}&#10;        draft_titles = get_draft_titles(payload)&#10;&#10;        # 4) OpenAI Responses API call (strict JSON schema)&#10;        schema = {&#10;            &quot;type&quot;: &quot;object&quot;,&#10;            &quot;additionalProperties&quot;: False,&#10;            &quot;properties&quot;: {&#10;                &quot;summary_html&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                &quot;letter_summary&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                &quot;draft_titles&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;clarification&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;extension&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;compliance&quot;: {&quot;type&quot;: &quot;string&quot;}&#10;                    },&#10;                    &quot;required&quot;: [&quot;clarification&quot;, &quot;extension&quot;, &quot;compliance&quot;]&#10;                },&#10;                &quot;risks_and_deadlines&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;deadlines&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 1},&#10;                        &quot;risks&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 3}&#10;                    },&#10;                    &quot;required&quot;: [&quot;deadlines&quot;, &quot;risks&quot;]&#10;                },&#10;                &quot;action_plan&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 6},&#10;                &quot;drafts&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;clarification&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;extension&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;compliance&quot;: {&quot;type&quot;: &quot;string&quot;}&#10;                    },&#10;                    &quot;required&quot;: [&quot;clarification&quot;, &quot;extension&quot;, &quot;compliance&quot;]&#10;                },&#10;                &quot;questions_to_ask&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 6},&#10;                &quot;lowest_cost_path&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 4}&#10;            },&#10;            &quot;required&quot;: [&#10;                &quot;summary_html&quot;, &quot;letter_summary&quot;, &quot;draft_titles&quot;, &quot;risks_and_deadlines&quot;,&#10;                &quot;action_plan&quot;, &quot;drafts&quot;, &quot;questions_to_ask&quot;, &quot;lowest_cost_path&quot;&#10;            ]&#10;        }&#10;&#10;        doc_fingerprint = {&#10;            'count': len(docs),&#10;            'usableCount': len(usable_docs),&#10;            'newestUpdatedAt': docs_newest,&#10;            'ids': [d['id'] for d in docs],&#10;            'statuses': [d.get('status') for d in docs],&#10;            'charCounts': [d.get('char_count') for d in docs]&#10;        }&#10;&#10;        messages = [&#10;            {&#10;                &quot;role&quot;: &quot;system&quot;,&#10;                &quot;content&quot;: &quot;&quot;&quot;&#10;You generate HOA dispute assistance for a homeowner.&#10;This is educational drafting help, not legal advice.&#10;&#10;OUTPUT RULES (CRITICAL):&#10;- ONLY &quot;summary_html&quot; may contain HTML.&#10;- summary_html must be valid HTML using ONLY: &lt;div&gt;, &lt;strong&gt;, &lt;ul&gt;, &lt;li&gt;.&#10;- ALL drafts (clarification/extension/compliance) MUST be PLAIN TEXT ONLY:&#10;  - NO HTML tags&#10;  - Use newlines with \\n&#10;  - Bullets: use &quot;- item&quot; lines&#10;- Return STRICT JSON that matches the schema exactly.&#10;&#10;DRAFT QUALITY REQUIREMENTS:&#10;- Each draft must be a complete, ready-to-send letter.&#10;- MUST directly quote or reference concrete facts from the extracted documents when available&#10;  (deadlines, email addresses, paragraph citations, dollar amounts, dates, etc.).&#10;- Each must include:&#10;  - Subject line&#10;  - Short opening&#10;  - 3–6 bullet-point requests (specific asks)&#10;  - Proposed timeline (e.g., &quot;Please respond within 10 business days&quot; if no deadline is provided)&#10;  - Request fines/penalties be paused/waived while pending (when relevant)&#10;  - Closing requesting confirmation in writing&#10;&#10;DEPTH REQUIREMENTS:&#10;- action_plan &gt;= 6 steps with timing hints (Today / 48 hours / Before deadline).&#10;- risks &gt;= 3 concrete risks tied to HOA enforcement.&#10;- questions_to_ask &gt;= 6 questions.&#10;- lowest_cost_path &gt;= 4 items.&#10;&#10;STYLE:&#10;- Calm, professional, firm, factual.&#10;&quot;&quot;&quot;&#10;            },&#10;            {&#10;                &quot;role&quot;: &quot;user&quot;,&#10;                &quot;content&quot;: (&#10;                    f&quot;Case payload JSON:\n{json.dumps(payload)}\n\n&quot;&#10;                    f&quot;Document fingerprint (debug):\n{json.dumps(doc_fingerprint)}\n\n&quot;&#10;                    f&quot;Extracted documents:\n{docs_block}\n\n&quot;&#10;                    f&quot;Draft types for this case (MUST follow exactly):\n&quot;&#10;                    f&quot;- drafts.clarification MUST be: \&quot;{draft_titles['clarification']}\&quot;\n&quot;&#10;                    f&quot;- drafts.extension MUST be: \&quot;{draft_titles['extension']}\&quot;\n&quot;&#10;                    f&quot;- drafts.compliance MUST be: \&quot;{draft_titles['compliance']}\&quot;\n\n&quot;&#10;                    f&quot;Also include draft_titles using these exact same strings.\n\n&quot;&#10;                    f&quot;summary_html must be valid HTML using ONLY: &lt;div&gt;, &lt;strong&gt;, &lt;ul&gt;, &lt;li&gt;.\n&quot;&#10;                    f&quot;Drafts must be PLAIN TEXT ONLY with \\n, and must NOT include any HTML tags.\n\n&quot;&#10;                    f&quot;Make this feel like a $30 deliverable: concrete, specific, complete.\n&quot;&#10;                )&#10;            }&#10;        ]&#10;&#10;        openai_payload = {&#10;            &quot;model&quot;: &quot;gpt-4o-mini&quot;,&#10;            &quot;input&quot;: messages,&#10;            &quot;text&quot;: {&#10;                &quot;format&quot;: {&#10;                    &quot;type&quot;: &quot;json_schema&quot;,&#10;                    &quot;name&quot;: &quot;dmhoa_case_outputs&quot;,&#10;                    &quot;strict&quot;: True,&#10;                    &quot;schema&quot;: schema&#10;                }&#10;            }&#10;        }&#10;&#10;        # Make OpenAI API call&#10;        try:&#10;            openai_response = requests.post(&#10;                'https://api.openai.com/v1/responses',&#10;                headers={&#10;                    'Authorization': f'Bearer {OPENAI_API_KEY}',&#10;                    'Content-Type': 'application/json'&#10;                },&#10;                json=openai_payload,&#10;                timeout=(10, 120)  # 10s connect, 120s read&#10;            )&#10;&#10;            if not openai_response.ok:&#10;                error_text = openai_response.text&#10;                logger.error('OpenAI call failed', extra={'status': openai_response.status_code, 'error': error_text})&#10;&#10;                # Update outputs table with error&#10;                error_data = {&#10;                    'case_token': token,&#10;                    'status': 'error',&#10;                    'error': error_text or 'OpenAI call failed',&#10;                    'updated_at': datetime.utcnow().isoformat()&#10;                }&#10;                try:&#10;                    requests.post(upsert_url, headers=upsert_headers, json=error_data, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                response = jsonify({'error': 'OpenAI call failed', 'details': error_text})&#10;                return add_cors_headers(response), 500&#10;&#10;            openai_json = openai_response.json()&#10;            structured = extract_structured_result(openai_json)&#10;&#10;            if structured:&#10;                outputs_to_store = {&#10;                    **structured,&#10;                    'draft_titles': structured.get('draft_titles', draft_titles),&#10;                    'doc_fingerprint': doc_fingerprint  # helpful for debugging what it saw&#10;                }&#10;            else:&#10;                outputs_to_store = {&#10;                    'raw': openai_json,&#10;                    'draft_titles': draft_titles,&#10;                    'doc_fingerprint': doc_fingerprint&#10;                }&#10;&#10;            # Save successful outputs&#10;            success_data = {&#10;                'case_token': token,&#10;                'status': 'ready',&#10;                'outputs': outputs_to_store,&#10;                'error': None,&#10;                'model': 'gpt-4o-mini',&#10;                'prompt_version': 'v3_docs_cache_invalidation',&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;&#10;            try:&#10;                requests.post(upsert_url, headers=upsert_headers, json=success_data, timeout=TIMEOUT)&#10;            except Exception as e:&#10;                logger.error('Failed saving outputs', extra={'error': str(e)})&#10;                response = jsonify({'error': 'Failed saving outputs', 'details': str(e)})&#10;                return add_cors_headers(response), 500&#10;&#10;            # Update case updated_at timestamp&#10;            try:&#10;                case_update_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;                case_update_params = {'token': f'eq.{token}'}&#10;                case_update_data = {'updated_at': datetime.utcnow().isoformat()}&#10;                case_update_headers = supabase_headers()&#10;                requests.patch(case_update_url, params=case_update_params,&#10;                             headers=case_update_headers, json=case_update_data, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            response = jsonify({&#10;                'ok': True,&#10;                'status': 'ready',&#10;                'cached': False,&#10;                'outputs': outputs_to_store&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        except Exception as e:&#10;            logger.error('OpenAI API error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'OpenAI API error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;    except Exception as e:&#10;        logger.error('case-analysis error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/case-data', methods=['GET', 'OPTIONS'])&#10;def get_case_data():&#10;    &quot;&quot;&quot;Get case data by token (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Get token from query parameters&#10;        token = request.args.get('token', '').strip()&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Fetch case data from Supabase&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'token,unlocked,status,created_at,payload,amount_total,currency'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;&#10;            if not cases:&#10;                response = jsonify({'error': 'Case not found'})&#10;                return add_cors_headers(response), 404&#10;&#10;            case_data = cases[0]&#10;&#10;        except requests.exceptions.RequestException as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Return case data&#10;        response = jsonify(case_data)&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('get-case-data error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/read-messages', methods=['GET', 'OPTIONS'])&#10;def read_messages():&#10;    &quot;&quot;&quot;Read chat messages for a case (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', 'https://disputemyhoa.com')  # or &quot;*&quot; while testing&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        response.headers.add('Access-Control-Max-Age', '86400')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', 'https://disputemyhoa.com')  # or &quot;*&quot; while testing&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        response.headers.add('Access-Control-Max-Age', '86400')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Get parameters from query string&#10;        token = request.args.get('token', '').strip()&#10;        limit_param = request.args.get('limit', '50')&#10;&#10;        # Parse and validate limit (min 1, max 200, default 50)&#10;        try:&#10;            limit = max(1, min(int(limit_param) or 50, 200))&#10;        except (ValueError, TypeError):&#10;            limit = 50&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Check if case exists and is unlocked&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'unlocked'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        if not case_row.get('unlocked'):&#10;            # Return empty messages array if case is not unlocked&#10;            response = jsonify({'ok': True, 'messages': []})&#10;            return add_cors_headers(response), 200&#10;&#10;        # Fetch messages for the case&#10;        messages_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        messages_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,role,content,created_at',&#10;            'order': 'created_at.asc',&#10;            'limit': str(limit)&#10;        }&#10;        messages_headers = supabase_headers()&#10;&#10;        try:&#10;            messages_response = requests.get(messages_url, params=messages_params, headers=messages_headers, timeout=TIMEOUT)&#10;            messages_response.raise_for_status()&#10;            messages = messages_response.json()&#10;        except Exception as e:&#10;            logger.error('Database error reading messages', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading messages'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Return messages&#10;        response = jsonify({'ok': True, 'messages': messages or []})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('read-messages error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/read-outputs', methods=['GET', 'POST', 'OPTIONS'])&#10;def read_outputs():&#10;    &quot;&quot;&quot;Read case analysis outputs by token (converted from Deno/TypeScript code)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing required environment variables'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Extract token from GET params or POST body&#10;        token = &quot;&quot;&#10;        if request.method == 'GET':&#10;            token = request.args.get('token', '').strip()&#10;        elif request.method == 'POST':&#10;            try:&#10;                body = request.get_json() or {}&#10;                token = (body.get('token') or '').strip()&#10;            except Exception:&#10;                token = &quot;&quot;&#10;        else:&#10;            response = jsonify({'error': 'Method not allowed'})&#10;            return add_cors_headers(response), 405&#10;&#10;        if not token:&#10;            response = jsonify({'error': 'Token is required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Fetch case outputs from Supabase&#10;        outputs_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_case_outputs&quot;&#10;        outputs_params = {&#10;            'case_token': f'eq.{token}',&#10;            'select': 'case_token,status,outputs,error,created_at,updated_at,model,prompt_version'&#10;        }&#10;        outputs_headers = supabase_headers()&#10;&#10;        try:&#10;            outputs_response = requests.get(outputs_url, params=outputs_params, headers=outputs_headers, timeout=TIMEOUT)&#10;            outputs_response.raise_for_status()&#10;            outputs_data = outputs_response.json()&#10;            data = outputs_data[0] if outputs_data else None&#10;        except Exception as e:&#10;            logger.error('[read-outputs] DB error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not data:&#10;            # Return 200 with missing status so client can poll without treating as error&#10;            response = jsonify({&#10;                'case_token': token,&#10;                'status': 'missing',&#10;                'outputs': None,&#10;                'error': None&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        # Return the outputs data&#10;        response = jsonify({&#10;            'case_token': data.get('case_token'),&#10;            'status': data.get('status'),&#10;            'outputs': data.get('outputs'),&#10;            'error': data.get('error'),&#10;            'model': data.get('model'),&#10;            'prompt_version': data.get('prompt_version'),&#10;            'created_at': data.get('created_at'),&#10;            'updated_at': data.get('updated_at')&#10;        })&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('[read-outputs] Error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'Internal server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/save-case', methods=['POST', 'OPTIONS'])&#10;def save_case():&#10;    &quot;&quot;&quot;Save case endpoint (converted from Deno/TypeScript save-case function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    try:&#10;        # Environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing required environment variables'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = body.get('token')&#10;        payload = body.get('payload')&#10;&#10;        if not token or not payload:&#10;            response = jsonify({'error': 'Token and payload are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Validate token format&#10;        if not str(token).startswith('case_'):&#10;            response = jsonify({'error': 'Invalid token format'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Check if case already exists&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,payload,created_at'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            existing_case = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error(f&quot;Database error reading case: {str(e)}&quot;)&#10;            response = jsonify({'error': 'Failed to check existing case'})&#10;            return add_cors_headers(response), 500&#10;&#10;        result = None&#10;&#10;        if existing_case:&#10;            # Case exists - update with merged payload&#10;            existing_payload = existing_case.get('payload') or {}&#10;            if isinstance(existing_payload, str):&#10;                try:&#10;                    existing_payload = json.loads(existing_payload)&#10;                except:&#10;                    existing_payload = {}&#10;&#10;            merged_payload = {**existing_payload, **payload}&#10;&#10;            update_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            update_params = {'token': f'eq.{token}'}&#10;            update_data = {&#10;                'payload': merged_payload,&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            update_headers = supabase_headers()&#10;            update_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                update_response = requests.patch(update_url, params=update_params,&#10;                                               headers=update_headers, json=update_data, timeout=TIMEOUT)&#10;                update_response.raise_for_status()&#10;                result = update_response.json()&#10;                logger.info(f&quot;Case updated: {token}&quot;)&#10;            except Exception as e:&#10;                logger.error(f&quot;Database update error: {str(e)}&quot;)&#10;                response = jsonify({'error': 'Failed to update case data'})&#10;                return add_cors_headers(response), 500&#10;&#10;        else:&#10;            # Case doesn't exist - create new&#10;            insert_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            insert_data = {&#10;                'token': token,&#10;                'payload': payload,&#10;                'status': 'new',&#10;                'unlocked': False,&#10;                'created_at': datetime.utcnow().isoformat(),&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            insert_headers = supabase_headers()&#10;            insert_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_response = requests.post(insert_url, headers=insert_headers,&#10;                                              json=insert_data, timeout=TIMEOUT)&#10;                insert_response.raise_for_status()&#10;                result = insert_response.json()&#10;                logger.info(f&quot;Case created: {token}&quot;)&#10;            except Exception as e:&#10;                logger.error(f&quot;Database insert error: {str(e)}&quot;)&#10;                response = jsonify({'error': 'Failed to create case data'})&#10;                return add_cors_headers(response), 500&#10;&#10;        # Log the save event for audit (non-critical)&#10;        try:&#10;            event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;            event_data = {&#10;                'token': token,&#10;                'type': 'case_updated' if existing_case else 'case_created',&#10;                'data': {&#10;                    'payload_keys': list((payload or {}).keys()),&#10;                    'timestamp': datetime.utcnow().isoformat()&#10;                }&#10;            }&#10;            event_headers = supabase_headers()&#10;&#10;            requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;        except Exception as e:&#10;            logger.warning(f&quot;Failed to log event (non-critical): {str(e)}&quot;)&#10;&#10;        # Start document extraction in background thread with delay&#10;        def delayed_extraction():&#10;            time.sleep(2)  # 2 second delay to ensure commit propagation&#10;            trigger_document_extraction_async(token, payload)&#10;&#10;        extraction_thread = threading.Thread(target=delayed_extraction)&#10;        extraction_thread.daemon = True&#10;        extraction_thread.start()&#10;&#10;        case_id = result[0].get('id') if result and len(result) &gt; 0 else None&#10;        response = jsonify({'success': True, 'case_id': case_id})&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Save case error: {str(e)}&quot;)&#10;        response = jsonify({'error': str(e) or 'Internal server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/send-message', methods=['POST', 'OPTIONS'])&#10;def send_message():&#10;    &quot;&quot;&quot;Send chat message endpoint (converted from Deno/TypeScript send-message function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type')&#10;        return response&#10;&#10;    if request.method != 'POST':&#10;        response = jsonify({'error': 'Method not allowed'})&#10;        return add_cors_headers(response), 405&#10;&#10;    try:&#10;        # Validate environment variables&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY or not OPENAI_API_KEY:&#10;            response = jsonify({'error': 'Missing env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = str(body.get('token', '')).strip()&#10;        user_content = clamp_text(body.get('content', ''), 1000)&#10;&#10;        if not token or not user_content:&#10;            response = jsonify({'error': 'token and content are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # 1) Ensure case exists + is unlocked&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'token,unlocked,payload'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Database error reading case', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found'})&#10;            return add_cors_headers(response), 404&#10;&#10;        if not case_row.get('unlocked'):&#10;            response = jsonify({'error': 'Case is not unlocked'})&#10;            return add_cors_headers(response), 402&#10;&#10;        # 2) Save user message&#10;        user_message_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        user_message_data = {&#10;            'token': token,&#10;            'role': 'user',&#10;            'content': user_content&#10;        }&#10;        user_message_headers = supabase_headers()&#10;        user_message_headers['Prefer'] = 'return=representation'&#10;&#10;        try:&#10;            user_message_response = requests.post(user_message_url, headers=user_message_headers,&#10;                                                json=user_message_data, timeout=TIMEOUT)&#10;            user_message_response.raise_for_status()&#10;            user_insert = user_message_response.json()&#10;            user_message = user_insert[0] if user_insert else None&#10;        except Exception as e:&#10;            logger.error('Failed to save user message', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to save user message'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 3) Load recent history (keep it lightweight)&#10;        history_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        history_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'role,content,created_at',&#10;            'order': 'created_at.asc',&#10;            'limit': '20'&#10;        }&#10;        history_headers = supabase_headers()&#10;&#10;        try:&#10;            history_response = requests.get(history_url, params=history_params, headers=history_headers, timeout=TIMEOUT)&#10;            history_response.raise_for_status()&#10;            history = history_response.json() or []&#10;        except Exception as e:&#10;            logger.error('Failed to load chat history', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to load chat history'})&#10;            return add_cors_headers(response), 500&#10;&#10;        payload = case_row.get('payload') or {}&#10;&#10;        system_prompt = &quot;&quot;&quot;&#10;You are &quot;Dispute My HOA&quot; chat support.&#10;This is educational drafting assistance, not legal advice.&#10;&#10;You help the homeowner with:&#10;- understanding the notice&#10;- drafting a practical response&#10;- next steps / timelines&#10;- reducing escalation risk&#10;&#10;Rules:&#10;- Be calm, practical, specific.&#10;- Ask 1-2 clarifying questions only if truly needed.&#10;- If the user asks for a new letter, produce a ready-to-send draft (plain text).&#10;- Do NOT claim to be a lawyer.&#10;&quot;&quot;&quot;&#10;&#10;        # 4) Call OpenAI (Responses API)&#10;        history_text = '\n'.join([&#10;            f&quot;{msg['role'].upper()}: {msg['content']}&quot;&#10;            for msg in history&#10;        ])&#10;&#10;        input_messages = [&#10;            {'role': 'system', 'content': system_prompt},&#10;            {&#10;                'role': 'user',&#10;                'content': (&#10;                    f&quot;Case payload JSON:\n{json.dumps(payload)}\n\n&quot;&#10;                    f&quot;Recent chat history:\n{history_text}\n\n&quot;&#10;                    f&quot;User message:\n{user_content}\n\nRespond as the assistant.&quot;&#10;                )&#10;            }&#10;        ]&#10;&#10;        openai_payload = {&#10;            'model': 'gpt-4o-mini',&#10;            'input': input_messages&#10;        }&#10;&#10;        try:&#10;            openai_response = requests.post(&#10;                'https://api.openai.com/v1/responses',&#10;                headers={&#10;                    'Authorization': f'Bearer {OPENAI_API_KEY}',&#10;                    'Content-Type': 'application/json'&#10;                },&#10;                json=openai_payload,&#10;                timeout=(10, 60)&#10;            )&#10;&#10;            if not openai_response.ok:&#10;                error_text = openai_response.text&#10;                logger.error('OpenAI call failed', extra={'status': openai_response.status_code, 'error': error_text})&#10;                response = jsonify({'error': 'OpenAI call failed', 'details': error_text})&#10;                return add_cors_headers(response), 500&#10;&#10;            openai_json = openai_response.json()&#10;&#10;            # Extract assistant text from Responses API output safely&#10;            assistant_text = &quot;&quot;&#10;            output = openai_json.get('output')&#10;            if isinstance(output, list):&#10;                for item in output:&#10;                    content = item.get('content') if item else None&#10;                    if isinstance(content, list):&#10;                        for c in content:&#10;                            if (c and c.get('type') == 'output_text' and&#10;                                isinstance(c.get('text'), str)):&#10;                                assistant_text = c['text']&#10;                                break&#10;                        if assistant_text:&#10;                            break&#10;&#10;            assistant_text = clamp_text(&#10;                assistant_text or &quot;I can help—what do you want to do next?&quot;,&#10;                2000&#10;            )&#10;&#10;        except Exception as e:&#10;            logger.error('OpenAI API error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'OpenAI API error', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 5) Save assistant message&#10;        assistant_message_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_messages&quot;&#10;        assistant_message_data = {&#10;            'token': token,&#10;            'role': 'assistant',&#10;            'content': assistant_text&#10;        }&#10;        assistant_message_headers = supabase_headers()&#10;        assistant_message_headers['Prefer'] = 'return=representation'&#10;&#10;        try:&#10;            assistant_message_response = requests.post(assistant_message_url, headers=assistant_message_headers,&#10;                                                     json=assistant_message_data, timeout=TIMEOUT)&#10;            assistant_message_response.raise_for_status()&#10;            assistant_insert = assistant_message_response.json()&#10;            assistant_message = assistant_insert[0] if assistant_insert else None&#10;        except Exception as e:&#10;            logger.error('Failed to save assistant message', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Failed to save assistant message'})&#10;            return add_cors_headers(response), 500&#10;&#10;        response = jsonify({&#10;            'ok': True,&#10;            'token': token,&#10;            'user_message': user_message,&#10;            'assistant_message': assistant_message&#10;        })&#10;        return add_cors_headers(response), 200&#10;&#10;    except Exception as e:&#10;        logger.error('send-message error', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/api/start-extraction', methods=['POST', 'OPTIONS'])&#10;def start_extraction():&#10;    &quot;&quot;&quot;Document extraction start endpoint (converted from Deno/TypeScript start-extraction function)&quot;&quot;&quot;&#10;&#10;    # Handle CORS preflight&#10;    if request.method == 'OPTIONS':&#10;        response = jsonify({'ok': True})&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    # Add CORS headers to actual response&#10;    def add_cors_headers(response):&#10;        response.headers.add('Access-Control-Allow-Origin', '*')&#10;        response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')&#10;        response.headers.add('Access-Control-Allow-Headers', 'authorization, x-client-info, apikey, content-type, x-doc-secret')&#10;        return response&#10;&#10;    def safe_trim(v) -&gt; str:&#10;        return str(v or '').strip()&#10;&#10;    logger.info(f&quot;[{datetime.utcnow().isoformat()}] {request.method} {request.url}&quot;)&#10;&#10;    if request.method != 'POST':&#10;        response = jsonify({'error': 'Method not allowed'})&#10;        return add_cors_headers(response), 405&#10;&#10;    try:&#10;        # Environment variables check&#10;        WEBHOOK_URL = os.environ.get('DOC_EXTRACT_WEBHOOK_URL', f&quot;{request.url_root.rstrip('/')}/webhooks/doc-extract&quot;)&#10;        WEBHOOK_SECRET = os.environ.get('DOC_EXTRACT_WEBHOOK_SECRET')&#10;        DOC_BUCKET = os.environ.get('DOC_EXTRACT_BUCKET', 'dmhoa-docs')&#10;&#10;        logger.info('Env check', extra={&#10;            'hasUrl': bool(SUPABASE_URL),&#10;            'hasServiceRole': bool(SUPABASE_SERVICE_ROLE_KEY),&#10;            'hasWebhookUrl': bool(WEBHOOK_URL),&#10;            'hasWebhookSecret': bool(DOC_EXTRACT_WEBHOOK_SECRET),&#10;            'bucket': DOC_BUCKET&#10;        })&#10;&#10;        if not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            response = jsonify({'error': 'Missing SUPABASE env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not WEBHOOK_URL or not WEBHOOK_SECRET:&#10;            response = jsonify({'error': 'Missing webhook env vars'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # Validate secret header&#10;        incoming_secret = request.headers.get('x-doc-secret', '').strip()&#10;        if not incoming_secret or incoming_secret != WEBHOOK_SECRET:&#10;            logger.error('Unauthorized - secret mismatch')&#10;            response = jsonify({'error': 'Unauthorized'})&#10;            return add_cors_headers(response), 401&#10;&#10;        # Parse request body&#10;        try:&#10;            body = request.get_json() or {}&#10;        except Exception:&#10;            body = {}&#10;&#10;        token = safe_trim(body.get('token'))&#10;        storage_path = safe_trim(body.get('storage_path'))&#10;        filename = safe_trim(body.get('filename')) or None&#10;        mime_type = safe_trim(body.get('mime_type')) or None&#10;&#10;        if not token or not storage_path:&#10;            response = jsonify({'error': 'token and storage_path are required'})&#10;            return add_cors_headers(response), 400&#10;&#10;        # Ensure case exists (fail fast)&#10;        case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        case_params = {&#10;            'token': f'eq.{token}',&#10;            'select': 'id,token,payload,created_at'&#10;        }&#10;        case_headers = supabase_headers()&#10;&#10;        try:&#10;            case_response = requests.get(case_url, params=case_params, headers=case_headers, timeout=TIMEOUT)&#10;            case_response.raise_for_status()&#10;            cases = case_response.json()&#10;            case_row = cases[0] if cases else None&#10;        except Exception as e:&#10;            logger.error('Case lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading case', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if not case_row:&#10;            response = jsonify({'error': 'Case not found', 'token': token})&#10;            return add_cors_headers(response), 404&#10;&#10;        # 1) Create (or reuse) a dmhoa_documents row for this file&#10;        document_id = None&#10;&#10;        # Check for existing document&#10;        doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        doc_params = {&#10;            'token': f'eq.{token}',&#10;            'path': f'eq.{storage_path}',&#10;            'select': 'id,status'&#10;        }&#10;        doc_headers = supabase_headers()&#10;&#10;        try:&#10;            doc_response = requests.get(doc_url, params=doc_params, headers=doc_headers, timeout=TIMEOUT)&#10;            doc_response.raise_for_status()&#10;            docs = doc_response.json()&#10;            existing_doc = docs[0] if docs else None&#10;        except Exception as e:&#10;            logger.error('Doc lookup error', extra={'error': str(e)})&#10;            response = jsonify({'error': 'Database error reading document', 'details': str(e)})&#10;            return add_cors_headers(response), 500&#10;&#10;        if existing_doc and existing_doc.get('id'):&#10;            document_id = existing_doc['id']&#10;            logger.info('Reusing existing dmhoa_documents row', extra={&#10;                'document_id': document_id,&#10;                'status': existing_doc.get('status')&#10;            })&#10;        else:&#10;            # Insert new document&#10;            insert_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            insert_doc_data = {&#10;                'token': token,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'filename': filename,&#10;                'mime_type': mime_type,&#10;                'status': 'pending'&#10;            }&#10;            insert_doc_headers = supabase_headers()&#10;            insert_doc_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                insert_doc_response = requests.post(insert_doc_url, headers=insert_doc_headers,&#10;                                                  json=insert_doc_data, timeout=TIMEOUT)&#10;                insert_doc_response.raise_for_status()&#10;                inserted_docs = insert_doc_response.json()&#10;                document_id = inserted_docs[0]['id'] if inserted_docs else None&#10;                logger.info('Created dmhoa_documents row', extra={'document_id': document_id})&#10;            except Exception as e:&#10;                logger.error('Doc insert error', extra={'error': str(e)})&#10;                response = jsonify({'error': 'Failed to create dmhoa_documents row', 'details': str(e)})&#10;                return add_cors_headers(response), 500&#10;&#10;        if not document_id:&#10;            response = jsonify({'error': 'Could not determine document_id'})&#10;            return add_cors_headers(response), 500&#10;&#10;        # 2) Update case payload summary status (optional, but useful for UI)&#10;        current_payload = {}&#10;        try:&#10;            payload_data = case_row.get('payload')&#10;            if isinstance(payload_data, str):&#10;                current_payload = json.loads(payload_data)&#10;            elif isinstance(payload_data, dict):&#10;                current_payload = payload_data&#10;        except Exception:&#10;            current_payload = {}&#10;&#10;        next_payload = {&#10;            **current_payload,&#10;            'extract_status': 'triggered',&#10;            'notice_storage_path': storage_path,&#10;            'notice_filename': filename,&#10;            'notice_mime_type': mime_type,&#10;            'extract_triggered_at': datetime.utcnow().isoformat(),&#10;            'document_id': document_id&#10;        }&#10;&#10;        # Update case payload&#10;        update_case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;        update_case_params = {'token': f'eq.{token}'}&#10;        update_case_data = {'payload': next_payload}&#10;        update_case_headers = supabase_headers()&#10;&#10;        try:&#10;            update_case_response = requests.patch(update_case_url, params=update_case_params,&#10;                                                headers=update_case_headers, json=update_case_data, timeout=TIMEOUT)&#10;            update_case_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Case payload update error', extra={'error': str(e)})&#10;            # Not fatal—doc record exists and webhook can still run&#10;&#10;        # 3) Mark document processing BEFORE webhook&#10;        mark_proc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;        mark_proc_params = {'id': f'eq.{document_id}'}&#10;        mark_proc_data = {'status': 'processing', 'error': None}&#10;        mark_proc_headers = supabase_headers()&#10;&#10;        try:&#10;            mark_proc_response = requests.patch(mark_proc_url, params=mark_proc_params,&#10;                                              headers=mark_proc_headers, json=mark_proc_data, timeout=TIMEOUT)&#10;            mark_proc_response.raise_for_status()&#10;        except Exception as e:&#10;            logger.error('Failed to mark document processing', extra={'error': str(e)})&#10;            # Not fatal, but you'll want to know&#10;&#10;        # 4) Call backend webhook (server-to-server)&#10;        logger.info('Calling webhook', extra={'webhook_url': WEBHOOK_URL})&#10;&#10;        webhook_payload = {&#10;            'token': token,&#10;            'document_id': document_id,&#10;            'bucket': DOC_BUCKET,&#10;            'path': storage_path,&#10;            'filename': filename,&#10;            'mime_type': mime_type,&#10;            'supabase_url': SUPABASE_URL  # optional&#10;        }&#10;&#10;        webhook_headers = {&#10;            'Content-Type': 'application/json',&#10;            'X-Webhook-Secret': WEBHOOK_SECRET,&#10;            'X-Doc-Extract-Secret': WEBHOOK_SECRET  # Alternative header name&#10;        }&#10;&#10;        try:&#10;            webhook_response = requests.post(WEBHOOK_URL, headers=webhook_headers,&#10;                                           json=webhook_payload, timeout=(10, 120))  # Longer timeout for processing&#10;&#10;            logger.info('Webhook response', extra={'status': webhook_response.status_code, 'ok': webhook_response.ok})&#10;&#10;            if not webhook_response.ok:&#10;                error_text = webhook_response.text&#10;                logger.error('Webhook failed', extra={'error': error_text})&#10;&#10;                # Update document status to failed&#10;                fail_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;                fail_doc_params = {'id': f'eq.{document_id}'}&#10;                fail_doc_data = {&#10;                    'status': 'failed',&#10;                    'error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500]&#10;                }&#10;                fail_doc_headers = supabase_headers()&#10;&#10;                try:&#10;                    requests.patch(fail_doc_url, params=fail_doc_params,&#10;                                 headers=fail_doc_headers, json=fail_doc_data, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                # Also reflect summary status on the case payload (optional)&#10;                fail_payload = {&#10;                    **next_payload,&#10;                    'extract_status': 'failed',&#10;                    'extract_error': f'Webhook {webhook_response.status_code}: {error_text}'[:1500],&#10;                    'extract_failed_at': datetime.utcnow().isoformat()&#10;                }&#10;&#10;                try:&#10;                    requests.patch(update_case_url, params=update_case_params,&#10;                                 headers=update_case_headers, json={'payload': fail_payload}, timeout=TIMEOUT)&#10;                except Exception:&#10;                    pass  # Best effort&#10;&#10;                response = jsonify({&#10;                    'error': 'Webhook call failed',&#10;                    'status': webhook_response.status_code,&#10;                    'details': error_text&#10;                })&#10;                return add_cors_headers(response), 502&#10;&#10;            # If webhook returns JSON, capture it (optional)&#10;            try:&#10;                webhook_json = webhook_response.json()&#10;            except Exception:&#10;                webhook_json = {}&#10;&#10;            # Mark queued/accepted (document is now in backend pipeline)&#10;            queue_doc_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_documents&quot;&#10;            queue_doc_params = {'id': f'eq.{document_id}'}&#10;            queue_doc_data = {'status': 'processing'}&#10;            queue_doc_headers = supabase_headers()&#10;&#10;            try:&#10;                requests.patch(queue_doc_url, params=queue_doc_params,&#10;                             headers=queue_doc_headers, json=queue_doc_data, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            ok_payload = {&#10;                **next_payload,&#10;                'extract_status': 'queued',&#10;                'webhook_response': webhook_json,&#10;                'extract_queued_at': datetime.utcnow().isoformat()&#10;            }&#10;&#10;            try:&#10;                requests.patch(update_case_url, params=update_case_params,&#10;                             headers=update_case_headers, json={'payload': ok_payload}, timeout=TIMEOUT)&#10;            except Exception:&#10;                pass  # Best effort&#10;&#10;            response = jsonify({&#10;                'ok': True,&#10;                'token': token,&#10;                'document_id': document_id,&#10;                'bucket': DOC_BUCKET,&#10;                'path': storage_path,&#10;                'webhook': webhook_json&#10;            })&#10;            return add_cors_headers(response), 200&#10;&#10;        except Exception as e:&#10;            logger.error('Webhook request failed', extra={'error': str(e)})&#10;            response = jsonify({'error': f'Webhook request failed: {str(e)}'})&#10;            return add_cors_headers(response), 502&#10;&#10;    except Exception as e:&#10;        logger.error('Unexpected error in start-extraction', extra={'error': str(e)})&#10;        response = jsonify({'error': str(e) or 'server error'})&#10;        return add_cors_headers(response), 500&#10;&#10;&#10;@app.route('/webhooks/stripe', methods=['POST'])&#10;def stripe_webhook():&#10;    &quot;&quot;&quot;Stripe webhook handler for processing payment events (converted from Deno/TypeScript)&quot;&quot;&quot;&#10;    try:&#10;        # Environment variables validation&#10;        if not STRIPE_SECRET_KEY or not STRIPE_WEBHOOK_SECRET or not SUPABASE_URL or not SUPABASE_SERVICE_ROLE_KEY:&#10;            logger.error(&quot;Missing required environment variables&quot;, extra={&#10;                'hasStripeKey': bool(STRIPE_SECRET_KEY),&#10;                'hasWebhookSecret': bool(STRIPE_WEBHOOK_SECRET),&#10;                'hasSupabaseUrl': bool(SUPABASE_URL),&#10;                'hasServiceRole': bool(SUPABASE_SERVICE_ROLE_KEY),&#10;            })&#10;            return jsonify({'error': 'Missing environment variables'}), 500&#10;&#10;        # Get raw body and signature&#10;        payload = request.get_data()&#10;        sig_header = request.headers.get('stripe-signature')&#10;&#10;        if not sig_header:&#10;            return jsonify({'error': 'No signature'}), 400&#10;&#10;        # Verify webhook signature&#10;        try:&#10;            event = stripe.Webhook.construct_event(&#10;                payload, sig_header, STRIPE_WEBHOOK_SECRET&#10;            )&#10;        except ValueError:&#10;            logger.error(&quot;Invalid payload&quot;)&#10;            return jsonify({'error': 'Invalid payload'}), 400&#10;        except stripe.error.SignatureVerificationError:&#10;            logger.error(&quot;Invalid signature&quot;)&#10;            return jsonify({'error': 'Invalid signature'}), 400&#10;&#10;        logger.info(f&quot;Webhook event type: {event['type']}&quot;)&#10;&#10;        if event['type'] == 'checkout.session.completed':&#10;            session = event['data']['object']&#10;&#10;            # Get token from client_reference_id or metadata&#10;            token = session.get('client_reference_id') or session.get('metadata', {}).get('token')&#10;            if not token:&#10;                return jsonify({'error': 'No token in session'}), 400&#10;&#10;            # Get email (prefer customer_details.email)&#10;            email = (&#10;                session.get('customer_details', {}).get('email') or&#10;                session.get('customer_email') or&#10;                None&#10;            )&#10;&#10;            logger.info(f&quot;Processing payment completion for token: {token}&quot;)&#10;&#10;            # Update case to unlocked&#10;            case_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_cases&quot;&#10;            case_params = {'token': f'eq.{token}'}&#10;            case_data = {&#10;                'unlocked': True,&#10;                'status': 'paid',&#10;                'stripe_checkout_session_id': session['id'],&#10;                'stripe_payment_intent_id': session.get('payment_intent'),&#10;                'amount_total': session.get('amount_total'),&#10;                'currency': session.get('currency'),&#10;                'updated_at': datetime.utcnow().isoformat()&#10;            }&#10;            case_headers = supabase_headers()&#10;            case_headers['Prefer'] = 'return=representation'&#10;&#10;            try:&#10;                case_response = requests.patch(case_url, params=case_params, headers=case_headers,&#10;                                             json=case_data, timeout=TIMEOUT)&#10;                case_response.raise_for_status()&#10;                updated_cases = case_response.json()&#10;&#10;                if not updated_cases:&#10;                    logger.error(f&quot;Case not found for token: {token}&quot;)&#10;                    return jsonify({'error': 'Case not found'}), 404&#10;&#10;                updated_case = updated_cases[0]&#10;                logger.info(f&quot;Successfully updated case: {updated_case.get('id')}&quot;)&#10;&#10;                # Fallback email from DB if Stripe didn't provide it&#10;                if not email:&#10;                    email = updated_case.get('email')&#10;&#10;            except Exception as e:&#10;                logger.error(f&quot;Failed to update case: {str(e)}&quot;)&#10;                return jsonify({'error': 'Database update failed'}), 500&#10;&#10;            # --- Send receipt email (non-fatal) ---&#10;            if not email:&#10;                logger.warning(&quot;No email available (Stripe + DB). Skipping receipt email send.&quot;)&#10;            elif not SMTP_SENDER_WEBHOOK_URL or not SMTP_SENDER_WEBHOOK_SECRET:&#10;                logger.warning(&quot;SMTP sender webhook env vars missing; skipping email send&quot;)&#10;            else:&#10;                case_url_link = f&quot;{SITE_URL}/case.html?case={token}&quot;&#10;                email_payload = {&#10;                    'token': token,&#10;                    'email': email,&#10;                    'case_url': case_url_link,&#10;                    'amount_total': session.get('amount_total'),&#10;                    'currency': session.get('currency'),&#10;                    'customer_name': session.get('customer_details', {}).get('name'),&#10;                    'stripe_session_id': session['id']&#10;                }&#10;&#10;                try:&#10;                    email_response = requests.post(&#10;                        SMTP_SENDER_WEBHOOK_URL,&#10;                        headers={&#10;                            'Content-Type': 'application/json',&#10;                            'X-Webhook-Secret': SMTP_SENDER_WEBHOOK_SECRET&#10;                        },&#10;                        json=email_payload,&#10;                        timeout=TIMEOUT&#10;                    )&#10;&#10;                    if not email_response.ok:&#10;                        error_text = email_response.text&#10;                        logger.warning(f&quot;Receipt email send failed (non-fatal): {email_response.status_code}, {error_text}&quot;)&#10;&#10;                        # Log failed email event&#10;                        try:&#10;                            event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;                            event_data = {&#10;                                'token': token,&#10;                                'type': 'receipt_email_failed',&#10;                                'data': {&#10;                                    'status': email_response.status_code,&#10;                                    'body': error_text[:1000]&#10;                                }&#10;                            }&#10;                            event_headers = supabase_headers()&#10;                            requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;                        except Exception:&#10;                            pass  # Best effort&#10;                    else:&#10;                        # Log successful email event&#10;                        try:&#10;                            event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;                            event_data = {&#10;                                'token': token,&#10;                                'type': 'receipt_email_sent',&#10;                                'data': {&#10;                                    'to': email,&#10;                                    'case_url': case_url_link&#10;                                }&#10;                            }&#10;                            event_headers = supabase_headers()&#10;                            requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;                        except Exception:&#10;                            pass  # Best effort&#10;&#10;                except Exception as e:&#10;                    logger.warning(f&quot;Receipt email send threw (non-fatal): {str(e)}&quot;)&#10;                    # Log error event&#10;                    try:&#10;                        event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;                        event_data = {&#10;                            'token': token,&#10;                            'type': 'receipt_email_failed',&#10;                            'data': {&#10;                                'error': str(e)[:1000]&#10;                            }&#10;                        }&#10;                        event_headers = supabase_headers()&#10;                        requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;                    except Exception:&#10;                        pass  # Best effort&#10;&#10;            # Log payment completion event (also non-fatal)&#10;            try:&#10;                event_url = f&quot;{SUPABASE_URL}/rest/v1/dmhoa_events&quot;&#10;                event_data = {&#10;                    'token': token,&#10;                    'type': 'payment_completed',&#10;                    'data': {&#10;                        'session_id': session['id'],&#10;                        'payment_intent': session.get('payment_intent'),&#10;                        'amount_total': session.get('amount_total'),&#10;                        'currency': session.get('currency'),&#10;                        'customer_email': session.get('customer_email'),&#10;                        'payment_status': session.get('payment_status')&#10;                    }&#10;                }&#10;                event_headers = supabase_headers()&#10;                requests.post(event_url, headers=event_headers, json=event_data, timeout=TIMEOUT)&#10;            except Exception as e:&#10;                logger.warning(f&quot;Failed to log payment_completed event (non-fatal): {str(e)}&quot;)&#10;&#10;            logger.info(f&quot;Payment completion processed successfully for token: {token}&quot;)&#10;&#10;        return jsonify({'received': True}), 200&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Webhook error: {str(e)}&quot;)&#10;        return jsonify({'error': 'Webhook error'}), 500&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/fix_app.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/fix_app.py" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;Fix syntax errors in app.py&quot;&quot;&quot;&#10;&#10;# Read the file&#10;with open('app.py', 'r') as f:&#10;    content = f.read()&#10;&#10;# Find and fix the corrupted schema in case_analysis&#10;# The corrupted section starts at line ~3165&#10;corrupted_section = '''                &quot;risks_and_deadlines&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;deadlines&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 1},&#10;                        &quot;risks&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 3}&#10;                    },&#10;                    &quot;required&quot;: [&quot;deadlines&quot;, &quot;risks&quot;]&#10;                    f&quot;- drafts.clarification MUST be: \\&quot;{draft_titles['clarification']}\\&quot;\\n&quot;&#10;                    f&quot;- drafts.extension MUST be: \\&quot;{draft_titles['extension']}\\&quot;\\n&quot;&#10;                    f&quot;- drafts.compliance MUST be: \\&quot;{draft_titles['compliance']}\\&quot;\\n\\n&quot;&#10;                    f&quot;Also include draft_titles using these exact same strings.\\n\\n&quot;&#10;                    f&quot;summary_html must be valid HTML using ONLY: &lt;div&gt;, &lt;strong&gt;, &lt;ul&gt;, &lt;li&gt;.\\n&quot;&#10;                    f&quot;Drafts must be PLAIN TEXT ONLY with \\\\n, and must NOT include any HTML tags.\\n\\n&quot;&#10;                    f&quot;Make this feel like a $30 deliverable: concrete, specific, complete.\\n&quot;&#10;                )&#10;            }&#10;        ]'''&#10;&#10;fixed_section = '''                &quot;risks_and_deadlines&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;deadlines&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 1},&#10;                        &quot;risks&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 3}&#10;                    },&#10;                    &quot;required&quot;: [&quot;deadlines&quot;, &quot;risks&quot;]&#10;                },&#10;                &quot;action_plan&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 6},&#10;                &quot;drafts&quot;: {&#10;                    &quot;type&quot;: &quot;object&quot;,&#10;                    &quot;additionalProperties&quot;: False,&#10;                    &quot;properties&quot;: {&#10;                        &quot;clarification&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;extension&quot;: {&quot;type&quot;: &quot;string&quot;},&#10;                        &quot;compliance&quot;: {&quot;type&quot;: &quot;string&quot;}&#10;                    },&#10;                    &quot;required&quot;: [&quot;clarification&quot;, &quot;extension&quot;, &quot;compliance&quot;]&#10;                },&#10;                &quot;questions_to_ask&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 6},&#10;                &quot;lowest_cost_path&quot;: {&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: {&quot;type&quot;: &quot;string&quot;}, &quot;minItems&quot;: 4}&#10;            },&#10;            &quot;required&quot;: [&#10;                &quot;summary_html&quot;, &quot;letter_summary&quot;, &quot;draft_titles&quot;, &quot;risks_and_deadlines&quot;,&#10;                &quot;action_plan&quot;, &quot;drafts&quot;, &quot;questions_to_ask&quot;, &quot;lowest_cost_path&quot;&#10;            ]&#10;        }&#10;&#10;        doc_fingerprint = {&#10;            'count': len(docs),&#10;            'usableCount': len(usable_docs),&#10;            'newestUpdatedAt': docs_newest,&#10;            'ids': [d['id'] for d in docs],&#10;            'statuses': [d.get('status') for d in docs],&#10;            'charCounts': [d.get('char_count') for d in docs]&#10;        }&#10;&#10;        messages = [&#10;            {&#10;                &quot;role&quot;: &quot;system&quot;,&#10;                &quot;content&quot;: &quot;&quot;&quot;&#10;You generate HOA dispute assistance for a homeowner.&#10;This is educational drafting help, not legal advice.&#10;&#10;OUTPUT RULES (CRITICAL):&#10;- ONLY &quot;summary_html&quot; may contain HTML.&#10;- summary_html must be valid HTML using ONLY: &lt;div&gt;, &lt;strong&gt;, &lt;ul&gt;, &lt;li&gt;.&#10;- ALL drafts (clarification/extension/compliance) MUST be PLAIN TEXT ONLY:&#10;  - NO HTML tags&#10;  - Use newlines with \\\\n&#10;  - Bullets: use &quot;- item&quot; lines&#10;- Return STRICT JSON that matches the schema exactly.&#10;&#10;DRAFT QUALITY REQUIREMENTS:&#10;- Each draft must be a complete, ready-to-send letter.&#10;- MUST directly quote or reference concrete facts from the extracted documents when available&#10;  (deadlines, email addresses, paragraph citations, dollar amounts, dates, etc.).&#10;- Each must include:&#10;  - Subject line&#10;  - Short opening&#10;  - 3–6 bullet-point requests (specific asks)&#10;  - Proposed timeline (e.g., &quot;Please respond within 10 business days&quot; if no deadline is provided)&#10;  - Request fines/penalties be paused/waived while pending (when relevant)&#10;  - Closing requesting confirmation in writing&#10;&#10;DEPTH REQUIREMENTS:&#10;- action_plan &gt;= 6 steps with timing hints (Today / 48 hours / Before deadline).&#10;- risks &gt;= 3 concrete risks tied to HOA enforcement.&#10;- questions_to_ask &gt;= 6 questions.&#10;- lowest_cost_path &gt;= 4 items.&#10;&#10;STYLE:&#10;- Calm, professional, firm, factual.&#10;&quot;&quot;&quot;&#10;            },&#10;            {&#10;                &quot;role&quot;: &quot;user&quot;,&#10;                &quot;content&quot;: (&#10;                    f&quot;Case payload JSON:\\n{json.dumps(payload)}\\n\\n&quot;&#10;                    f&quot;Document fingerprint (debug):\\n{json.dumps(doc_fingerprint)}\\n\\n&quot;&#10;                    f&quot;Extracted documents:\\n{docs_block}\\n\\n&quot;&#10;                    f&quot;Draft types for this case (MUST follow exactly):\\n&quot;&#10;                    f&quot;- drafts.clarification MUST be: \\&quot;{draft_titles['clarification']}\\&quot;\\n&quot;&#10;                    f&quot;- drafts.extension MUST be: \\&quot;{draft_titles['extension']}\\&quot;\\n&quot;&#10;                    f&quot;- drafts.compliance MUST be: \\&quot;{draft_titles['compliance']}\\&quot;\\n\\n&quot;&#10;                    f&quot;Also include draft_titles using these exact same strings.\\n\\n&quot;&#10;                    f&quot;summary_html must be valid HTML using ONLY: &lt;div&gt;, &lt;strong&gt;, &lt;ul&gt;, &lt;li&gt;.\\n&quot;&#10;                    f&quot;Drafts must be PLAIN TEXT ONLY with \\\\n, and must NOT include any HTML tags.\\n\\n&quot;&#10;                    f&quot;Make this feel like a $30 deliverable: concrete, specific, complete.\\n&quot;&#10;                )&#10;            }&#10;        ]'''&#10;&#10;# Replace the corrupted section&#10;content = content.replace(corrupted_section, fixed_section)&#10;&#10;# Remove duplicate function definitions by finding the second occurrence&#10;# Find the second trigger_document_extraction_async&#10;lines = content.split('\n')&#10;found_first_trigger = False&#10;found_first_clamp = False&#10;cleaned_lines = []&#10;skip_until_next_def = False&#10;&#10;for i, line in enumerate(lines):&#10;    # Handle duplicate trigger_document_extraction_async&#10;    if line.startswith('def trigger_document_extraction_async('):&#10;        if not found_first_trigger:&#10;            found_first_trigger = True&#10;            cleaned_lines.append(line)&#10;        else:&#10;            # Skip the duplicate and everything until the next @app.route or def at the same indentation&#10;            skip_until_next_def = True&#10;            continue&#10;    &#10;    # Handle duplicate clamp_text&#10;    elif line.startswith('def clamp_text('):&#10;        if not found_first_clamp:&#10;            found_first_clamp = True&#10;            cleaned_lines.append(line)&#10;        else:&#10;            skip_until_next_def = True&#10;            continue&#10;    &#10;    # Stop skipping when we hit the next function/route at base indentation&#10;    elif skip_until_next_def and (line.startswith('@app.route(') or (line.startswith('def ') and not line.startswith('    '))):&#10;        skip_until_next_def = False&#10;        cleaned_lines.append(line)&#10;    &#10;    # Normal lines&#10;    elif not skip_until_next_def:&#10;        cleaned_lines.append(line)&#10;&#10;content = '\n'.join(cleaned_lines)&#10;&#10;# Write the fixed content&#10;with open('app.py', 'w') as f:&#10;    f.write(content)&#10;&#10;print(&quot;Fixed app.py successfully!&quot;)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>